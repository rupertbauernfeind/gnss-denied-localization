{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Feature Matching Tuning on Local Map Crops\n",
    "\n",
    "This notebook focuses on finding robust matching settings for localizing train images inside a constant map crop.\n",
    "\n",
    "What is compared:\n",
    "- Backends: `SIFT`, `SuperPoint+LightGlue`, optional `LoFTR`\n",
    "- Filters: raw/gray/shadow/edge/denoise + segmentation-like variants\n",
    "- Strategies:\n",
    "  - `direct`: query vs full crop\n",
    "  - `anchor_roi`: query vs ROI around anchor GT (anchor method)\n",
    "- Invariance handling: scale + rotation sweep per query\n",
    "\n",
    "Evaluation signal:\n",
    "- `raw matches`, `MAGSAC inliers`, `success rate`, center error in crop (px)\n",
    "- visual checks with 4-column plot:\n",
    "  - anchor vs crop\n",
    "  - val vs crop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Position GT for both images is available from train labels.\n",
    "- Orientation GT is not available directly; estimated orientation from homography is still visualized.\n",
    "- Start with a small benchmark subset, then increase once settings look promising.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from time import perf_counter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency checks\n",
    "try:\n",
    "    from lightglue import LightGlue, SuperPoint\n",
    "    from lightglue.utils import rbd\n",
    "    LIGHTGLUE_AVAILABLE = True\n",
    "except Exception:\n",
    "    LIGHTGLUE_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from kornia.feature import LoFTR\n",
    "    LOFTR_AVAILABLE = True\n",
    "except Exception:\n",
    "    LOFTR_AVAILABLE = False\n",
    "\n",
    "if not hasattr(cv2, 'SIFT_create'):\n",
    "    print('Warning: OpenCV SIFT is not available in this build.')\n",
    "\n",
    "# Paths\n",
    "CANDIDATE_ROOTS = [Path.cwd(), Path.cwd().parent, Path('.'), Path('..')]\n",
    "PROJECT_ROOT = None\n",
    "_seen = set()\n",
    "for cand in CANDIDATE_ROOTS:\n",
    "    try:\n",
    "        root = cand.resolve()\n",
    "    except Exception:\n",
    "        continue\n",
    "    key = str(root)\n",
    "    if key in _seen:\n",
    "        continue\n",
    "    _seen.add(key)\n",
    "    if (root / 'data' / 'data').exists():\n",
    "        PROJECT_ROOT = root\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError('Could not find project root containing data/data.')\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'data'\n",
    "TRAIN_IMG_DIR = DATA_ROOT / 'train_data' / 'train_images'\n",
    "TRAIN_POS_CSV = DATA_ROOT / 'train_data' / 'train_pos.csv'\n",
    "TRAIN_CAM_CSV = DATA_ROOT / 'train_data' / 'train_cam.csv'\n",
    "MAP_PATH = DATA_ROOT / 'map.png'\n",
    "\n",
    "# Core config\n",
    "IMAGE_MAX_SIDE = 1280\n",
    "\n",
    "# Constant crop around anchor GT\n",
    "CONST_MAP_CROP_BASE_PX = 900\n",
    "CONST_MAP_CROP_SCALE = 1.0\n",
    "CONST_MAP_CROP_MIN_PX = 192\n",
    "CONST_MAP_CROP_MAX_PX = 1600\n",
    "\n",
    "# Matching params\n",
    "MATCH_MIN_CONF = 0.03\n",
    "MAGSAC_REPROJ_THR = 4.0\n",
    "MAX_NUM_KEYPOINTS = 4096\n",
    "MIN_INLIERS_SUCCESS = 6\n",
    "\n",
    "# SIFT params\n",
    "SIFT_NFEATURES = 6000\n",
    "SIFT_RATIO_TEST = 0.85\n",
    "\n",
    "# LoFTR params\n",
    "LOFTR_MIN_CONF = 0.10\n",
    "\n",
    "# Sweep (rotation/scale invariance)\n",
    "SCALE_SWEEP = [0.16, 0.25, 0.40, 0.60, 0.80, 1.00]\n",
    "ROT_SWEEP_DEG = [-25.0, -15.0, -8.0, 0.0, 8.0, 15.0, 25.0]\n",
    "\n",
    "# Anchor ROI strategy\n",
    "ANCHOR_ROI_FACTOR = 0.60  # ROI size relative to crop size\n",
    "\n",
    "# Filtering params\n",
    "CLAHE_CLIP_LIMIT = 2.5\n",
    "CLAHE_GRID = (8, 8)\n",
    "EDGE_CANNY_LOW = 50\n",
    "EDGE_CANNY_HIGH = 150\n",
    "EDGE_DILATE_KERNEL = 3\n",
    "EDGE_BLEND_GRAY = 0.70\n",
    "EDGE_BLEND_EDGE = 0.30\n",
    "\n",
    "# Benchmark settings\n",
    "BENCH_MAX_PAIRS = 12\n",
    "BENCH_BACKENDS = ['superpoint_lightglue', 'sift', 'loftr']\n",
    "BENCH_FILTERS = [\n",
    "    'raw_rgb',\n",
    "    'gray',\n",
    "    'shadow_clahe_rgb',\n",
    "    'gray_edge_binary',\n",
    "    'gray_edge_blend',\n",
    "    'denoise_edge',\n",
    "    'seg_non_green_gray',\n",
    "    'seg_structure_mask',\n",
    "]\n",
    "BENCH_STRATEGIES = ['direct', 'anchor_roi']\n",
    "\n",
    "print('project_root:', PROJECT_ROOT)\n",
    "print('LightGlue available:', LIGHTGLUE_AVAILABLE)\n",
    "print('LoFTR available:', LOFTR_AVAILABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and build consecutive pairs (id, id+1)\n",
    "train_pos_df = pd.read_csv(TRAIN_POS_CSV)\n",
    "train_cam_df = pd.read_csv(TRAIN_CAM_CSV)\n",
    "train_df = train_cam_df.merge(train_pos_df, on='id', how='inner').copy()\n",
    "train_df['id'] = train_df['id'].astype(int)\n",
    "train_df = train_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "map_bgr = cv2.imread(str(MAP_PATH), cv2.IMREAD_COLOR)\n",
    "if map_bgr is None:\n",
    "    raise FileNotFoundError(f'Map not found: {MAP_PATH}')\n",
    "map_rgb = cv2.cvtColor(map_bgr, cv2.COLOR_BGR2RGB)\n",
    "MAP_H, MAP_W = map_rgb.shape[:2]\n",
    "\n",
    "pairs = []\n",
    "for i in range(len(train_df) - 1):\n",
    "    r0 = train_df.iloc[i]\n",
    "    r1 = train_df.iloc[i + 1]\n",
    "    id0 = int(r0['id'])\n",
    "    id1 = int(r1['id'])\n",
    "    if id1 != id0 + 1:\n",
    "        continue\n",
    "    pairs.append({\n",
    "        'pair_idx': int(len(pairs)),\n",
    "        'anchor_id': id0,\n",
    "        'val_id': id1,\n",
    "        'anchor_x': float(r0['x_pixel']),\n",
    "        'anchor_y': float(r0['y_pixel']),\n",
    "        'val_gt_x': float(r1['x_pixel']),\n",
    "        'val_gt_y': float(r1['y_pixel']),\n",
    "    })\n",
    "\n",
    "pair_df = pd.DataFrame(pairs)\n",
    "print('pairs:', len(pair_df), 'map:', (MAP_W, MAP_H))\n",
    "display(pair_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: image loading, crop extraction, transforms\n",
    "_IMAGE_CACHE: Dict[Tuple[int, Optional[int]], np.ndarray] = {}\n",
    "\n",
    "\n",
    "def resolve_train_image_path(image_id: int) -> Path:\n",
    "    stems = [f'{int(image_id):04d}', str(int(image_id))]\n",
    "    exts = ['.JPG', '.jpg', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "    for st in stems:\n",
    "        for ext in exts:\n",
    "            p = TRAIN_IMG_DIR / f'{st}{ext}'\n",
    "            if p.exists():\n",
    "                return p\n",
    "    raise FileNotFoundError(f'Image not found for id={image_id} in {TRAIN_IMG_DIR}')\n",
    "\n",
    "\n",
    "def resize_keep_aspect(img_rgb: np.ndarray, max_side: Optional[int]) -> np.ndarray:\n",
    "    if max_side is None:\n",
    "        return img_rgb\n",
    "    h, w = img_rgb.shape[:2]\n",
    "    m = max(h, w)\n",
    "    if m <= int(max_side):\n",
    "        return img_rgb\n",
    "    s = float(max_side) / float(m)\n",
    "    nw = max(32, int(round(w * s)))\n",
    "    nh = max(32, int(round(h * s)))\n",
    "    return cv2.resize(img_rgb, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def load_train_image_cached(image_id: int, max_side: Optional[int]) -> np.ndarray:\n",
    "    key = (int(image_id), max_side)\n",
    "    if key in _IMAGE_CACHE:\n",
    "        return _IMAGE_CACHE[key]\n",
    "\n",
    "    p = resolve_train_image_path(int(image_id))\n",
    "    bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise RuntimeError(f'Cannot read image: {p}')\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    rgb = resize_keep_aspect(rgb, max_side=max_side)\n",
    "    _IMAGE_CACHE[key] = rgb\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def resize_rgb(img: np.ndarray, scale: float) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    nw = max(8, int(round(w * float(scale))))\n",
    "    nh = max(8, int(round(h * float(scale))))\n",
    "    return cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def rotate_rgb_keep_size(img: np.ndarray, angle_deg: float) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w / 2.0, h / 2.0), float(angle_deg), 1.0)\n",
    "    return cv2.warpAffine(\n",
    "        img,\n",
    "        M,\n",
    "        (w, h),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_CONSTANT,\n",
    "        borderValue=(0, 0, 0),\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_crop_by_size(map_img: np.ndarray, center_xy: Tuple[float, float], crop_w: int, crop_h: int) -> Tuple[np.ndarray, int, int]:\n",
    "    cw = int(max(16, crop_w))\n",
    "    ch = int(max(16, crop_h))\n",
    "\n",
    "    cx, cy = float(center_xy[0]), float(center_xy[1])\n",
    "    x0 = int(round(cx - cw / 2.0))\n",
    "    y0 = int(round(cy - ch / 2.0))\n",
    "    x0 = int(np.clip(x0, 0, max(0, map_img.shape[1] - cw)))\n",
    "    y0 = int(np.clip(y0, 0, max(0, map_img.shape[0] - ch)))\n",
    "\n",
    "    x1 = min(map_img.shape[1], x0 + cw)\n",
    "    y1 = min(map_img.shape[0], y0 + ch)\n",
    "    crop = map_img[y0:y1, x0:x1]\n",
    "    return crop, x0, y0\n",
    "\n",
    "\n",
    "def pair_to_data(pr: pd.Series) -> Dict[str, object]:\n",
    "    anchor_xy = (float(pr['anchor_x']), float(pr['anchor_y']))\n",
    "    val_xy = (float(pr['val_gt_x']), float(pr['val_gt_y']))\n",
    "\n",
    "    anchor_rgb = load_train_image_cached(int(pr['anchor_id']), max_side=IMAGE_MAX_SIDE)\n",
    "    val_rgb = load_train_image_cached(int(pr['val_id']), max_side=IMAGE_MAX_SIDE)\n",
    "\n",
    "    tile_size = int(np.clip(\n",
    "        round(float(CONST_MAP_CROP_BASE_PX) * float(CONST_MAP_CROP_SCALE)),\n",
    "        int(CONST_MAP_CROP_MIN_PX),\n",
    "        min(MAP_W, MAP_H, int(CONST_MAP_CROP_MAX_PX)),\n",
    "    ))\n",
    "    crop_rgb, x0, y0 = extract_crop_by_size(map_rgb, center_xy=anchor_xy, crop_w=tile_size, crop_h=tile_size)\n",
    "\n",
    "    anchor_local = (float(anchor_xy[0] - x0), float(anchor_xy[1] - y0))\n",
    "    val_local = (float(val_xy[0] - x0), float(val_xy[1] - y0))\n",
    "\n",
    "    return {\n",
    "        'pr': pr,\n",
    "        'anchor_rgb': anchor_rgb,\n",
    "        'val_rgb': val_rgb,\n",
    "        'crop_rgb': crop_rgb,\n",
    "        'crop_origin': (int(x0), int(y0)),\n",
    "        'anchor_local': anchor_local,\n",
    "        'val_local': val_local,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter variants (incl. segmentation-like heuristics)\n",
    "def _to_rgb_uint8(img: np.ndarray) -> np.ndarray:\n",
    "    if img.ndim == 2:\n",
    "        img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def _gray(img: np.ndarray) -> np.ndarray:\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def _shadow_clahe_rgb(img: np.ndarray, clip=2.5, grid=(8, 8)) -> np.ndarray:\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=float(clip), tileGridSize=tuple(grid))\n",
    "    l2 = clahe.apply(l)\n",
    "    return cv2.cvtColor(cv2.merge([l2, a, b]), cv2.COLOR_LAB2RGB)\n",
    "\n",
    "\n",
    "def _edges(gray: np.ndarray) -> np.ndarray:\n",
    "    e = cv2.Canny(gray, int(EDGE_CANNY_LOW), int(EDGE_CANNY_HIGH))\n",
    "    k = int(max(1, EDGE_DILATE_KERNEL))\n",
    "    if k > 1:\n",
    "        e = cv2.dilate(e, np.ones((k, k), dtype=np.uint8), iterations=1)\n",
    "    return e\n",
    "\n",
    "\n",
    "def f_raw(img):\n",
    "    return img\n",
    "\n",
    "\n",
    "def f_gray(img):\n",
    "    return _gray(img)\n",
    "\n",
    "\n",
    "def f_shadow(img):\n",
    "    return _shadow_clahe_rgb(img, clip=CLAHE_CLIP_LIMIT, grid=CLAHE_GRID)\n",
    "\n",
    "\n",
    "def f_gray_edge_binary(img):\n",
    "    return _edges(_gray(img))\n",
    "\n",
    "\n",
    "def f_gray_edge_blend(img):\n",
    "    g = _gray(img)\n",
    "    e = _edges(g)\n",
    "    return cv2.addWeighted(g, float(EDGE_BLEND_GRAY), e, float(EDGE_BLEND_EDGE), 0.0)\n",
    "\n",
    "\n",
    "def f_denoise_edge(img):\n",
    "    g = cv2.bilateralFilter(_gray(img), d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    return _edges(g)\n",
    "\n",
    "\n",
    "def f_seg_non_green_gray(img):\n",
    "    # segmentation-like heuristic: suppress green vegetation by HSV mask\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    lower = np.array([30, 25, 20], dtype=np.uint8)\n",
    "    upper = np.array([95, 255, 255], dtype=np.uint8)\n",
    "    green_mask = cv2.inRange(hsv, lower, upper)\n",
    "    keep = cv2.bitwise_not(green_mask)\n",
    "    g = _gray(img)\n",
    "    out = cv2.bitwise_and(g, g, mask=keep)\n",
    "    return out\n",
    "\n",
    "\n",
    "def f_seg_structure_mask(img):\n",
    "    # segmentation-like structure map: adaptive threshold + edges\n",
    "    g = _gray(img)\n",
    "    thr = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 35, 2)\n",
    "    e = _edges(g)\n",
    "    mask = cv2.bitwise_or(thr, e)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n",
    "    out = cv2.bitwise_and(g, g, mask=mask)\n",
    "    return out\n",
    "\n",
    "\n",
    "FILTER_VARIANTS = {\n",
    "    'raw_rgb': f_raw,\n",
    "    'gray': f_gray,\n",
    "    'shadow_clahe_rgb': f_shadow,\n",
    "    'gray_edge_binary': f_gray_edge_binary,\n",
    "    'gray_edge_blend': f_gray_edge_blend,\n",
    "    'denoise_edge': f_denoise_edge,\n",
    "    'seg_non_green_gray': f_seg_non_green_gray,\n",
    "    'seg_structure_mask': f_seg_structure_mask,\n",
    "}\n",
    "\n",
    "\n",
    "def apply_filter_variant(name: str, img_rgb: np.ndarray) -> np.ndarray:\n",
    "    if name not in FILTER_VARIANTS:\n",
    "        raise KeyError(f'Unknown filter variant: {name}')\n",
    "    return _to_rgb_uint8(FILTER_VARIANTS[name](img_rgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backends: SuperPoint+LightGlue, SIFT, optional LoFTR\n",
    "@dataclass\n",
    "class MatchResult:\n",
    "    k0: np.ndarray\n",
    "    k1: np.ndarray\n",
    "    matches: np.ndarray\n",
    "    conf: np.ndarray\n",
    "\n",
    "\n",
    "class SuperPointLightGlueBackend:\n",
    "    def __init__(self, min_conf: float = 0.03, max_num_keypoints: int = 4096, device: Optional[str] = None):\n",
    "        self.min_conf = float(min_conf)\n",
    "        self.max_num_keypoints = int(max_num_keypoints)\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.extractor = None\n",
    "        self.matcher = None\n",
    "\n",
    "    def _lazy_init(self):\n",
    "        if self.extractor is not None and self.matcher is not None:\n",
    "            return\n",
    "        if not LIGHTGLUE_AVAILABLE:\n",
    "            raise RuntimeError('LightGlue/SuperPoint is not available.')\n",
    "        self.extractor = SuperPoint(max_num_keypoints=self.max_num_keypoints).eval().to(self.device)\n",
    "        self.matcher = LightGlue(features='superpoint').eval().to(self.device)\n",
    "\n",
    "    def _to_tensor(self, img_rgb: np.ndarray) -> torch.Tensor:\n",
    "        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        return (torch.from_numpy(gray).float()[None, None] / 255.0).to(self.device)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def match(self, img0_rgb: np.ndarray, img1_rgb: np.ndarray, min_conf: Optional[float] = None) -> MatchResult:\n",
    "        self._lazy_init()\n",
    "        thr = self.min_conf if min_conf is None else float(min_conf)\n",
    "\n",
    "        t0 = self._to_tensor(img0_rgb)\n",
    "        t1 = self._to_tensor(img1_rgb)\n",
    "\n",
    "        f0 = self.extractor.extract(t0)\n",
    "        f1 = self.extractor.extract(t1)\n",
    "        out = self.matcher({'image0': f0, 'image1': f1})\n",
    "        f0, f1, out = [rbd(x) for x in [f0, f1, out]]\n",
    "\n",
    "        k0 = f0['keypoints'].detach().cpu().numpy().astype(np.float32)\n",
    "        k1 = f1['keypoints'].detach().cpu().numpy().astype(np.float32)\n",
    "        m = out['matches'].detach().cpu().numpy().astype(np.int32)\n",
    "\n",
    "        if m.size == 0:\n",
    "            return MatchResult(k0, k1, np.zeros((0, 2), dtype=np.int32), np.zeros((0,), dtype=np.float32))\n",
    "\n",
    "        if m.ndim != 2:\n",
    "            m = m.reshape(-1, 2)\n",
    "\n",
    "        if 'scores' in out:\n",
    "            conf = out['scores'].detach().cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            conf = np.ones((m.shape[0],), dtype=np.float32)\n",
    "\n",
    "        if conf.shape[0] != m.shape[0]:\n",
    "            conf = np.ones((m.shape[0],), dtype=np.float32)\n",
    "\n",
    "        keep = conf >= thr\n",
    "        return MatchResult(k0, k1, m[keep], conf[keep])\n",
    "\n",
    "\n",
    "class LoFTRBackend:\n",
    "    def __init__(self, min_conf: float = 0.10, device: Optional[str] = None):\n",
    "        self.min_conf = float(min_conf)\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = None\n",
    "\n",
    "    def _lazy_init(self):\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        if not LOFTR_AVAILABLE:\n",
    "            raise RuntimeError('LoFTR is not available (install kornia).')\n",
    "        self.model = LoFTR(pretrained='outdoor').eval().to(self.device)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def match(self, img0_rgb: np.ndarray, img1_rgb: np.ndarray, min_conf: Optional[float] = None) -> MatchResult:\n",
    "        self._lazy_init()\n",
    "        thr = self.min_conf if min_conf is None else float(min_conf)\n",
    "\n",
    "        g0 = cv2.cvtColor(img0_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        g1 = cv2.cvtColor(img1_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        t0 = (torch.from_numpy(g0).float()[None, None] / 255.0).to(self.device)\n",
    "        t1 = (torch.from_numpy(g1).float()[None, None] / 255.0).to(self.device)\n",
    "\n",
    "        out = self.model({'image0': t0, 'image1': t1})\n",
    "        if 'keypoints0' not in out or out['keypoints0'].numel() == 0:\n",
    "            return MatchResult(\n",
    "                np.zeros((0, 2), dtype=np.float32),\n",
    "                np.zeros((0, 2), dtype=np.float32),\n",
    "                np.zeros((0, 2), dtype=np.int32),\n",
    "                np.zeros((0,), dtype=np.float32),\n",
    "            )\n",
    "\n",
    "        k0 = out['keypoints0'].detach().cpu().numpy().astype(np.float32)\n",
    "        k1 = out['keypoints1'].detach().cpu().numpy().astype(np.float32)\n",
    "        if 'confidence' in out:\n",
    "            conf = out['confidence'].detach().cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            conf = np.ones((k0.shape[0],), dtype=np.float32)\n",
    "\n",
    "        keep = conf >= thr\n",
    "        k0 = k0[keep]\n",
    "        k1 = k1[keep]\n",
    "        conf = conf[keep]\n",
    "        n = k0.shape[0]\n",
    "        m = np.column_stack([np.arange(n), np.arange(n)]).astype(np.int32)\n",
    "        return MatchResult(k0, k1, m, conf)\n",
    "\n",
    "\n",
    "def match_sift(img0_rgb: np.ndarray, img1_rgb: np.ndarray) -> MatchResult:\n",
    "    if not hasattr(cv2, 'SIFT_create'):\n",
    "        raise RuntimeError('OpenCV build has no SIFT (cv2.SIFT_create missing).')\n",
    "\n",
    "    g0 = cv2.cvtColor(img0_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    g1 = cv2.cvtColor(img1_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sift = cv2.SIFT_create(nfeatures=int(SIFT_NFEATURES), contrastThreshold=0.01, edgeThreshold=10)\n",
    "    kp0, d0 = sift.detectAndCompute(g0, None)\n",
    "    kp1, d1 = sift.detectAndCompute(g1, None)\n",
    "\n",
    "    if d0 is None or d1 is None or len(kp0) == 0 or len(kp1) == 0:\n",
    "        return MatchResult(\n",
    "            np.zeros((0, 2), dtype=np.float32),\n",
    "            np.zeros((0, 2), dtype=np.float32),\n",
    "            np.zeros((0, 2), dtype=np.int32),\n",
    "            np.zeros((0,), dtype=np.float32),\n",
    "        )\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    knn = bf.knnMatch(d0, d1, k=2)\n",
    "\n",
    "    good = []\n",
    "    for pair in knn:\n",
    "        if len(pair) < 2:\n",
    "            continue\n",
    "        m, n = pair\n",
    "        if m.distance < float(SIFT_RATIO_TEST) * n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    k0 = np.array([k.pt for k in kp0], dtype=np.float32)\n",
    "    k1 = np.array([k.pt for k in kp1], dtype=np.float32)\n",
    "\n",
    "    if len(good) == 0:\n",
    "        return MatchResult(k0, k1, np.zeros((0, 2), dtype=np.int32), np.zeros((0,), dtype=np.float32))\n",
    "\n",
    "    matches = np.array([[m.queryIdx, m.trainIdx] for m in good], dtype=np.int32)\n",
    "    conf = np.array([1.0 / (m.distance + 1e-6) for m in good], dtype=np.float32)\n",
    "    conf /= max(1e-6, float(conf.max()))\n",
    "    return MatchResult(k0, k1, matches, conf)\n",
    "\n",
    "\n",
    "SP_LG = SuperPointLightGlueBackend(min_conf=MATCH_MIN_CONF, max_num_keypoints=MAX_NUM_KEYPOINTS)\n",
    "LOFTR_BK = LoFTRBackend(min_conf=LOFTR_MIN_CONF)\n",
    "\n",
    "\n",
    "def run_backend_match(backend_name: str, img0_rgb: np.ndarray, img1_rgb: np.ndarray) -> MatchResult:\n",
    "    if backend_name == 'superpoint_lightglue':\n",
    "        return SP_LG.match(img0_rgb, img1_rgb, min_conf=MATCH_MIN_CONF)\n",
    "    if backend_name == 'sift':\n",
    "        return match_sift(img0_rgb, img1_rgb)\n",
    "    if backend_name == 'loftr':\n",
    "        return LOFTR_BK.match(img0_rgb, img1_rgb, min_conf=LOFTR_MIN_CONF)\n",
    "    raise KeyError(f'Unknown backend: {backend_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry, sweep search, scoring, visualization helpers\n",
    "\n",
    "def magsac_homography(k0: np.ndarray, k1: np.ndarray, matches: np.ndarray, reproj_thr: float = 4.0):\n",
    "    if matches.shape[0] < 8:\n",
    "        return None, np.zeros((matches.shape[0],), dtype=bool)\n",
    "\n",
    "    p0 = k0[matches[:, 0]].astype(np.float32)\n",
    "    p1 = k1[matches[:, 1]].astype(np.float32)\n",
    "\n",
    "    H, mask = cv2.findHomography(\n",
    "        p0,\n",
    "        p1,\n",
    "        method=cv2.USAC_MAGSAC,\n",
    "        ransacReprojThreshold=float(reproj_thr),\n",
    "        maxIters=10000,\n",
    "        confidence=0.999,\n",
    "    )\n",
    "    if H is None or mask is None:\n",
    "        return None, np.zeros((matches.shape[0],), dtype=bool)\n",
    "    return H, mask.ravel().astype(bool)\n",
    "\n",
    "\n",
    "def project_point_homography(H: np.ndarray, xy: Tuple[float, float]) -> Tuple[float, float]:\n",
    "    p = np.array([float(xy[0]), float(xy[1]), 1.0], dtype=np.float64)\n",
    "    q = H @ p\n",
    "    if abs(float(q[2])) < 1e-12:\n",
    "        return np.nan, np.nan\n",
    "    return float(q[0] / q[2]), float(q[1] / q[2])\n",
    "\n",
    "\n",
    "def estimate_orientation_from_h(H: np.ndarray, q_shape: Tuple[int, int, int], offset_xy: Tuple[float, float] = (0.0, 0.0)) -> float:\n",
    "    hq, wq = q_shape[:2]\n",
    "    c = (wq * 0.5, hq * 0.5)\n",
    "    xaxis = (wq * 0.75, hq * 0.5)\n",
    "    c2 = project_point_homography(H, c)\n",
    "    x2 = project_point_homography(H, xaxis)\n",
    "    if not (np.isfinite(c2[0]) and np.isfinite(c2[1]) and np.isfinite(x2[0]) and np.isfinite(x2[1])):\n",
    "        return np.nan\n",
    "    dx = (x2[0] + offset_xy[0]) - (c2[0] + offset_xy[0])\n",
    "    dy = (x2[1] + offset_xy[1]) - (c2[1] + offset_xy[1])\n",
    "    if abs(dx) < 1e-12 and abs(dy) < 1e-12:\n",
    "        return np.nan\n",
    "    return float(np.degrees(np.arctan2(dy, dx)))\n",
    "\n",
    "\n",
    "def extract_anchor_roi(ref_crop: np.ndarray, anchor_local: Tuple[float, float], factor: float) -> Tuple[np.ndarray, int, int]:\n",
    "    ch, cw = ref_crop.shape[:2]\n",
    "    rw = int(np.clip(round(float(cw) * float(factor)), 96, cw))\n",
    "    rh = int(np.clip(round(float(ch) * float(factor)), 96, ch))\n",
    "    return extract_crop_by_size(ref_crop, center_xy=anchor_local, crop_w=rw, crop_h=rh)\n",
    "\n",
    "\n",
    "def run_match_sweep(\n",
    "    backend_name: str,\n",
    "    query_rgb: np.ndarray,\n",
    "    full_crop_rgb: np.ndarray,\n",
    "    strategy: str,\n",
    "    anchor_local: Tuple[float, float],\n",
    "    gt_local: Tuple[float, float],\n",
    "    scales: List[float],\n",
    "    rots_deg: List[float],\n",
    ") -> Dict[str, object]:\n",
    "    if strategy not in {'direct', 'anchor_roi'}:\n",
    "        raise ValueError(f'Unknown strategy: {strategy}')\n",
    "\n",
    "    if strategy == 'anchor_roi':\n",
    "        ref_rgb, rx, ry = extract_anchor_roi(full_crop_rgb, anchor_local=anchor_local, factor=float(ANCHOR_ROI_FACTOR))\n",
    "    else:\n",
    "        ref_rgb = full_crop_rgb\n",
    "        rx, ry = 0, 0\n",
    "\n",
    "    best = None\n",
    "\n",
    "    for s in scales:\n",
    "        s = float(s)\n",
    "        if s <= 0.0:\n",
    "            continue\n",
    "        q_s = resize_rgb(query_rgb, s) if abs(s - 1.0) > 1e-6 else query_rgb\n",
    "\n",
    "        for rdeg in rots_deg:\n",
    "            rdeg = float(rdeg)\n",
    "            q_sr = rotate_rgb_keep_size(q_s, rdeg) if abs(rdeg) > 1e-6 else q_s\n",
    "\n",
    "            try:\n",
    "                m = run_backend_match(backend_name, q_sr, ref_rgb)\n",
    "                H, inl = magsac_homography(m.k0, m.k1, m.matches, reproj_thr=MAGSAC_REPROJ_THR)\n",
    "            except Exception as e:\n",
    "                m = MatchResult(\n",
    "                    k0=np.zeros((0, 2), dtype=np.float32),\n",
    "                    k1=np.zeros((0, 2), dtype=np.float32),\n",
    "                    matches=np.zeros((0, 2), dtype=np.int32),\n",
    "                    conf=np.zeros((0,), dtype=np.float32),\n",
    "                )\n",
    "                H, inl = None, np.zeros((0,), dtype=bool)\n",
    "                raw_matches, inliers = 0, 0\n",
    "                pred_full = (np.nan, np.nan)\n",
    "                err_px = np.nan\n",
    "                ori_deg = np.nan\n",
    "                score = (-1, -1, -1.0)\n",
    "                cand = {\n",
    "                    'ok': False,\n",
    "                    'error': str(e),\n",
    "                    'query_used': q_sr,\n",
    "                    'ref_used': ref_rgb,\n",
    "                    'ref_offset': (int(rx), int(ry)),\n",
    "                    'scale_used': s,\n",
    "                    'rot_used_deg': rdeg,\n",
    "                    'match': m,\n",
    "                    'H': H,\n",
    "                    'inlier_mask': inl,\n",
    "                    'raw_matches': raw_matches,\n",
    "                    'inliers': inliers,\n",
    "                    'pred_local_full': pred_full,\n",
    "                    'ori_deg': ori_deg,\n",
    "                    'err_px': err_px,\n",
    "                    'score': score,\n",
    "                }\n",
    "            else:\n",
    "                raw_matches = int(m.matches.shape[0])\n",
    "                inliers = int(inl.sum()) if inl is not None else 0\n",
    "\n",
    "                if H is not None and inliers >= int(MIN_INLIERS_SUCCESS):\n",
    "                    q_center = (float(q_sr.shape[1] * 0.5), float(q_sr.shape[0] * 0.5))\n",
    "                    px_ref, py_ref = project_point_homography(H, q_center)\n",
    "                    if np.isfinite(px_ref) and np.isfinite(py_ref):\n",
    "                        pred_full = (float(px_ref + rx), float(py_ref + ry))\n",
    "                        err_px = float(np.hypot(pred_full[0] - gt_local[0], pred_full[1] - gt_local[1]))\n",
    "                    else:\n",
    "                        pred_full = (np.nan, np.nan)\n",
    "                        err_px = np.nan\n",
    "                    ori_deg = estimate_orientation_from_h(H, q_sr.shape, offset_xy=(float(rx), float(ry)))\n",
    "                else:\n",
    "                    pred_full = (np.nan, np.nan)\n",
    "                    err_px = np.nan\n",
    "                    ori_deg = np.nan\n",
    "\n",
    "                conf_mean = float(m.conf.mean()) if m.conf.shape[0] > 0 else 0.0\n",
    "                score = (inliers, raw_matches, conf_mean)\n",
    "                cand = {\n",
    "                    'ok': True,\n",
    "                    'error': '',\n",
    "                    'query_used': q_sr,\n",
    "                    'ref_used': ref_rgb,\n",
    "                    'ref_offset': (int(rx), int(ry)),\n",
    "                    'scale_used': s,\n",
    "                    'rot_used_deg': rdeg,\n",
    "                    'match': m,\n",
    "                    'H': H,\n",
    "                    'inlier_mask': inl,\n",
    "                    'raw_matches': raw_matches,\n",
    "                    'inliers': inliers,\n",
    "                    'pred_local_full': pred_full,\n",
    "                    'ori_deg': ori_deg,\n",
    "                    'err_px': err_px,\n",
    "                    'score': score,\n",
    "                }\n",
    "\n",
    "            if best is None or cand['score'] > best['score']:\n",
    "                best = cand\n",
    "\n",
    "    if best is None:\n",
    "        best = {\n",
    "            'ok': False,\n",
    "            'error': 'no candidate',\n",
    "            'query_used': query_rgb,\n",
    "            'ref_used': full_crop_rgb,\n",
    "            'ref_offset': (0, 0),\n",
    "            'scale_used': 1.0,\n",
    "            'rot_used_deg': 0.0,\n",
    "            'match': MatchResult(\n",
    "                k0=np.zeros((0, 2), dtype=np.float32),\n",
    "                k1=np.zeros((0, 2), dtype=np.float32),\n",
    "                matches=np.zeros((0, 2), dtype=np.int32),\n",
    "                conf=np.zeros((0,), dtype=np.float32),\n",
    "            ),\n",
    "            'H': None,\n",
    "            'inlier_mask': np.zeros((0,), dtype=bool),\n",
    "            'raw_matches': 0,\n",
    "            'inliers': 0,\n",
    "            'pred_local_full': (np.nan, np.nan),\n",
    "            'ori_deg': np.nan,\n",
    "            'err_px': np.nan,\n",
    "            'score': (-1, -1, -1.0),\n",
    "        }\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def evaluate_pair_one_setting(\n",
    "    pr: pd.Series,\n",
    "    backend_name: str,\n",
    "    filter_name: str,\n",
    "    strategy: str,\n",
    ") -> Dict[str, object]:\n",
    "    data = pair_to_data(pr)\n",
    "\n",
    "    anchor_f = apply_filter_variant(filter_name, data['anchor_rgb'])\n",
    "    val_f = apply_filter_variant(filter_name, data['val_rgb'])\n",
    "    crop_f = apply_filter_variant(filter_name, data['crop_rgb'])\n",
    "\n",
    "    anchor_res = run_match_sweep(\n",
    "        backend_name=backend_name,\n",
    "        query_rgb=anchor_f,\n",
    "        full_crop_rgb=crop_f,\n",
    "        strategy=strategy,\n",
    "        anchor_local=data['anchor_local'],\n",
    "        gt_local=data['anchor_local'],\n",
    "        scales=SCALE_SWEEP,\n",
    "        rots_deg=ROT_SWEEP_DEG,\n",
    "    )\n",
    "\n",
    "    val_res = run_match_sweep(\n",
    "        backend_name=backend_name,\n",
    "        query_rgb=val_f,\n",
    "        full_crop_rgb=crop_f,\n",
    "        strategy=strategy,\n",
    "        anchor_local=data['anchor_local'],\n",
    "        gt_local=data['val_local'],\n",
    "        scales=SCALE_SWEEP,\n",
    "        rots_deg=ROT_SWEEP_DEG,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'pr': pr,\n",
    "        'data': data,\n",
    "        'backend': backend_name,\n",
    "        'filter': filter_name,\n",
    "        'strategy': strategy,\n",
    "        'anchor_res': anchor_res,\n",
    "        'val_res': val_res,\n",
    "        'anchor_f': anchor_f,\n",
    "        'val_f': val_f,\n",
    "        'crop_f': crop_f,\n",
    "    }\n",
    "\n",
    "\n",
    "def _pick_draw_idx(match: MatchResult, inl: np.ndarray, max_draw: int = 120, seed: int = 7):\n",
    "    n = int(match.matches.shape[0])\n",
    "    if n == 0:\n",
    "        return np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "    if inl is not None and inl.shape[0] == n and np.any(inl):\n",
    "        idx = np.where(inl.astype(bool))[0]\n",
    "    else:\n",
    "        idx = np.arange(n, dtype=np.int32)\n",
    "\n",
    "    if idx.size <= max_draw:\n",
    "        return idx\n",
    "\n",
    "    if match.conf is not None and match.conf.shape[0] == n:\n",
    "        order = np.argsort(-match.conf[idx])[:max_draw]\n",
    "        return idx[order]\n",
    "\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "    return np.sort(rng.choice(idx, size=max_draw, replace=False))\n",
    "\n",
    "\n",
    "def draw_4col_inspection(res: Dict[str, object], max_draw: int = 120, seed: int = 7):\n",
    "    # [anchor|crop] [val|crop]\n",
    "    a = _to_rgb_uint8(res['anchor_res']['query_used'])\n",
    "    v = _to_rgb_uint8(res['val_res']['query_used'])\n",
    "    c = _to_rgb_uint8(res['crop_f'])\n",
    "\n",
    "    h = max(a.shape[0], c.shape[0], v.shape[0], c.shape[0])\n",
    "    w1, w2, w3, w4 = a.shape[1], c.shape[1], v.shape[1], c.shape[1]\n",
    "    W = w1 + w2 + w3 + w4\n",
    "    canvas = np.zeros((h, W, 3), dtype=np.uint8)\n",
    "\n",
    "    def put(im, x):\n",
    "        y = (h - im.shape[0]) // 2\n",
    "        canvas[y:y + im.shape[0], x:x + im.shape[1]] = im\n",
    "        return (x, y, im.shape[1], im.shape[0])\n",
    "\n",
    "    p1 = put(a, 0)\n",
    "    p2 = put(c, w1)\n",
    "    p3 = put(v, w1 + w2)\n",
    "    p4 = put(c, w1 + w2 + w3)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(30, 6))\n",
    "    ax.imshow(canvas)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # separators\n",
    "    for xs in [p2[0] - 0.5, p3[0] - 0.5, p4[0] - 0.5]:\n",
    "        ax.axvline(xs, color='white', linewidth=1.0, alpha=0.6)\n",
    "\n",
    "    # anchor->crop lines\n",
    "    ar = res['anchor_res']\n",
    "    am = ar['match']\n",
    "    a_idx = _pick_draw_idx(am, ar['inlier_mask'], max_draw=max_draw, seed=seed)\n",
    "    x1, y1, _, _ = p1\n",
    "    x2, y2, _, _ = p2\n",
    "    offx_a, offy_a = ar['ref_offset']\n",
    "\n",
    "    for i in a_idx:\n",
    "        ii = int(i)\n",
    "        qi = int(am.matches[ii, 0])\n",
    "        ri = int(am.matches[ii, 1])\n",
    "        q = am.k0[qi]\n",
    "        r = am.k1[ri]\n",
    "        ok_inl = bool(ar['inlier_mask'][ii]) if ar['inlier_mask'] is not None and ii < len(ar['inlier_mask']) else False\n",
    "        ax.plot(\n",
    "            [float(q[0] + x1), float(r[0] + offx_a + x2)],\n",
    "            [float(q[1] + y1), float(r[1] + offy_a + y2)],\n",
    "            color='cyan',\n",
    "            linewidth=1.2 if ok_inl else 0.6,\n",
    "            alpha=0.9 if ok_inl else 0.25,\n",
    "        )\n",
    "\n",
    "    # val->crop lines\n",
    "    vr = res['val_res']\n",
    "    vm = vr['match']\n",
    "    v_idx = _pick_draw_idx(vm, vr['inlier_mask'], max_draw=max_draw, seed=seed)\n",
    "    x3, y3, _, _ = p3\n",
    "    x4, y4, _, _ = p4\n",
    "    offx_v, offy_v = vr['ref_offset']\n",
    "\n",
    "    for i in v_idx:\n",
    "        ii = int(i)\n",
    "        qi = int(vm.matches[ii, 0])\n",
    "        ri = int(vm.matches[ii, 1])\n",
    "        q = vm.k0[qi]\n",
    "        r = vm.k1[ri]\n",
    "        ok_inl = bool(vr['inlier_mask'][ii]) if vr['inlier_mask'] is not None and ii < len(vr['inlier_mask']) else False\n",
    "        ax.plot(\n",
    "            [float(q[0] + x3), float(r[0] + offx_v + x4)],\n",
    "            [float(q[1] + y3), float(r[1] + offy_v + y4)],\n",
    "            color='orange',\n",
    "            linewidth=1.2 if ok_inl else 0.6,\n",
    "            alpha=0.9 if ok_inl else 0.25,\n",
    "        )\n",
    "\n",
    "    # GT + predicted centers on crop columns\n",
    "    al = res['data']['anchor_local']\n",
    "    vl = res['data']['val_local']\n",
    "\n",
    "    # left crop\n",
    "    ax.scatter([al[0] + x2], [al[1] + y2], s=30, c='red')\n",
    "    ax.scatter([vl[0] + x2], [vl[1] + y2], s=28, c='cyan')\n",
    "    if np.isfinite(ar['pred_local_full'][0]) and np.isfinite(ar['pred_local_full'][1]):\n",
    "        ax.scatter([ar['pred_local_full'][0] + x2], [ar['pred_local_full'][1] + y2], s=55, c='yellow', marker='*')\n",
    "\n",
    "    # right crop\n",
    "    ax.scatter([al[0] + x4], [al[1] + y4], s=30, c='red')\n",
    "    ax.scatter([vl[0] + x4], [vl[1] + y4], s=28, c='cyan')\n",
    "    if np.isfinite(vr['pred_local_full'][0]) and np.isfinite(vr['pred_local_full'][1]):\n",
    "        ax.scatter([vr['pred_local_full'][0] + x4], [vr['pred_local_full'][1] + y4], s=55, c='yellow', marker='*')\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{res['filter']} | {res['backend']} | {res['strategy']} | \"\n",
    "        f\"A raw={ar['raw_matches']} inl={ar['inliers']} err={ar['err_px']:.1f} | \"\n",
    "        f\"V raw={vr['raw_matches']} inl={vr['inliers']} err={vr['err_px']:.1f}\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-column comparison with SuperPoint+LightGlue matches (inspector)\n",
    "\n",
    "PAIR_ANCHOR_ID = 13\n",
    "PAIR_VAL_ID = 14\n",
    "PREVIEW_PAIR_INDEX = 0\n",
    "\n",
    "INSPECT_BACKEND = 'superpoint_lightglue'   # 'superpoint_lightglue' | 'sift' | 'loftr'\n",
    "INSPECT_FILTER = 'gray'                    # key from FILTER_VARIANTS\n",
    "INSPECT_STRATEGY = 'direct'                # 'direct' | 'anchor_roi'\n",
    "\n",
    "# pick pair\n",
    "sel = pair_df[\n",
    "    (pair_df['anchor_id'].astype(int) == int(PAIR_ANCHOR_ID)) &\n",
    "    (pair_df['val_id'].astype(int) == int(PAIR_VAL_ID))\n",
    "]\n",
    "if len(sel) == 0:\n",
    "    idx = int(np.clip(PREVIEW_PAIR_INDEX, 0, len(pair_df) - 1))\n",
    "    pr = pair_df.iloc[idx]\n",
    "    print(f'Pair {PAIR_ANCHOR_ID}->{PAIR_VAL_ID} not found, using pair index {idx}.')\n",
    "else:\n",
    "    pr = sel.iloc[0]\n",
    "\n",
    "if INSPECT_BACKEND == 'loftr' and not LOFTR_AVAILABLE:\n",
    "    raise RuntimeError('LoFTR backend selected but kornia/LoFTR is not available.')\n",
    "if INSPECT_BACKEND == 'superpoint_lightglue' and not LIGHTGLUE_AVAILABLE:\n",
    "    raise RuntimeError('SuperPoint+LightGlue selected but lightglue is not available.')\n",
    "\n",
    "res = evaluate_pair_one_setting(\n",
    "    pr=pr,\n",
    "    backend_name=INSPECT_BACKEND,\n",
    "    filter_name=INSPECT_FILTER,\n",
    "    strategy=INSPECT_STRATEGY,\n",
    ")\n",
    "\n",
    "draw_4col_inspection(res, max_draw=120, seed=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: methods x filters x strategies on a subset of pairs\n",
    "\n",
    "active_backends = []\n",
    "for b in BENCH_BACKENDS:\n",
    "    if b == 'superpoint_lightglue' and not LIGHTGLUE_AVAILABLE:\n",
    "        continue\n",
    "    if b == 'loftr' and not LOFTR_AVAILABLE:\n",
    "        continue\n",
    "    active_backends.append(b)\n",
    "\n",
    "if len(active_backends) == 0:\n",
    "    raise RuntimeError('No backend available for benchmark.')\n",
    "\n",
    "n_pairs = int(min(BENCH_MAX_PAIRS, len(pair_df)))\n",
    "sub_pairs = pair_df.head(n_pairs)\n",
    "\n",
    "rows = []\n",
    "cache = {}\n",
    "\n",
    "t0 = perf_counter()\n",
    "for k, pr in enumerate(sub_pairs.itertuples(index=False), 1):\n",
    "    pr_s = pd.Series(pr._asdict())\n",
    "    for backend in active_backends:\n",
    "        for filt in BENCH_FILTERS:\n",
    "            if filt not in FILTER_VARIANTS:\n",
    "                continue\n",
    "            for strat in BENCH_STRATEGIES:\n",
    "                out = evaluate_pair_one_setting(\n",
    "                    pr=pr_s,\n",
    "                    backend_name=backend,\n",
    "                    filter_name=filt,\n",
    "                    strategy=strat,\n",
    "                )\n",
    "\n",
    "                ar = out['anchor_res']\n",
    "                vr = out['val_res']\n",
    "\n",
    "                rows.append({\n",
    "                    'pair_idx': int(pr_s['pair_idx']),\n",
    "                    'anchor_id': int(pr_s['anchor_id']),\n",
    "                    'val_id': int(pr_s['val_id']),\n",
    "                    'backend': backend,\n",
    "                    'filter': filt,\n",
    "                    'strategy': strat,\n",
    "                    'anchor_raw': int(ar['raw_matches']),\n",
    "                    'anchor_inliers': int(ar['inliers']),\n",
    "                    'anchor_err_px': float(ar['err_px']) if np.isfinite(ar['err_px']) else np.nan,\n",
    "                    'anchor_success': bool(ar['inliers'] >= MIN_INLIERS_SUCCESS),\n",
    "                    'anchor_scale': float(ar['scale_used']),\n",
    "                    'anchor_rot': float(ar['rot_used_deg']),\n",
    "                    'val_raw': int(vr['raw_matches']),\n",
    "                    'val_inliers': int(vr['inliers']),\n",
    "                    'val_err_px': float(vr['err_px']) if np.isfinite(vr['err_px']) else np.nan,\n",
    "                    'val_success': bool(vr['inliers'] >= MIN_INLIERS_SUCCESS),\n",
    "                    'val_scale': float(vr['scale_used']),\n",
    "                    'val_rot': float(vr['rot_used_deg']),\n",
    "                })\n",
    "\n",
    "                cache[(int(pr_s['pair_idx']), backend, filt, strat)] = out\n",
    "\n",
    "    if k % 2 == 0:\n",
    "        print(f'processed pairs: {k}/{n_pairs}')\n",
    "\n",
    "bench_detail_df = pd.DataFrame(rows)\n",
    "print('benchmark rows:', len(bench_detail_df), 'runtime_s:', f'{(perf_counter()-t0):.1f}')\n",
    "display(bench_detail_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate ranking + top visualizations\n",
    "if len(bench_detail_df) == 0:\n",
    "    raise RuntimeError('No benchmark data available.')\n",
    "\n",
    "agg = (\n",
    "    bench_detail_df\n",
    "    .groupby(['backend', 'filter', 'strategy'], as_index=False)\n",
    "    .agg(\n",
    "        n_pairs=('pair_idx', 'count'),\n",
    "        anchor_raw_mean=('anchor_raw', 'mean'),\n",
    "        anchor_inl_mean=('anchor_inliers', 'mean'),\n",
    "        anchor_success_rate=('anchor_success', 'mean'),\n",
    "        anchor_err_median=('anchor_err_px', 'median'),\n",
    "        val_raw_mean=('val_raw', 'mean'),\n",
    "        val_inl_mean=('val_inliers', 'mean'),\n",
    "        val_success_rate=('val_success', 'mean'),\n",
    "        val_err_median=('val_err_px', 'median'),\n",
    "    )\n",
    ")\n",
    "\n",
    "# score prioritizes robust val matching\n",
    "agg['score'] = (\n",
    "    100.0 * agg['val_success_rate']\n",
    "    + 2.0 * agg['val_inl_mean']\n",
    "    - 0.20 * agg['val_err_median'].fillna(999.0)\n",
    ")\n",
    "\n",
    "agg = agg.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(agg.head(30))\n",
    "print('Pivot val_inl_mean:')\n",
    "display(agg.pivot_table(index='filter', columns='backend', values='val_inl_mean', aggfunc='max'))\n",
    "\n",
    "# Visualize top-k settings on chosen pair\n",
    "TOP_K_VIS = 5\n",
    "VIS_PAIR_ANCHOR_ID = 13\n",
    "VIS_PAIR_VAL_ID = 14\n",
    "VIS_PAIR_INDEX_FALLBACK = 0\n",
    "\n",
    "sel = pair_df[\n",
    "    (pair_df['anchor_id'].astype(int) == int(VIS_PAIR_ANCHOR_ID)) &\n",
    "    (pair_df['val_id'].astype(int) == int(VIS_PAIR_VAL_ID))\n",
    "]\n",
    "if len(sel) == 0:\n",
    "    idx = int(np.clip(VIS_PAIR_INDEX_FALLBACK, 0, len(pair_df) - 1))\n",
    "    pr = pair_df.iloc[idx]\n",
    "else:\n",
    "    pr = sel.iloc[0]\n",
    "pair_idx = int(pr['pair_idx'])\n",
    "\n",
    "show_rows = agg.head(int(min(TOP_K_VIS, len(agg))))\n",
    "for rr in show_rows.itertuples(index=False):\n",
    "    key = (pair_idx, rr.backend, rr.filter, rr.strategy)\n",
    "    if key not in cache:\n",
    "        out = evaluate_pair_one_setting(\n",
    "            pr=pr,\n",
    "            backend_name=rr.backend,\n",
    "            filter_name=rr.filter,\n",
    "            strategy=rr.strategy,\n",
    "        )\n",
    "    else:\n",
    "        out = cache[key]\n",
    "    draw_4col_inspection(out, max_draw=120, seed=7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
