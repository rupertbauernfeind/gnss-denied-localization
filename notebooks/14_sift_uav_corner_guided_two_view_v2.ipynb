{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b9e67d",
   "metadata": {},
   "source": [
    "# 14 - SIFT Two-View Pose (Notebook 12 + Corner-Guided Ideas)\n",
    "\n",
    "Dieses Notebook kombiniert die robuste Daten-/Pair-Logik aus Notebook 12 mit den Ideen aus Notebook 14:\n",
    "- optionales Corner-Guiding fuer SIFT (`goodFeaturesToTrack` + `SIFT.compute`)\n",
    "- RootSIFT\n",
    "- Fokusmasken gegen Gras-Textur (`none`, `nongreen`, `edge_corner_mild`, `edge_corner_strict`, `line_corner_only`)\n",
    "- Homography-guided Essential/Pose-Auswertung\n",
    "\n",
    "Ziel: robuste relative Pose (Rotation/Translation/Scale in Pixeln) fuer ein aufeinanderfolgendes Bildpaar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 130\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5704c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic checks + paths + global config\n",
    "if not hasattr(cv2, 'SIFT_create'):\n",
    "    raise RuntimeError('OpenCV build has no SIFT. Please install opencv-contrib-python.')\n",
    "\n",
    "CANDIDATE_ROOTS = [Path.cwd(), Path.cwd().parent, Path('.'), Path('..')]\n",
    "PROJECT_ROOT = None\n",
    "_seen = set()\n",
    "for cand in CANDIDATE_ROOTS:\n",
    "    try:\n",
    "        root = cand.resolve()\n",
    "    except Exception:\n",
    "        continue\n",
    "    k = str(root)\n",
    "    if k in _seen:\n",
    "        continue\n",
    "    _seen.add(k)\n",
    "    if (root / 'data' / 'data').exists():\n",
    "        PROJECT_ROOT = root\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError('Could not find project root containing data/data.')\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'data'\n",
    "TRAIN_IMG_DIR = DATA_ROOT / 'train_data' / 'train_images'\n",
    "TRAIN_POS_CSV = DATA_ROOT / 'train_data' / 'train_pos.csv'\n",
    "TRAIN_CAM_CSV = DATA_ROOT / 'train_data' / 'train_cam.csv'\n",
    "\n",
    "# Pair selection\n",
    "PAIR_ANCHOR_ID = 13\n",
    "PAIR_VAL_ID = 14\n",
    "PREVIEW_PAIR_INDEX = 0\n",
    "\n",
    "# Runtime + preprocessing\n",
    "IMAGE_MAX_SIDE = 1400  # None for full resolution\n",
    "PREPROCESS_MODE = 'gray_denoise_clahe'  # ['gray', 'gray_clahe', 'gray_denoise_clahe']\n",
    "\n",
    "# Geometry thresholds\n",
    "AFFINE_RANSAC_THR = 3.0\n",
    "HOMOGRAPHY_RANSAC_THR = 4.0\n",
    "ESSENTIAL_RANSAC_THR = 1.5  # in normalized coordinates (after undistortPoints)\n",
    "\n",
    "# Match filtering\n",
    "H_GUIDE_ERR_PX = 4.0\n",
    "MIN_MATCHES_FOR_GEOM = 8\n",
    "\n",
    "# Draw control\n",
    "MAX_DRAW_MATCHES = 500\n",
    "\n",
    "print('project_root:', PROJECT_ROOT)\n",
    "print('train_img_dir:', TRAIN_IMG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train table + consecutive pairs\n",
    "train_pos_df = pd.read_csv(TRAIN_POS_CSV)\n",
    "train_cam_df = pd.read_csv(TRAIN_CAM_CSV)\n",
    "train_df = train_cam_df.merge(train_pos_df, on='id', how='inner').copy()\n",
    "train_df['id'] = train_df['id'].astype(int)\n",
    "train_df = train_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "required_cols = ['id', 'x_pixel', 'y_pixel', 'fx', 'fy', 'cx', 'cy']\n",
    "for c in required_cols:\n",
    "    if c not in train_df.columns:\n",
    "        raise KeyError(f'Missing required column: {c}')\n",
    "\n",
    "pairs = []\n",
    "for i in range(len(train_df) - 1):\n",
    "    r0 = train_df.iloc[i]\n",
    "    r1 = train_df.iloc[i + 1]\n",
    "    id0 = int(r0['id'])\n",
    "    id1 = int(r1['id'])\n",
    "    if id1 != id0 + 1:\n",
    "        continue\n",
    "    pairs.append({'pair_idx': len(pairs), 'anchor_id': id0, 'val_id': id1})\n",
    "pair_df = pd.DataFrame(pairs)\n",
    "\n",
    "print('consecutive pairs:', len(pair_df))\n",
    "display(pair_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: image loading, preprocess, intrinsics\n",
    "_IMAGE_CACHE: Dict[Tuple[int, Optional[int]], Tuple[np.ndarray, float]] = {}\n",
    "\n",
    "\n",
    "def resolve_train_image_path(image_id: int) -> Path:\n",
    "    stems = [f'{int(image_id):04d}', str(int(image_id))]\n",
    "    exts = ['.JPG', '.jpg', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "    for st in stems:\n",
    "        for ext in exts:\n",
    "            p = TRAIN_IMG_DIR / f'{st}{ext}'\n",
    "            if p.exists():\n",
    "                return p\n",
    "    raise FileNotFoundError(f'Image not found for id={image_id} in {TRAIN_IMG_DIR}')\n",
    "\n",
    "\n",
    "def load_train_image_cached(image_id: int, max_side: Optional[int]) -> Tuple[np.ndarray, float]:\n",
    "    key = (int(image_id), max_side)\n",
    "    if key in _IMAGE_CACHE:\n",
    "        return _IMAGE_CACHE[key]\n",
    "\n",
    "    p = resolve_train_image_path(int(image_id))\n",
    "    bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise RuntimeError(f'Cannot read image: {p}')\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    scale = 1.0\n",
    "    if max_side is not None:\n",
    "        h, w = rgb.shape[:2]\n",
    "        m = max(h, w)\n",
    "        if m > int(max_side):\n",
    "            scale = float(max_side) / float(m)\n",
    "            nw = max(32, int(round(w * scale)))\n",
    "            nh = max(32, int(round(h * scale)))\n",
    "            rgb = cv2.resize(rgb, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    _IMAGE_CACHE[key] = (rgb, scale)\n",
    "    return rgb, scale\n",
    "\n",
    "\n",
    "def preprocess_for_sift(img_rgb: np.ndarray, mode: str = 'gray_clahe') -> np.ndarray:\n",
    "    g = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    if mode == 'gray':\n",
    "        return g\n",
    "    if mode == 'gray_clahe':\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "        return clahe.apply(g)\n",
    "    if mode == 'gray_denoise_clahe':\n",
    "        g2 = cv2.bilateralFilter(g, d=7, sigmaColor=45, sigmaSpace=45)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "        return clahe.apply(g2)\n",
    "    raise KeyError(f'Unknown preprocess mode: {mode}')\n",
    "\n",
    "\n",
    "def scaled_K(cam_row: pd.Series, image_scale: float) -> np.ndarray:\n",
    "    fx = float(cam_row['fx']) * float(image_scale)\n",
    "    fy = float(cam_row['fy']) * float(image_scale)\n",
    "    cx = float(cam_row['cx']) * float(image_scale)\n",
    "    cy = float(cam_row['cy']) * float(image_scale)\n",
    "    return np.array([[fx, 0.0, cx], [0.0, fy, cy], [0.0, 0.0, 1.0]], dtype=np.float64)\n",
    "\n",
    "\n",
    "def select_pair_row(pair_df: pd.DataFrame, anchor_id: int, val_id: int, fallback_idx: int = 0) -> pd.Series:\n",
    "    sel = pair_df[\n",
    "        (pair_df['anchor_id'].astype(int) == int(anchor_id)) &\n",
    "        (pair_df['val_id'].astype(int) == int(val_id))\n",
    "    ]\n",
    "    if len(sel) > 0:\n",
    "        return sel.iloc[0]\n",
    "    idx = int(np.clip(fallback_idx, 0, len(pair_df) - 1))\n",
    "    print(f'Pair {anchor_id}->{val_id} not found, fallback index {idx}.')\n",
    "    return pair_df.iloc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-focus masks (less grass, more structure)\n",
    "def _ensure_gray_u8(gray: np.ndarray) -> np.ndarray:\n",
    "    if gray.dtype == np.uint8:\n",
    "        return gray\n",
    "    return np.clip(gray, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def compute_green_mask(\n",
    "    img_rgb: np.ndarray,\n",
    "    h_low: int = 30,\n",
    "    h_high: int = 100,\n",
    "    s_min: int = 35,\n",
    "    v_min: int = 25,\n",
    ") -> np.ndarray:\n",
    "    hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
    "    lo = np.array([int(h_low), int(s_min), int(v_min)], dtype=np.uint8)\n",
    "    hi = np.array([int(h_high), 255, 255], dtype=np.uint8)\n",
    "    return cv2.inRange(hsv, lo, hi)\n",
    "\n",
    "\n",
    "def _draw_hough_line_mask(edges: np.ndarray, threshold: int, min_line_len: int, max_line_gap: int, thickness: int) -> np.ndarray:\n",
    "    line_mask = np.zeros_like(edges, dtype=np.uint8)\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges,\n",
    "        rho=1,\n",
    "        theta=np.pi / 180.0,\n",
    "        threshold=int(threshold),\n",
    "        minLineLength=int(min_line_len),\n",
    "        maxLineGap=int(max_line_gap),\n",
    "    )\n",
    "    if lines is not None:\n",
    "        for ln in lines:\n",
    "            x1, y1, x2, y2 = ln[0]\n",
    "            cv2.line(line_mask, (int(x1), int(y1)), (int(x2), int(y2)), 255, int(thickness), cv2.LINE_AA)\n",
    "    return line_mask\n",
    "\n",
    "\n",
    "def _draw_corner_mask(gray_u8: np.ndarray, max_corners: int, quality: float, min_dist: float, radius: int) -> np.ndarray:\n",
    "    corner_mask = np.zeros_like(gray_u8, dtype=np.uint8)\n",
    "    corners = cv2.goodFeaturesToTrack(\n",
    "        gray_u8,\n",
    "        maxCorners=int(max_corners),\n",
    "        qualityLevel=float(quality),\n",
    "        minDistance=float(min_dist),\n",
    "        useHarrisDetector=False,\n",
    "    )\n",
    "    if corners is not None:\n",
    "        for c in corners.reshape(-1, 2):\n",
    "            x = int(round(float(c[0])))\n",
    "            y = int(round(float(c[1])))\n",
    "            cv2.circle(corner_mask, (x, y), int(radius), 255, -1, cv2.LINE_AA)\n",
    "    return corner_mask\n",
    "\n",
    "\n",
    "def build_feature_focus_mask(\n",
    "    img_rgb: np.ndarray,\n",
    "    gray: np.ndarray,\n",
    "    profile: str,\n",
    "    params: Optional[Dict[str, float]] = None,\n",
    ") -> Tuple[np.ndarray, Dict[str, float], np.ndarray]:\n",
    "    p = dict(params or {})\n",
    "    gray_u8 = _ensure_gray_u8(gray)\n",
    "\n",
    "    full = np.full_like(gray_u8, 255, dtype=np.uint8)\n",
    "    green = compute_green_mask(\n",
    "        img_rgb,\n",
    "        h_low=int(p.get('green_h_low', 30)),\n",
    "        h_high=int(p.get('green_h_high', 100)),\n",
    "        s_min=int(p.get('green_s_min', 35)),\n",
    "        v_min=int(p.get('green_v_min', 25)),\n",
    "    )\n",
    "    nongreen = cv2.bitwise_not(green)\n",
    "\n",
    "    k_open = int(max(1, p.get('nongreen_open', 3)))\n",
    "    k_close = int(max(1, p.get('nongreen_close', 5)))\n",
    "    nongreen = cv2.morphologyEx(nongreen, cv2.MORPH_OPEN, np.ones((k_open, k_open), np.uint8))\n",
    "    nongreen = cv2.morphologyEx(nongreen, cv2.MORPH_CLOSE, np.ones((k_close, k_close), np.uint8))\n",
    "\n",
    "    canny_low = int(p.get('canny_low', 70))\n",
    "    canny_high = int(p.get('canny_high', 170))\n",
    "    edges = cv2.Canny(gray_u8, canny_low, canny_high)\n",
    "\n",
    "    edge_dilate = int(max(1, p.get('edge_dilate', 2)))\n",
    "    if edge_dilate > 1:\n",
    "        edges = cv2.dilate(edges, np.ones((edge_dilate, edge_dilate), np.uint8), iterations=1)\n",
    "\n",
    "    line_mask = _draw_hough_line_mask(\n",
    "        edges=edges,\n",
    "        threshold=int(p.get('line_threshold', 65)),\n",
    "        min_line_len=int(p.get('line_min_len', 60)),\n",
    "        max_line_gap=int(p.get('line_max_gap', 8)),\n",
    "        thickness=int(p.get('line_thickness', 2)),\n",
    "    )\n",
    "    corner_mask = _draw_corner_mask(\n",
    "        gray_u8=gray_u8,\n",
    "        max_corners=int(p.get('corner_max', 1200)),\n",
    "        quality=float(p.get('corner_quality', 0.010)),\n",
    "        min_dist=float(p.get('corner_min_dist', 6.0)),\n",
    "        radius=int(p.get('corner_radius', 2)),\n",
    "    )\n",
    "\n",
    "    line_dilate = int(max(1, p.get('line_dilate', 2)))\n",
    "    corner_dilate = int(max(1, p.get('corner_dilate', 2)))\n",
    "    if line_dilate > 1:\n",
    "        line_mask = cv2.dilate(line_mask, np.ones((line_dilate, line_dilate), np.uint8), iterations=1)\n",
    "    if corner_dilate > 1:\n",
    "        corner_mask = cv2.dilate(corner_mask, np.ones((corner_dilate, corner_dilate), np.uint8), iterations=1)\n",
    "\n",
    "    structure = cv2.bitwise_or(edges, line_mask)\n",
    "    structure = cv2.bitwise_or(structure, corner_mask)\n",
    "\n",
    "    profile = str(profile).strip().lower()\n",
    "    if profile == 'none':\n",
    "        mask = full\n",
    "    elif profile == 'nongreen':\n",
    "        mask = nongreen\n",
    "    elif profile == 'edge_corner_mild':\n",
    "        mask = cv2.bitwise_and(nongreen, cv2.dilate(structure, np.ones((3, 3), np.uint8), iterations=1))\n",
    "        mask = cv2.bitwise_or(mask, line_mask)\n",
    "        mask = cv2.bitwise_or(mask, corner_mask)\n",
    "    elif profile == 'edge_corner_strict':\n",
    "        mask = cv2.bitwise_and(nongreen, structure)\n",
    "        mask = cv2.bitwise_or(mask, cv2.bitwise_and(line_mask, nongreen))\n",
    "        mask = cv2.bitwise_or(mask, cv2.bitwise_and(corner_mask, nongreen))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    elif profile == 'line_corner_only':\n",
    "        mask = cv2.bitwise_or(line_mask, corner_mask)\n",
    "    else:\n",
    "        raise KeyError(f'Unknown mask profile: {profile}')\n",
    "\n",
    "    final_close = int(max(1, p.get('final_close', 3)))\n",
    "    if final_close > 1:\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((final_close, final_close), np.uint8))\n",
    "\n",
    "    min_cov = float(p.get('min_coverage', 0.03))\n",
    "    cov = float((mask > 0).mean())\n",
    "    fallback = 0.0\n",
    "    if cov < min_cov:\n",
    "        mask = nongreen.copy()\n",
    "        cov = float((mask > 0).mean())\n",
    "        fallback = 1.0\n",
    "\n",
    "    diag = {\n",
    "        'mask_cov': cov,\n",
    "        'green_cov': float((green > 0).mean()),\n",
    "        'edge_cov': float((edges > 0).mean()),\n",
    "        'line_cov': float((line_mask > 0).mean()),\n",
    "        'corner_cov': float((corner_mask > 0).mean()),\n",
    "        'fallback': fallback,\n",
    "    }\n",
    "    return mask.astype(np.uint8), diag, green.astype(np.uint8)\n",
    "\n",
    "\n",
    "def _mask_tint(gray: np.ndarray, mask: np.ndarray) -> np.ndarray:\n",
    "    base = cv2.cvtColor(_ensure_gray_u8(gray), cv2.COLOR_GRAY2RGB)\n",
    "    vis = base.copy()\n",
    "    blocked = mask <= 0\n",
    "    if np.any(blocked):\n",
    "        red = np.array([255, 45, 45], dtype=np.uint8)\n",
    "        vis[blocked] = (0.35 * vis[blocked] + 0.65 * red).astype(np.uint8)\n",
    "    return vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT extraction + matching (RootSIFT, corner-guided, grid-select)\n",
    "def rootsift(desc: Optional[np.ndarray], eps: float = 1e-12) -> Optional[np.ndarray]:\n",
    "    if desc is None:\n",
    "        return None\n",
    "    desc = desc.astype(np.float32)\n",
    "    desc /= (np.sum(np.abs(desc), axis=1, keepdims=True) + eps)\n",
    "    desc = np.sqrt(np.clip(desc, 0.0, None))\n",
    "    return desc\n",
    "\n",
    "\n",
    "def grid_select_keypoints(\n",
    "    kps: List[cv2.KeyPoint],\n",
    "    desc: np.ndarray,\n",
    "    img_shape: Tuple[int, int],\n",
    "    grid_shape: Tuple[int, int] = (8, 8),\n",
    "    per_cell: int = 200,\n",
    ") -> Tuple[List[cv2.KeyPoint], np.ndarray]:\n",
    "    if len(kps) == 0 or desc is None or len(desc) == 0:\n",
    "        return [], np.zeros((0, 128), dtype=np.float32)\n",
    "\n",
    "    h, w = img_shape[:2]\n",
    "    gy, gx = int(grid_shape[0]), int(grid_shape[1])\n",
    "    cell_w, cell_h = max(1.0, w / gx), max(1.0, h / gy)\n",
    "\n",
    "    buckets = [[[] for _ in range(gx)] for _ in range(gy)]\n",
    "    for i, kp in enumerate(kps):\n",
    "        x, y = kp.pt\n",
    "        cx = min(gx - 1, int(x / cell_w))\n",
    "        cy = min(gy - 1, int(y / cell_h))\n",
    "        buckets[cy][cx].append((float(kp.response), i))\n",
    "\n",
    "    keep_idx: List[int] = []\n",
    "    for cy in range(gy):\n",
    "        for cx in range(gx):\n",
    "            buckets[cy][cx].sort(key=lambda t: t[0], reverse=True)\n",
    "            keep_idx.extend([i for _, i in buckets[cy][cx][:int(per_cell)]])\n",
    "\n",
    "    if len(keep_idx) == 0:\n",
    "        return [], np.zeros((0, desc.shape[1]), dtype=desc.dtype)\n",
    "\n",
    "    keep_idx_arr = np.array(keep_idx, dtype=np.int32)\n",
    "    kps_sel = [kps[int(i)] for i in keep_idx_arr]\n",
    "    desc_sel = desc[keep_idx_arr]\n",
    "    return kps_sel, desc_sel\n",
    "\n",
    "\n",
    "def make_corner_keypoints(\n",
    "    gray: np.ndarray,\n",
    "    mask: Optional[np.ndarray],\n",
    "    max_corners: int,\n",
    "    quality_level: float,\n",
    "    min_distance: float,\n",
    "    block_size: int,\n",
    "    use_harris: bool,\n",
    "    kp_size: float,\n",
    ") -> List[cv2.KeyPoint]:\n",
    "    corners = cv2.goodFeaturesToTrack(\n",
    "        gray,\n",
    "        maxCorners=int(max_corners),\n",
    "        qualityLevel=float(quality_level),\n",
    "        minDistance=float(min_distance),\n",
    "        mask=mask,\n",
    "        blockSize=int(block_size),\n",
    "        useHarrisDetector=bool(use_harris),\n",
    "    )\n",
    "    if corners is None:\n",
    "        return []\n",
    "    out: List[cv2.KeyPoint] = []\n",
    "    for c in corners.reshape(-1, 2):\n",
    "        out.append(cv2.KeyPoint(float(c[0]), float(c[1]), float(kp_size)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_sift_features(gray: np.ndarray, mask: Optional[np.ndarray], cfg: Dict[str, object]) -> Tuple[List[cv2.KeyPoint], Optional[np.ndarray]]:\n",
    "    sift = cv2.SIFT_create(\n",
    "        nfeatures=int(cfg.get('nfeatures', 9000)),\n",
    "        contrastThreshold=float(cfg.get('contrast_thr', 0.03)),\n",
    "        edgeThreshold=float(cfg.get('edge_thr', 12.0)),\n",
    "        sigma=float(cfg.get('sigma', 1.6)),\n",
    "    )\n",
    "\n",
    "    use_corner_guided = bool(cfg.get('use_corner_guided', False))\n",
    "    if use_corner_guided:\n",
    "        guided_kps = make_corner_keypoints(\n",
    "            gray=gray,\n",
    "            mask=mask,\n",
    "            max_corners=int(cfg.get('corner_max', 6000)),\n",
    "            quality_level=float(cfg.get('corner_quality', 0.01)),\n",
    "            min_distance=float(cfg.get('corner_min_dist', 6.0)),\n",
    "            block_size=int(cfg.get('corner_block_size', 7)),\n",
    "            use_harris=bool(cfg.get('corner_use_harris', False)),\n",
    "            kp_size=float(cfg.get('corner_kp_size', 16.0)),\n",
    "        )\n",
    "        if len(guided_kps) == 0:\n",
    "            return [], None\n",
    "        kps, desc = sift.compute(gray, guided_kps)\n",
    "    else:\n",
    "        kps, desc = sift.detectAndCompute(gray, mask)\n",
    "\n",
    "    if desc is None or kps is None or len(kps) == 0:\n",
    "        return [], None\n",
    "\n",
    "    if bool(cfg.get('use_rootsift', True)):\n",
    "        desc = rootsift(desc)\n",
    "\n",
    "    if bool(cfg.get('use_grid_selection', False)):\n",
    "        kps, desc = grid_select_keypoints(\n",
    "            kps=kps,\n",
    "            desc=desc,\n",
    "            img_shape=gray.shape,\n",
    "            grid_shape=tuple(cfg.get('grid_shape', (8, 8))),\n",
    "            per_cell=int(cfg.get('grid_per_cell', 180)),\n",
    "        )\n",
    "\n",
    "    return kps, desc\n",
    "\n",
    "\n",
    "def knn_ratio_matches(desc0: np.ndarray, desc1: np.ndarray, ratio: float = 0.75) -> List[cv2.DMatch]:\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    knn = bf.knnMatch(desc0, desc1, k=2)\n",
    "    good: List[cv2.DMatch] = []\n",
    "    for pair in knn:\n",
    "        if len(pair) < 2:\n",
    "            continue\n",
    "        m, n = pair\n",
    "        if m.distance < float(ratio) * n.distance:\n",
    "            good.append(m)\n",
    "    return good\n",
    "\n",
    "\n",
    "def mutual_filter(matches_01: List[cv2.DMatch], matches_10: List[cv2.DMatch]) -> List[cv2.DMatch]:\n",
    "    map_01 = {(int(m.queryIdx), int(m.trainIdx)): m for m in matches_01}\n",
    "    mutual: List[cv2.DMatch] = []\n",
    "    for m in matches_10:\n",
    "        key = (int(m.trainIdx), int(m.queryIdx))\n",
    "        if key in map_01:\n",
    "            mutual.append(map_01[key])\n",
    "    return mutual\n",
    "\n",
    "\n",
    "def match_descriptors(desc0: Optional[np.ndarray], desc1: Optional[np.ndarray], ratio: float, mutual: bool) -> List[cv2.DMatch]:\n",
    "    if desc0 is None or desc1 is None or len(desc0) < 2 or len(desc1) < 2:\n",
    "        return []\n",
    "    m01 = knn_ratio_matches(desc0, desc1, ratio=float(ratio))\n",
    "    if not bool(mutual):\n",
    "        return m01\n",
    "    m10 = knn_ratio_matches(desc1, desc0, ratio=float(ratio))\n",
    "    return mutual_filter(m01, m10)\n",
    "\n",
    "\n",
    "def matches_to_points(kps0: List[cv2.KeyPoint], kps1: List[cv2.KeyPoint], matches: List[cv2.DMatch]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    if len(matches) == 0:\n",
    "        return (\n",
    "            np.zeros((0, 2), dtype=np.float32),\n",
    "            np.zeros((0, 2), dtype=np.float32),\n",
    "            np.zeros((0,), dtype=np.float32),\n",
    "            np.zeros((0,), dtype=np.float32),\n",
    "        )\n",
    "    pts0 = np.array([kps0[m.queryIdx].pt for m in matches], dtype=np.float32)\n",
    "    pts1 = np.array([kps1[m.trainIdx].pt for m in matches], dtype=np.float32)\n",
    "    s0 = np.array([kps0[m.queryIdx].size for m in matches], dtype=np.float32)\n",
    "    s1 = np.array([kps1[m.trainIdx].size for m in matches], dtype=np.float32)\n",
    "    return pts0, pts1, s0, s1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry + result structure\n",
    "def rotation_matrix_to_euler_zyx(R: np.ndarray) -> Tuple[float, float, float]:\n",
    "    sy = float(np.sqrt(R[0, 0] ** 2 + R[1, 0] ** 2))\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        yaw = np.arctan2(R[1, 0], R[0, 0])\n",
    "        pitch = np.arctan2(-R[2, 0], sy)\n",
    "        roll = np.arctan2(R[2, 1], R[2, 2])\n",
    "    else:\n",
    "        yaw = np.arctan2(-R[0, 1], R[1, 1])\n",
    "        pitch = np.arctan2(-R[2, 0], sy)\n",
    "        roll = 0.0\n",
    "    return float(np.degrees(yaw)), float(np.degrees(pitch)), float(np.degrees(roll))\n",
    "\n",
    "\n",
    "def affine_transform_points(M: np.ndarray, pts: np.ndarray) -> np.ndarray:\n",
    "    if pts.shape[0] == 0:\n",
    "        return pts.copy()\n",
    "    ones = np.ones((pts.shape[0], 1), dtype=np.float32)\n",
    "    p = np.hstack([pts.astype(np.float32), ones])\n",
    "    q = (M @ p.T).T\n",
    "    return q.astype(np.float32)\n",
    "\n",
    "\n",
    "def estimate_affine_partial(pts0: np.ndarray, pts1: np.ndarray, thr_px: float) -> Tuple[Optional[np.ndarray], np.ndarray]:\n",
    "    if pts0.shape[0] < 3:\n",
    "        return None, np.zeros((pts0.shape[0],), dtype=bool)\n",
    "    M, inl = cv2.estimateAffinePartial2D(\n",
    "        pts1,\n",
    "        pts0,\n",
    "        method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=float(thr_px),\n",
    "        maxIters=20000,\n",
    "        confidence=0.999,\n",
    "        refineIters=50,\n",
    "    )\n",
    "    if inl is None:\n",
    "        return M, np.zeros((pts0.shape[0],), dtype=bool)\n",
    "    return M, inl.ravel().astype(bool)\n",
    "\n",
    "\n",
    "def estimate_homography(pts0: np.ndarray, pts1: np.ndarray, thr_px: float) -> Tuple[Optional[np.ndarray], np.ndarray]:\n",
    "    if pts0.shape[0] < 4:\n",
    "        return None, np.zeros((pts0.shape[0],), dtype=bool)\n",
    "    method = cv2.USAC_MAGSAC if hasattr(cv2, 'USAC_MAGSAC') else cv2.RANSAC\n",
    "    H, inl = cv2.findHomography(\n",
    "        pts1,\n",
    "        pts0,\n",
    "        method=method,\n",
    "        ransacReprojThreshold=float(thr_px),\n",
    "        maxIters=20000,\n",
    "        confidence=0.999,\n",
    "    )\n",
    "    if inl is None:\n",
    "        return H, np.zeros((pts0.shape[0],), dtype=bool)\n",
    "    return H, inl.ravel().astype(bool)\n",
    "\n",
    "\n",
    "def homography_transfer_error(H: Optional[np.ndarray], pts1: np.ndarray, pts0: np.ndarray) -> np.ndarray:\n",
    "    if H is None or pts0.shape[0] == 0:\n",
    "        return np.full((pts0.shape[0],), np.inf, dtype=np.float32)\n",
    "    pts1_h = cv2.convertPointsToHomogeneous(pts1).reshape(-1, 3)\n",
    "    proj = (H @ pts1_h.T).T\n",
    "    denom = np.clip(proj[:, 2:3], 1e-8, None)\n",
    "    proj_xy = proj[:, :2] / denom\n",
    "    err = np.linalg.norm(proj_xy - pts0, axis=1)\n",
    "    return err.astype(np.float32)\n",
    "\n",
    "\n",
    "def guided_filter_by_H(H: Optional[np.ndarray], pts0: np.ndarray, pts1: np.ndarray, max_err_px: float) -> np.ndarray:\n",
    "    if pts0.shape[0] == 0:\n",
    "        return np.zeros((0,), dtype=bool)\n",
    "    if H is None:\n",
    "        return np.ones((pts0.shape[0],), dtype=bool)\n",
    "    err = homography_transfer_error(H, pts1, pts0)\n",
    "    return err < float(max_err_px)\n",
    "\n",
    "\n",
    "def estimate_essential_pose(\n",
    "    pts0: np.ndarray,\n",
    "    pts1: np.ndarray,\n",
    "    K0: np.ndarray,\n",
    "    K1: np.ndarray,\n",
    "    thr_norm: float,\n",
    ") -> Tuple[Optional[np.ndarray], np.ndarray, Optional[np.ndarray], Optional[np.ndarray], np.ndarray]:\n",
    "    if pts0.shape[0] < 8:\n",
    "        n = pts0.shape[0]\n",
    "        return None, np.zeros((n,), dtype=bool), None, None, np.zeros((n,), dtype=bool)\n",
    "\n",
    "    pts0n = cv2.undistortPoints(pts0.reshape(-1, 1, 2), K0, None).reshape(-1, 2)\n",
    "    pts1n = cv2.undistortPoints(pts1.reshape(-1, 1, 2), K1, None).reshape(-1, 2)\n",
    "\n",
    "    E, inl = cv2.findEssentialMat(\n",
    "        pts0n,\n",
    "        pts1n,\n",
    "        cameraMatrix=np.eye(3),\n",
    "        method=cv2.RANSAC,\n",
    "        prob=0.999,\n",
    "        threshold=float(thr_norm),\n",
    "    )\n",
    "\n",
    "    if inl is None:\n",
    "        n = pts0.shape[0]\n",
    "        return E, np.zeros((n,), dtype=bool), None, None, np.zeros((n,), dtype=bool)\n",
    "\n",
    "    inl = inl.ravel().astype(bool)\n",
    "    if np.count_nonzero(inl) < 8 or E is None:\n",
    "        return E, inl, None, None, np.zeros_like(inl)\n",
    "\n",
    "    _, R, t, inl_pose = cv2.recoverPose(\n",
    "        E,\n",
    "        pts0n,\n",
    "        pts1n,\n",
    "        cameraMatrix=np.eye(3),\n",
    "        mask=inl.astype(np.uint8).reshape(-1, 1),\n",
    "    )\n",
    "    if inl_pose is None:\n",
    "        inl_pose = inl.copy().astype(np.uint8).reshape(-1, 1)\n",
    "    return E, inl, R, t.reshape(3), inl_pose.ravel().astype(bool)\n",
    "\n",
    "\n",
    "def _pts_in_mask(mask_u8: np.ndarray, pts: np.ndarray) -> np.ndarray:\n",
    "    if pts.shape[0] == 0:\n",
    "        return np.zeros((0,), dtype=bool)\n",
    "    h, w = mask_u8.shape[:2]\n",
    "    out = np.zeros((pts.shape[0],), dtype=bool)\n",
    "    for i, p in enumerate(pts):\n",
    "        x = int(np.clip(round(float(p[0])), 0, w - 1))\n",
    "        y = int(np.clip(round(float(p[1])), 0, h - 1))\n",
    "        out[i] = bool(mask_u8[y, x] > 0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _kp_green_fraction(kps: List[cv2.KeyPoint], green_mask_u8: np.ndarray) -> float:\n",
    "    if len(kps) == 0:\n",
    "        return np.nan\n",
    "    h, w = green_mask_u8.shape[:2]\n",
    "    c = 0\n",
    "    for kp in kps:\n",
    "        x = int(np.clip(round(float(kp.pt[0])), 0, w - 1))\n",
    "        y = int(np.clip(round(float(kp.pt[1])), 0, h - 1))\n",
    "        if green_mask_u8[y, x] > 0:\n",
    "            c += 1\n",
    "    return 100.0 * float(c) / float(len(kps))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VariantResult:\n",
    "    name: str\n",
    "    preprocess_mode: str\n",
    "    mask_profile: str\n",
    "    gray0: np.ndarray\n",
    "    gray1: np.ndarray\n",
    "    mask0: np.ndarray\n",
    "    mask1: np.ndarray\n",
    "    green0: np.ndarray\n",
    "    green1: np.ndarray\n",
    "    mask_diag0: Dict[str, float]\n",
    "    mask_diag1: Dict[str, float]\n",
    "    keypoints0: List[cv2.KeyPoint]\n",
    "    keypoints1: List[cv2.KeyPoint]\n",
    "    matches: List[cv2.DMatch]\n",
    "    pts0: np.ndarray\n",
    "    pts1: np.ndarray\n",
    "    kp_size0: np.ndarray\n",
    "    kp_size1: np.ndarray\n",
    "    affine_M_1to0: Optional[np.ndarray]\n",
    "    affine_inliers: np.ndarray\n",
    "    affine_rotation_deg: float\n",
    "    affine_tx: float\n",
    "    affine_ty: float\n",
    "    affine_scale: float\n",
    "    affine_rmse: float\n",
    "    H_1to0: Optional[np.ndarray]\n",
    "    homography_inliers: np.ndarray\n",
    "    guided_mask: np.ndarray\n",
    "    sfm_inliers: np.ndarray\n",
    "    sfm_R: Optional[np.ndarray]\n",
    "    sfm_t: Optional[np.ndarray]\n",
    "    sfm_rot_deg: float\n",
    "    sfm_yaw_deg: float\n",
    "    sfm_pitch_deg: float\n",
    "    sfm_roll_deg: float\n",
    "    essential_inliers_raw: np.ndarray\n",
    "    dropped_by_response: int\n",
    "    dropped_by_size_ratio: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e044b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full variant runner\n",
    "def _empty_variant_result(\n",
    "    name: str,\n",
    "    preprocess_mode: str,\n",
    "    mask_profile: str,\n",
    "    gray0: np.ndarray,\n",
    "    gray1: np.ndarray,\n",
    "    mask0: np.ndarray,\n",
    "    mask1: np.ndarray,\n",
    "    green0: np.ndarray,\n",
    "    green1: np.ndarray,\n",
    "    diag0: Dict[str, float],\n",
    "    diag1: Dict[str, float],\n",
    "    keypoints0: Optional[List[cv2.KeyPoint]] = None,\n",
    "    keypoints1: Optional[List[cv2.KeyPoint]] = None,\n",
    ") -> VariantResult:\n",
    "    return VariantResult(\n",
    "        name=name,\n",
    "        preprocess_mode=preprocess_mode,\n",
    "        mask_profile=mask_profile,\n",
    "        gray0=gray0,\n",
    "        gray1=gray1,\n",
    "        mask0=mask0,\n",
    "        mask1=mask1,\n",
    "        green0=green0,\n",
    "        green1=green1,\n",
    "        mask_diag0=diag0,\n",
    "        mask_diag1=diag1,\n",
    "        keypoints0=keypoints0 if keypoints0 is not None else [],\n",
    "        keypoints1=keypoints1 if keypoints1 is not None else [],\n",
    "        matches=[],\n",
    "        pts0=np.zeros((0, 2), dtype=np.float32),\n",
    "        pts1=np.zeros((0, 2), dtype=np.float32),\n",
    "        kp_size0=np.zeros((0,), dtype=np.float32),\n",
    "        kp_size1=np.zeros((0,), dtype=np.float32),\n",
    "        affine_M_1to0=None,\n",
    "        affine_inliers=np.zeros((0,), dtype=bool),\n",
    "        affine_rotation_deg=np.nan,\n",
    "        affine_tx=np.nan,\n",
    "        affine_ty=np.nan,\n",
    "        affine_scale=np.nan,\n",
    "        affine_rmse=np.nan,\n",
    "        H_1to0=None,\n",
    "        homography_inliers=np.zeros((0,), dtype=bool),\n",
    "        guided_mask=np.zeros((0,), dtype=bool),\n",
    "        sfm_inliers=np.zeros((0,), dtype=bool),\n",
    "        sfm_R=None,\n",
    "        sfm_t=None,\n",
    "        sfm_rot_deg=np.nan,\n",
    "        sfm_yaw_deg=np.nan,\n",
    "        sfm_pitch_deg=np.nan,\n",
    "        sfm_roll_deg=np.nan,\n",
    "        essential_inliers_raw=np.zeros((0,), dtype=bool),\n",
    "        dropped_by_response=0,\n",
    "        dropped_by_size_ratio=0,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_sift_corner_variant(\n",
    "    img0_rgb: np.ndarray,\n",
    "    img1_rgb: np.ndarray,\n",
    "    K0: np.ndarray,\n",
    "    K1: np.ndarray,\n",
    "    cfg: Dict[str, object],\n",
    ") -> VariantResult:\n",
    "    name = str(cfg['name'])\n",
    "    preprocess_mode = str(cfg.get('preprocess_mode', PREPROCESS_MODE))\n",
    "    mask_profile = str(cfg.get('mask_profile', 'none'))\n",
    "\n",
    "    gray0 = preprocess_for_sift(img0_rgb, preprocess_mode)\n",
    "    gray1 = preprocess_for_sift(img1_rgb, preprocess_mode)\n",
    "\n",
    "    mask0, diag0, green0 = build_feature_focus_mask(img0_rgb, gray0, mask_profile, cfg.get('mask_params', {}))\n",
    "    mask1, diag1, green1 = build_feature_focus_mask(img1_rgb, gray1, mask_profile, cfg.get('mask_params', {}))\n",
    "\n",
    "    k0, d0 = extract_sift_features(gray0, mask0, cfg)\n",
    "    k1, d1 = extract_sift_features(gray1, mask1, cfg)\n",
    "\n",
    "    if d0 is None or d1 is None or len(k0) == 0 or len(k1) == 0:\n",
    "        return _empty_variant_result(name, preprocess_mode, mask_profile, gray0, gray1, mask0, mask1, green0, green1, diag0, diag1, k0, k1)\n",
    "\n",
    "    ratio = float(cfg.get('ratio_thr', 0.78))\n",
    "    mutual = bool(cfg.get('mutual_check', False))\n",
    "    matches = match_descriptors(d0, d1, ratio=ratio, mutual=mutual)\n",
    "\n",
    "    if len(matches) == 0:\n",
    "        return _empty_variant_result(name, preprocess_mode, mask_profile, gray0, gray1, mask0, mask1, green0, green1, diag0, diag1, k0, k1)\n",
    "\n",
    "    pts0, pts1, s0, s1 = matches_to_points(k0, k1, matches)\n",
    "\n",
    "    kp_response_min = float(cfg.get('kp_response_min', 0.0))\n",
    "    size_ratio_min = float(cfg.get('size_ratio_min', 0.0))\n",
    "    size_ratio_max = float(cfg.get('size_ratio_max', 99.0))\n",
    "\n",
    "    keep = np.ones((pts0.shape[0],), dtype=bool)\n",
    "    dropped_resp = 0\n",
    "    dropped_size = 0\n",
    "    for i, m in enumerate(matches):\n",
    "        if not keep[i]:\n",
    "            continue\n",
    "        r0 = float(k0[m.queryIdx].response)\n",
    "        r1 = float(k1[m.trainIdx].response)\n",
    "        if min(r0, r1) < kp_response_min:\n",
    "            keep[i] = False\n",
    "            dropped_resp += 1\n",
    "            continue\n",
    "        sr = (float(k1[m.trainIdx].size) + 1e-6) / (float(k0[m.queryIdx].size) + 1e-6)\n",
    "        if sr < size_ratio_min or sr > size_ratio_max:\n",
    "            keep[i] = False\n",
    "            dropped_size += 1\n",
    "\n",
    "    if not np.any(keep):\n",
    "        out = _empty_variant_result(name, preprocess_mode, mask_profile, gray0, gray1, mask0, mask1, green0, green1, diag0, diag1, k0, k1)\n",
    "        out.dropped_by_response = dropped_resp\n",
    "        out.dropped_by_size_ratio = dropped_size\n",
    "        return out\n",
    "\n",
    "    matches = [m for i, m in enumerate(matches) if keep[i]]\n",
    "    pts0 = pts0[keep]\n",
    "    pts1 = pts1[keep]\n",
    "    s0 = s0[keep]\n",
    "    s1 = s1[keep]\n",
    "\n",
    "    M, inl_aff = estimate_affine_partial(pts0, pts1, thr_px=float(cfg.get('affine_thr', AFFINE_RANSAC_THR)))\n",
    "    H, inl_h = estimate_homography(pts0, pts1, thr_px=float(cfg.get('homography_thr', HOMOGRAPHY_RANSAC_THR)))\n",
    "\n",
    "    if M is not None and inl_aff.size > 0:\n",
    "        rot_deg = float(np.degrees(np.arctan2(M[1, 0], M[0, 0])))\n",
    "        scale = float(np.sqrt(M[0, 0] ** 2 + M[1, 0] ** 2))\n",
    "        tx = float(M[0, 2])\n",
    "        ty = float(M[1, 2])\n",
    "\n",
    "        p1w = affine_transform_points(M, pts1)\n",
    "        if np.any(inl_aff):\n",
    "            err = np.linalg.norm(pts0[inl_aff] - p1w[inl_aff], axis=1)\n",
    "            rmse = float(np.sqrt(np.mean(err ** 2)))\n",
    "        else:\n",
    "            rmse = np.nan\n",
    "    else:\n",
    "        rot_deg = np.nan\n",
    "        scale = np.nan\n",
    "        tx = np.nan\n",
    "        ty = np.nan\n",
    "        rmse = np.nan\n",
    "\n",
    "    guided_mask = guided_filter_by_H(H, pts0, pts1, max_err_px=float(cfg.get('h_guide_err_px', H_GUIDE_ERR_PX)))\n",
    "    pts0_g = pts0[guided_mask]\n",
    "    pts1_g = pts1[guided_mask]\n",
    "\n",
    "    _, inl_e_raw, _, _, _ = estimate_essential_pose(\n",
    "        pts0=pts0,\n",
    "        pts1=pts1,\n",
    "        K0=K0,\n",
    "        K1=K1,\n",
    "        thr_norm=float(cfg.get('essential_thr', ESSENTIAL_RANSAC_THR)),\n",
    "    )\n",
    "\n",
    "    _, inl_e, R, t, inl_pose = estimate_essential_pose(\n",
    "        pts0=pts0_g,\n",
    "        pts1=pts1_g,\n",
    "        K0=K0,\n",
    "        K1=K1,\n",
    "        thr_norm=float(cfg.get('essential_thr', ESSENTIAL_RANSAC_THR)),\n",
    "    )\n",
    "\n",
    "    sfm_rot = np.nan\n",
    "    sfm_yaw = np.nan\n",
    "    sfm_pitch = np.nan\n",
    "    sfm_roll = np.nan\n",
    "    if R is not None:\n",
    "        rvec, _ = cv2.Rodrigues(R)\n",
    "        sfm_rot = float(np.linalg.norm(rvec) * 180.0 / np.pi)\n",
    "        sfm_yaw, sfm_pitch, sfm_roll = rotation_matrix_to_euler_zyx(R)\n",
    "\n",
    "    return VariantResult(\n",
    "        name=name,\n",
    "        preprocess_mode=preprocess_mode,\n",
    "        mask_profile=mask_profile,\n",
    "        gray0=gray0,\n",
    "        gray1=gray1,\n",
    "        mask0=mask0,\n",
    "        mask1=mask1,\n",
    "        green0=green0,\n",
    "        green1=green1,\n",
    "        mask_diag0=diag0,\n",
    "        mask_diag1=diag1,\n",
    "        keypoints0=k0,\n",
    "        keypoints1=k1,\n",
    "        matches=matches,\n",
    "        pts0=pts0,\n",
    "        pts1=pts1,\n",
    "        kp_size0=s0,\n",
    "        kp_size1=s1,\n",
    "        affine_M_1to0=M,\n",
    "        affine_inliers=inl_aff,\n",
    "        affine_rotation_deg=rot_deg,\n",
    "        affine_tx=tx,\n",
    "        affine_ty=ty,\n",
    "        affine_scale=scale,\n",
    "        affine_rmse=rmse,\n",
    "        H_1to0=H,\n",
    "        homography_inliers=inl_h,\n",
    "        guided_mask=guided_mask,\n",
    "        sfm_inliers=inl_pose,\n",
    "        sfm_R=R,\n",
    "        sfm_t=t,\n",
    "        sfm_rot_deg=sfm_rot,\n",
    "        sfm_yaw_deg=sfm_yaw,\n",
    "        sfm_pitch_deg=sfm_pitch,\n",
    "        sfm_roll_deg=sfm_roll,\n",
    "        essential_inliers_raw=inl_e_raw,\n",
    "        dropped_by_response=int(dropped_resp),\n",
    "        dropped_by_size_ratio=int(dropped_size),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f44ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair data preparation\n",
    "pair_row = select_pair_row(pair_df, PAIR_ANCHOR_ID, PAIR_VAL_ID, PREVIEW_PAIR_INDEX)\n",
    "anchor_id = int(pair_row['anchor_id'])\n",
    "val_id = int(pair_row['val_id'])\n",
    "\n",
    "r0 = train_df[train_df['id'].astype(int) == anchor_id].iloc[0]\n",
    "r1 = train_df[train_df['id'].astype(int) == val_id].iloc[0]\n",
    "\n",
    "img0_rgb, scale0 = load_train_image_cached(anchor_id, max_side=IMAGE_MAX_SIDE)\n",
    "img1_rgb, scale1 = load_train_image_cached(val_id, max_side=IMAGE_MAX_SIDE)\n",
    "\n",
    "K0 = scaled_K(r0, scale0)\n",
    "K1 = scaled_K(r1, scale1)\n",
    "\n",
    "gt0 = np.array([float(r0['x_pixel']) * scale0, float(r0['y_pixel']) * scale0], dtype=np.float64)\n",
    "gt1 = np.array([float(r1['x_pixel']) * scale1, float(r1['y_pixel']) * scale1], dtype=np.float64)\n",
    "gt_d = gt1 - gt0\n",
    "\n",
    "print(f'pair: {anchor_id}->{val_id}')\n",
    "print('img0:', img0_rgb.shape, 'scale0:', round(scale0, 4))\n",
    "print('img1:', img1_rgb.shape, 'scale1:', round(scale1, 4))\n",
    "print('GT delta (val-anchor):', np.round(gt_d, 2))\n",
    "\n",
    "prev0 = preprocess_for_sift(img0_rgb, PREPROCESS_MODE)\n",
    "prev1 = preprocess_for_sift(img1_rgb, PREPROCESS_MODE)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "axes[0].imshow(prev0, cmap='gray')\n",
    "axes[0].set_title(f'Anchor preprocessed | id={anchor_id}')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(prev1, cmap='gray')\n",
    "axes[1].set_title(f'Validation preprocessed | id={val_id}')\n",
    "axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abcbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variant grid and run (Notebook-12 baseline + Notebook-14 ideas)\n",
    "VARIANTS = [\n",
    "    {\n",
    "        'name': 'baseline_balanced',\n",
    "        'preprocess_mode': 'gray_clahe',\n",
    "        'mask_profile': 'none',\n",
    "        'nfeatures': 9000,\n",
    "        'contrast_thr': 0.03,\n",
    "        'edge_thr': 12,\n",
    "        'sigma': 1.6,\n",
    "        'ratio_thr': 0.78,\n",
    "        'mutual_check': False,\n",
    "        'use_rootsift': False,\n",
    "        'use_corner_guided': False,\n",
    "        'use_grid_selection': False,\n",
    "        'kp_response_min': 0.0,\n",
    "        'size_ratio_min': 0.0,\n",
    "        'size_ratio_max': 99.0,\n",
    "        'essential_thr': ESSENTIAL_RANSAC_THR,\n",
    "        'h_guide_err_px': H_GUIDE_ERR_PX,\n",
    "        'mask_params': {},\n",
    "    },\n",
    "    {\n",
    "        'name': 'rootsift_nongreen_mutual',\n",
    "        'preprocess_mode': 'gray_clahe',\n",
    "        'mask_profile': 'nongreen',\n",
    "        'nfeatures': 9000,\n",
    "        'contrast_thr': 0.04,\n",
    "        'edge_thr': 12,\n",
    "        'sigma': 1.6,\n",
    "        'ratio_thr': 0.76,\n",
    "        'mutual_check': True,\n",
    "        'use_rootsift': True,\n",
    "        'use_corner_guided': False,\n",
    "        'use_grid_selection': True,\n",
    "        'grid_shape': (8, 8),\n",
    "        'grid_per_cell': 180,\n",
    "        'kp_response_min': 0.010,\n",
    "        'size_ratio_min': 0.45,\n",
    "        'size_ratio_max': 2.40,\n",
    "        'essential_thr': ESSENTIAL_RANSAC_THR,\n",
    "        'h_guide_err_px': H_GUIDE_ERR_PX,\n",
    "        'mask_params': {\n",
    "            'green_h_low': 30,\n",
    "            'green_h_high': 100,\n",
    "            'green_s_min': 35,\n",
    "            'green_v_min': 25,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'corner_guided_edge_mild',\n",
    "        'preprocess_mode': 'gray_denoise_clahe',\n",
    "        'mask_profile': 'edge_corner_mild',\n",
    "        'nfeatures': 9500,\n",
    "        'contrast_thr': 0.045,\n",
    "        'edge_thr': 16,\n",
    "        'sigma': 1.6,\n",
    "        'ratio_thr': 0.75,\n",
    "        'mutual_check': True,\n",
    "        'use_rootsift': True,\n",
    "        'use_corner_guided': True,\n",
    "        'corner_max': 7000,\n",
    "        'corner_quality': 0.01,\n",
    "        'corner_min_dist': 6.0,\n",
    "        'corner_block_size': 7,\n",
    "        'corner_use_harris': False,\n",
    "        'corner_kp_size': 16.0,\n",
    "        'use_grid_selection': True,\n",
    "        'grid_shape': (8, 8),\n",
    "        'grid_per_cell': 180,\n",
    "        'kp_response_min': 0.010,\n",
    "        'size_ratio_min': 0.45,\n",
    "        'size_ratio_max': 2.20,\n",
    "        'essential_thr': ESSENTIAL_RANSAC_THR,\n",
    "        'h_guide_err_px': H_GUIDE_ERR_PX,\n",
    "        'mask_params': {\n",
    "            'canny_low': 70,\n",
    "            'canny_high': 170,\n",
    "            'line_threshold': 60,\n",
    "            'line_min_len': 55,\n",
    "            'line_max_gap': 8,\n",
    "            'corner_max': 1200,\n",
    "            'corner_quality': 0.010,\n",
    "            'corner_min_dist': 6,\n",
    "            'min_coverage': 0.04,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'corner_guided_edge_strict',\n",
    "        'preprocess_mode': 'gray_denoise_clahe',\n",
    "        'mask_profile': 'edge_corner_strict',\n",
    "        'nfeatures': 8000,\n",
    "        'contrast_thr': 0.055,\n",
    "        'edge_thr': 20,\n",
    "        'sigma': 1.6,\n",
    "        'ratio_thr': 0.72,\n",
    "        'mutual_check': True,\n",
    "        'use_rootsift': True,\n",
    "        'use_corner_guided': True,\n",
    "        'corner_max': 6000,\n",
    "        'corner_quality': 0.012,\n",
    "        'corner_min_dist': 7.0,\n",
    "        'corner_block_size': 7,\n",
    "        'corner_use_harris': False,\n",
    "        'corner_kp_size': 16.0,\n",
    "        'use_grid_selection': True,\n",
    "        'grid_shape': (8, 8),\n",
    "        'grid_per_cell': 160,\n",
    "        'kp_response_min': 0.015,\n",
    "        'size_ratio_min': 0.55,\n",
    "        'size_ratio_max': 1.90,\n",
    "        'essential_thr': ESSENTIAL_RANSAC_THR,\n",
    "        'h_guide_err_px': H_GUIDE_ERR_PX,\n",
    "        'mask_params': {\n",
    "            'canny_low': 80,\n",
    "            'canny_high': 190,\n",
    "            'line_threshold': 72,\n",
    "            'line_min_len': 68,\n",
    "            'line_max_gap': 7,\n",
    "            'corner_max': 900,\n",
    "            'corner_quality': 0.015,\n",
    "            'corner_min_dist': 7,\n",
    "            'min_coverage': 0.03,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "results: List[VariantResult] = []\n",
    "for cfg in VARIANTS:\n",
    "    out = run_sift_corner_variant(\n",
    "        img0_rgb=img0_rgb,\n",
    "        img1_rgb=img1_rgb,\n",
    "        K0=K0,\n",
    "        K1=K1,\n",
    "        cfg=cfg,\n",
    "    )\n",
    "    results.append(out)\n",
    "\n",
    "print('Finished variants:', [r.name for r in results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebe053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helpers + 2-column panel\n",
    "def to_rgb(gray: np.ndarray) -> np.ndarray:\n",
    "    if gray.ndim == 2:\n",
    "        return cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "    return gray.copy()\n",
    "\n",
    "\n",
    "def clip_pt(p: np.ndarray, w: int, h: int) -> Tuple[int, int]:\n",
    "    x = int(np.clip(round(float(p[0])), 0, w - 1))\n",
    "    y = int(np.clip(round(float(p[1])), 0, h - 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def draw_variant_pair(res: VariantResult, max_draw: int = 500) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    h0, w0 = res.gray0.shape[:2]\n",
    "\n",
    "    left = _mask_tint(res.gray0, res.mask0)\n",
    "\n",
    "    if res.affine_M_1to0 is not None:\n",
    "        warped1 = cv2.warpAffine(res.gray1, res.affine_M_1to0, (w0, h0), flags=cv2.INTER_LINEAR, borderValue=0)\n",
    "        p1w = affine_transform_points(res.affine_M_1to0, res.pts1)\n",
    "    else:\n",
    "        warped1 = cv2.resize(res.gray1, (w0, h0), interpolation=cv2.INTER_LINEAR)\n",
    "        p1w = np.zeros_like(res.pts1)\n",
    "\n",
    "    right = cv2.addWeighted(to_rgb(res.gray0), 0.45, to_rgb(warped1), 0.55, 0.0)\n",
    "\n",
    "    n = len(res.matches)\n",
    "    if n == 0:\n",
    "        return left, right\n",
    "\n",
    "    draw_idx = np.arange(n, dtype=np.int32)\n",
    "    inl = res.affine_inliers if res.affine_inliers.shape[0] == n else np.zeros((n,), dtype=bool)\n",
    "\n",
    "    if draw_idx.size > max_draw:\n",
    "        inl_idx = np.where(inl)[0]\n",
    "        out_idx = np.where(~inl)[0]\n",
    "        if inl_idx.size >= max_draw:\n",
    "            draw_idx = inl_idx[:max_draw]\n",
    "        else:\n",
    "            rem = max_draw - inl_idx.size\n",
    "            draw_idx = np.concatenate([inl_idx, out_idx[:rem]])\n",
    "\n",
    "    guided = res.guided_mask if res.guided_mask.shape[0] == n else np.zeros((n,), dtype=bool)\n",
    "\n",
    "    for i in draw_idx:\n",
    "        ok = bool(inl[i])\n",
    "        gd = bool(guided[i])\n",
    "\n",
    "        # green=inlier, orange=outlier+guided, red=outlier\n",
    "        if ok:\n",
    "            col = (0, 255, 0)\n",
    "        elif gd:\n",
    "            col = (255, 170, 0)\n",
    "        else:\n",
    "            col = (255, 0, 0)\n",
    "\n",
    "        p0 = res.pts0[i]\n",
    "        x0, y0 = clip_pt(p0, w0, h0)\n",
    "        r0 = int(max(2, round(float(res.kp_size0[i]) * 0.35)))\n",
    "        cv2.circle(left, (x0, y0), r0, col, 1, cv2.LINE_AA)\n",
    "        cv2.circle(left, (x0, y0), 1, (255, 255, 0), -1, cv2.LINE_AA)\n",
    "\n",
    "        if res.affine_M_1to0 is not None:\n",
    "            p1 = p1w[i]\n",
    "            x1, y1 = clip_pt(p1, w0, h0)\n",
    "            r1 = int(max(2, round(float(res.kp_size1[i]) * 0.35)))\n",
    "            cv2.circle(right, (x1, y1), r1, col, 1, cv2.LINE_AA)\n",
    "            cv2.circle(right, (x1, y1), 1, (255, 255, 0), -1, cv2.LINE_AA)\n",
    "            if ok:\n",
    "                cv2.line(left, (x0, y0), (x1, y1), (0, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return left, right\n",
    "\n",
    "\n",
    "if len(results) == 0:\n",
    "    raise RuntimeError('No variant results found. Run the variant cell first.')\n",
    "\n",
    "fig, axes = plt.subplots(len(results), 2, figsize=(18, 5.8 * len(results)))\n",
    "if len(results) == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "row_tags = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)']\n",
    "\n",
    "for r, res in enumerate(results):\n",
    "    left, right = draw_variant_pair(res, max_draw=MAX_DRAW_MATCHES)\n",
    "\n",
    "    axes[r, 0].imshow(left)\n",
    "    axes[r, 0].axis('off')\n",
    "    axes[r, 1].imshow(right)\n",
    "    axes[r, 1].axis('off')\n",
    "\n",
    "    tag = row_tags[r] if r < len(row_tags) else f'({r + 1})'\n",
    "    inl_a = int(res.affine_inliers.sum()) if res.affine_inliers.size else 0\n",
    "    inl_h = int(res.homography_inliers.sum()) if res.homography_inliers.size else 0\n",
    "    inl_s = int(res.sfm_inliers.sum()) if res.sfm_inliers.size else 0\n",
    "    inl_er = int(res.essential_inliers_raw.sum()) if res.essential_inliers_raw.size else 0\n",
    "\n",
    "    axes[r, 0].set_title(\n",
    "        f\"{res.name} {tag} | kp0={len(res.keypoints0)} kp1={len(res.keypoints1)} \"\n",
    "        f\"matches={len(res.matches)} | affine inl={inl_a}\"\n",
    "    )\n",
    "    axes[r, 1].set_title(\n",
    "        f\"rot={res.affine_rotation_deg:.2f}deg tx={res.affine_tx:.1f}px ty={res.affine_ty:.1f}px \"\n",
    "        f\"scale={res.affine_scale:.4f} | H inl={inl_h} Eraw inl={inl_er} Eguided inl={inl_s}\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics table + best variant + planar diagnostic\n",
    "def summarize_variant(res: VariantResult) -> Dict[str, object]:\n",
    "    n = len(res.matches)\n",
    "    inl_aff = int(res.affine_inliers.sum()) if res.affine_inliers.size else 0\n",
    "    inl_h = int(res.homography_inliers.sum()) if res.homography_inliers.size else 0\n",
    "    inl_e_raw = int(res.essential_inliers_raw.sum()) if res.essential_inliers_raw.size else 0\n",
    "    inl_e = int(res.sfm_inliers.sum()) if res.sfm_inliers.size else 0\n",
    "\n",
    "    rH = float(inl_h) / float(max(1, n))\n",
    "    rEraw = float(inl_e_raw) / float(max(1, n))\n",
    "    planar_dom = rH / max(1e-6, rEraw)\n",
    "\n",
    "    gm0 = _pts_in_mask(res.green0, res.pts0)\n",
    "    gm1 = _pts_in_mask(res.green1, res.pts1)\n",
    "    mg0 = (100.0 * float(gm0.mean())) if n > 0 else np.nan\n",
    "    mg1 = (100.0 * float(gm1.mean())) if n > 0 else np.nan\n",
    "\n",
    "    sfm_tx, sfm_ty, sfm_tz = (np.nan, np.nan, np.nan)\n",
    "    if res.sfm_t is not None:\n",
    "        t = res.sfm_t.astype(float)\n",
    "        tn = float(np.linalg.norm(t))\n",
    "        if tn > 1e-12:\n",
    "            t = t / tn\n",
    "        sfm_tx, sfm_ty, sfm_tz = float(t[0]), float(t[1]), float(t[2])\n",
    "\n",
    "    focus_score = float(inl_aff) - 0.10 * float((mg0 if pd.notna(mg0) else 100.0) + (mg1 if pd.notna(mg1) else 100.0))\n",
    "\n",
    "    return {\n",
    "        'variant': res.name,\n",
    "        'preprocess': res.preprocess_mode,\n",
    "        'mask_profile': res.mask_profile,\n",
    "        'kp0': len(res.keypoints0),\n",
    "        'kp1': len(res.keypoints1),\n",
    "        'kp0_green_pct': _kp_green_fraction(res.keypoints0, res.green0),\n",
    "        'kp1_green_pct': _kp_green_fraction(res.keypoints1, res.green1),\n",
    "        'matches': n,\n",
    "        'match_green0_pct': mg0,\n",
    "        'match_green1_pct': mg1,\n",
    "        'affine_inliers': inl_aff,\n",
    "        'homography_inliers': inl_h,\n",
    "        'essential_raw_inliers': inl_e_raw,\n",
    "        'essential_guided_inliers': inl_e,\n",
    "        'planar_dom_ratio_H_over_Eraw': planar_dom,\n",
    "        'affine_rot_deg': res.affine_rotation_deg,\n",
    "        'affine_tx_px': res.affine_tx,\n",
    "        'affine_ty_px': res.affine_ty,\n",
    "        'affine_scale': res.affine_scale,\n",
    "        'affine_rmse_px': res.affine_rmse,\n",
    "        'sfm_rot3d_deg': res.sfm_rot_deg,\n",
    "        'sfm_yaw_deg': res.sfm_yaw_deg,\n",
    "        'sfm_pitch_deg': res.sfm_pitch_deg,\n",
    "        'sfm_roll_deg': res.sfm_roll_deg,\n",
    "        'sfm_t_dir_x': sfm_tx,\n",
    "        'sfm_t_dir_y': sfm_ty,\n",
    "        'sfm_t_dir_z': sfm_tz,\n",
    "        'mask_cov0': float(res.mask_diag0.get('mask_cov', np.nan)),\n",
    "        'mask_cov1': float(res.mask_diag1.get('mask_cov', np.nan)),\n",
    "        'mask_fallback0': int(res.mask_diag0.get('fallback', 0.0) > 0.5),\n",
    "        'mask_fallback1': int(res.mask_diag1.get('fallback', 0.0) > 0.5),\n",
    "        'drop_resp': int(res.dropped_by_response),\n",
    "        'drop_size_ratio': int(res.dropped_by_size_ratio),\n",
    "        'focus_score': focus_score,\n",
    "    }\n",
    "\n",
    "\n",
    "rows = [summarize_variant(r) for r in results]\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df = metrics_df.sort_values(\n",
    "    ['focus_score', 'affine_inliers', 'matches'],\n",
    "    ascending=[False, False, False],\n",
    ").reset_index(drop=True)\n",
    "display(metrics_df)\n",
    "\n",
    "best = metrics_df.iloc[0]\n",
    "print('Best variant:', best['variant'])\n",
    "print(\n",
    "    f\"2D pose: rot={best['affine_rot_deg']:.2f}deg tx={best['affine_tx_px']:.2f}px \"\n",
    "    f\"ty={best['affine_ty_px']:.2f}px scale={best['affine_scale']:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Planar diagnostic H/Eraw={best['planar_dom_ratio_H_over_Eraw']:.2f} \"\n",
    "    f\"(>1.3 often means homography-dominated pair)\"\n",
    ")\n",
    "print(\n",
    "    f\"SfM orientation: yaw={best['sfm_yaw_deg']:.2f} pitch={best['sfm_pitch_deg']:.2f} \"\n",
    "    f\"roll={best['sfm_roll_deg']:.2f} deg\"\n",
    ")\n",
    "print(\n",
    "    f\"SfM t dir (unit): [{best['sfm_t_dir_x']:.3f}, {best['sfm_t_dir_y']:.3f}, {best['sfm_t_dir_z']:.3f}]\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1890867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: raw match lines for one selected variant (notebook-1 style)\n",
    "SELECT_VARIANT = 'corner_guided_edge_mild'\n",
    "MAX_LINE_MATCHES = 180\n",
    "\n",
    "cand = [r for r in results if r.name == SELECT_VARIANT]\n",
    "if len(cand) == 0:\n",
    "    sel_res = results[0]\n",
    "    print(f'Variant {SELECT_VARIANT} not found. Using {sel_res.name}.')\n",
    "else:\n",
    "    sel_res = cand[0]\n",
    "\n",
    "show_idx = np.arange(len(sel_res.matches), dtype=np.int32)\n",
    "inl = sel_res.affine_inliers if sel_res.affine_inliers.shape[0] == len(sel_res.matches) else np.zeros((len(sel_res.matches),), bool)\n",
    "if show_idx.size > MAX_LINE_MATCHES:\n",
    "    inl_idx = np.where(inl)[0]\n",
    "    out_idx = np.where(~inl)[0]\n",
    "    need = int(MAX_LINE_MATCHES)\n",
    "    if inl_idx.size >= need:\n",
    "        show_idx = inl_idx[:need]\n",
    "    else:\n",
    "        show_idx = np.concatenate([inl_idx, out_idx[:need - inl_idx.size]])\n",
    "\n",
    "vis0 = cv2.cvtColor(_ensure_gray_u8(sel_res.gray0), cv2.COLOR_GRAY2BGR)\n",
    "vis1 = cv2.cvtColor(_ensure_gray_u8(sel_res.gray1), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "draw_matches = [sel_res.matches[int(i)] for i in show_idx]\n",
    "match_img = cv2.drawMatches(\n",
    "    vis0,\n",
    "    sel_res.keypoints0,\n",
    "    vis1,\n",
    "    sel_res.keypoints1,\n",
    "    draw_matches,\n",
    "    None,\n",
    "    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Raw matches | {sel_res.name} | drawn={len(draw_matches)}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6f0cc",
   "metadata": {},
   "source": [
    "## Hinweise\n",
    "- Die Pipeline nutzt jetzt die robuste Pfad-/Dateilogik aus Notebook 12.\n",
    "- Ideen aus Notebook 14 sind integriert (`RootSIFT`, `corner_guided`, `H-guided` Pose-Auswertung).\n",
    "- Wenn du nur \"12 + Fokus\" willst, lasse `use_corner_guided=False` in allen Varianten.\n",
    "- Falls zu wenige Matches entstehen: zuerst `mask_profile='none'` oder `'nongreen'`, dann `ratio_thr` leicht erhoehen (z. B. 0.78 -> 0.82).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
