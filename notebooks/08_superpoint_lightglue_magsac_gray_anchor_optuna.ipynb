{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - SuperPoint + LightGlue + MAGSAC with Gray/Edge, Anchor Crop, and Optuna\n",
    "\n",
    "Pipeline goal:\n",
    "- gray filtering for map and frame images (optional edge enhancement)\n",
    "- SuperPoint + LightGlue matching with MAGSAC outlier filtering\n",
    "- per-frame intrinsics are used for scale/height handling\n",
    "- anchor-based search from last known position (`id-1` preferred)\n",
    "- test IDs below anchor ID are processed in reverse order (for this dataset: 1..12, anchor at 13)\n",
    "- Optuna optimization for Kaggle metric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric (Kaggle style)\n",
    "\n",
    "For each frame:\n",
    "`d = sqrt((x_pred - x_gt)^2 + (y_pred - y_gt)^2)`\n",
    "\n",
    "Score:\n",
    "`100 * mean(acc@25px, acc@125px, acc@500px)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except Exception:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "print(f\"Optuna available: {OPTUNA_AVAILABLE}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency check for SuperPoint + LightGlue\n",
    "try:\n",
    "    from lightglue import LightGlue, SuperPoint\n",
    "    from lightglue.utils import rbd\n",
    "except Exception as e:\n",
    "    raise ImportError('This notebook requires LightGlue+SuperPoint. Install with: pip install lightglue') from e\n",
    "\n",
    "# Paths (robust for running from project root or notebooks/)\n",
    "CANDIDATE_ROOTS = [Path.cwd(), Path.cwd().parent, Path('.'), Path('..')]\n",
    "PROJECT_ROOT = None\n",
    "_seen_roots = set()\n",
    "for cand in CANDIDATE_ROOTS:\n",
    "    try:\n",
    "        root = cand.resolve()\n",
    "    except Exception:\n",
    "        continue\n",
    "    key = str(root)\n",
    "    if key in _seen_roots:\n",
    "        continue\n",
    "    _seen_roots.add(key)\n",
    "    if (root / 'data' / 'data').exists():\n",
    "        PROJECT_ROOT = root\n",
    "        break\n",
    "if PROJECT_ROOT is None:\n",
    "    raise FileNotFoundError('Could not find project root containing data/data.')\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / 'data' / 'data'\n",
    "TRAIN_IMG_DIR = DATA_ROOT / 'train_data' / 'train_images'\n",
    "TEST_IMG_DIR = DATA_ROOT / 'test_data' / 'test_images'\n",
    "TRAIN_POS_CSV = DATA_ROOT / 'train_data' / 'train_pos.csv'\n",
    "TRAIN_CAM_CSV = DATA_ROOT / 'train_data' / 'train_cam.csv'\n",
    "TEST_CAM_CSV = DATA_ROOT / 'test_data' / 'test_cam.csv'\n",
    "MAP_PATH = DATA_ROOT / 'map.png'\n",
    "\n",
    "# Split / runtime\n",
    "SPLIT_SEED = 42\n",
    "TRAIN_FRACTION = 0.8\n",
    "IMAGE_MAX_SIDE = 1400  # set None for full-res\n",
    "\n",
    "# Preprocessing (gray + optional edge)\n",
    "ENABLE_GRAY_FILTER = True\n",
    "ENABLE_EDGE_FILTER = True\n",
    "EDGE_CANNY_LOW = 50\n",
    "EDGE_CANNY_HIGH = 150\n",
    "EDGE_DILATE_KERNEL = 3\n",
    "EDGE_BLEND_GRAY = 0.70\n",
    "EDGE_BLEND_EDGE = 0.30\n",
    "\n",
    "# Matcher settings\n",
    "LIGHTGLUE_MAX_NUM_KEYPOINTS = 2048\n",
    "\n",
    "# Anchor / ordering\n",
    "TEST_REVERSE_ANCHOR_ID = 13\n",
    "\n",
    "# Base hyperparameters\n",
    "BASE_HPARAMS = {\n",
    "    'match_min_conf': 0.20,\n",
    "    'magsac_reproj_thr': 3.0,\n",
    "    'virtual_zoom_out': 1.80,\n",
    "    'crop_width_factor': 3.0,\n",
    "    'crop_height_factor_n': 4.5,\n",
    "    'min_inliers': 12,\n",
    "    'scale_low_mul': 0.85,\n",
    "    'scale_high_mul': 1.20,\n",
    "}\n",
    "\n",
    "# Height calibration settings\n",
    "HEIGHT_CALIB_FRAMES = 30\n",
    "HEIGHT_LOCAL_RADIUS = 900\n",
    "HEIGHT_SCALE_CANDIDATES = [0.09, 0.11, 0.13, 0.15, 0.17, 0.19, 0.22, 0.25, 0.28]\n",
    "HEIGHT_MIN_NCC = 0.08\n",
    "\n",
    "# Optuna settings\n",
    "RUN_OPTUNA = False\n",
    "OPTUNA_TRIALS = 15\n",
    "OPTUNA_VAL_LIMIT = 45\n",
    "OPTUNA_TIMEOUT_S = None\n",
    "\n",
    "SUBMISSION_OUT = PROJECT_ROOT / 'build' / 'submission_08_superpoint_lightglue_gray_magsac.csv'\n",
    "\n",
    "# Load data\n",
    "train_pos_df = pd.read_csv(TRAIN_POS_CSV)\n",
    "train_cam_df = pd.read_csv(TRAIN_CAM_CSV)\n",
    "test_cam_df = pd.read_csv(TEST_CAM_CSV)\n",
    "\n",
    "train_df = train_cam_df.merge(train_pos_df, on='id', how='inner').copy()\n",
    "train_df['id'] = train_df['id'].astype(int)\n",
    "test_cam_df['id'] = test_cam_df['id'].astype(int)\n",
    "train_df = train_df.sort_values('id').reset_index(drop=True)\n",
    "test_cam_df = test_cam_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "map_bgr = cv2.imread(str(MAP_PATH), cv2.IMREAD_COLOR)\n",
    "if map_bgr is None:\n",
    "    raise FileNotFoundError(f'Map not found: {MAP_PATH}')\n",
    "map_rgb = cv2.cvtColor(map_bgr, cv2.COLOR_BGR2RGB)\n",
    "MAP_H, MAP_W = map_rgb.shape[:2]\n",
    "\n",
    "print('project_root:', PROJECT_ROOT)\n",
    "print('train:', len(train_df), 'test:', len(test_cam_df), 'map:', (MAP_W, MAP_H))\n",
    "print('optuna_available:', OPTUNA_AVAILABLE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible train/val split\n",
    "rng = np.random.default_rng(SPLIT_SEED)\n",
    "all_ids = train_df['id'].unique().copy()\n",
    "rng.shuffle(all_ids)\n",
    "\n",
    "n_fit = max(1, min(len(all_ids) - 1, int(round(len(all_ids) * TRAIN_FRACTION))))\n",
    "fit_ids = set(int(x) for x in all_ids[:n_fit])\n",
    "val_ids = set(int(x) for x in all_ids[n_fit:])\n",
    "\n",
    "fit_df = train_df[train_df['id'].isin(fit_ids)].copy().sort_values('id').reset_index(drop=True)\n",
    "val_df = train_df[train_df['id'].isin(val_ids)].copy().sort_values('id').reset_index(drop=True)\n",
    "\n",
    "print('fit:', len(fit_df), 'val:', len(val_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: image loading, preprocessing, metric, ordering\n",
    "_IMAGE_CACHE: Dict[Tuple[str, int, Optional[int]], np.ndarray] = {}\n",
    "_PROC_CACHE: Dict[Tuple[str, int, Optional[int], bool, bool, int, int, int], np.ndarray] = {}\n",
    "\n",
    "\n",
    "def resolve_image_path(image_id: int, is_train: bool) -> Path:\n",
    "    folder = TRAIN_IMG_DIR if is_train else TEST_IMG_DIR\n",
    "    stems = [f'{int(image_id):04d}', str(int(image_id))]\n",
    "    exts = ['.JPG', '.jpg', '.jpeg', '.JPEG', '.png', '.PNG']\n",
    "    for st in stems:\n",
    "        for ext in exts:\n",
    "            p = folder / f'{st}{ext}'\n",
    "            if p.exists():\n",
    "                return p\n",
    "    raise FileNotFoundError(f'Image not found for id={image_id} in {folder}')\n",
    "\n",
    "\n",
    "def resize_keep_aspect(img_rgb: np.ndarray, max_side: Optional[int]) -> np.ndarray:\n",
    "    if max_side is None:\n",
    "        return img_rgb\n",
    "    h, w = img_rgb.shape[:2]\n",
    "    m = max(h, w)\n",
    "    if m <= int(max_side):\n",
    "        return img_rgb\n",
    "    s = float(max_side) / float(m)\n",
    "    nw = max(32, int(round(w * s)))\n",
    "    nh = max(32, int(round(h * s)))\n",
    "    return cv2.resize(img_rgb, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def load_image_cached(image_id: int, split: str, max_side: Optional[int]) -> np.ndarray:\n",
    "    key = (split, int(image_id), max_side)\n",
    "    if key in _IMAGE_CACHE:\n",
    "        return _IMAGE_CACHE[key]\n",
    "\n",
    "    is_train = split in {'train', 'fit', 'val'}\n",
    "    p = resolve_image_path(int(image_id), is_train=is_train)\n",
    "    bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "    if bgr is None:\n",
    "        raise RuntimeError(f'Cannot read image: {p}')\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    rgb = resize_keep_aspect(rgb, max_side=max_side)\n",
    "    _IMAGE_CACHE[key] = rgb\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def to_gray_rgb(img_rgb: np.ndarray) -> np.ndarray:\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "def preprocess_for_matching(\n",
    "    img_rgb: np.ndarray,\n",
    "    enable_gray: bool,\n",
    "    enable_edge: bool,\n",
    "    canny_low: int,\n",
    "    canny_high: int,\n",
    ") -> np.ndarray:\n",
    "    proc = to_gray_rgb(img_rgb) if bool(enable_gray) else img_rgb\n",
    "\n",
    "    if not bool(enable_edge):\n",
    "        return proc\n",
    "\n",
    "    gray = cv2.cvtColor(proc, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, int(canny_low), int(canny_high))\n",
    "    k = int(max(1, EDGE_DILATE_KERNEL))\n",
    "    if k > 1:\n",
    "        kernel = np.ones((k, k), dtype=np.uint8)\n",
    "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "    mix = cv2.addWeighted(gray, float(EDGE_BLEND_GRAY), edges, float(EDGE_BLEND_EDGE), 0.0)\n",
    "    return cv2.cvtColor(mix, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "def get_match_image(image_id: int, split: str) -> np.ndarray:\n",
    "    key = (\n",
    "        split,\n",
    "        int(image_id),\n",
    "        IMAGE_MAX_SIDE,\n",
    "        bool(ENABLE_GRAY_FILTER),\n",
    "        bool(ENABLE_EDGE_FILTER),\n",
    "        int(EDGE_CANNY_LOW),\n",
    "        int(EDGE_CANNY_HIGH),\n",
    "        int(EDGE_DILATE_KERNEL),\n",
    "    )\n",
    "    if key in _PROC_CACHE:\n",
    "        return _PROC_CACHE[key]\n",
    "\n",
    "    rgb = load_image_cached(int(image_id), split=split, max_side=IMAGE_MAX_SIDE)\n",
    "    proc = preprocess_for_matching(\n",
    "        rgb,\n",
    "        enable_gray=ENABLE_GRAY_FILTER,\n",
    "        enable_edge=ENABLE_EDGE_FILTER,\n",
    "        canny_low=EDGE_CANNY_LOW,\n",
    "        canny_high=EDGE_CANNY_HIGH,\n",
    "    )\n",
    "    _PROC_CACHE[key] = proc\n",
    "    return proc\n",
    "\n",
    "\n",
    "def choose_processing_order(ids: List[int], reverse_anchor_id: int) -> List[int]:\n",
    "    low = sorted([i for i in ids if i < int(reverse_anchor_id)], reverse=True)\n",
    "    high = sorted([i for i in ids if i >= int(reverse_anchor_id)])\n",
    "    return low + high\n",
    "\n",
    "\n",
    "def eval_metric_from_df(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    if len(df) == 0:\n",
    "        return {\n",
    "            'n': 0.0,\n",
    "            'mean_err_px': np.nan,\n",
    "            'median_err_px': np.nan,\n",
    "            'acc_25': np.nan,\n",
    "            'acc_125': np.nan,\n",
    "            'acc_500': np.nan,\n",
    "            'score': np.nan,\n",
    "        }\n",
    "\n",
    "    d = np.sqrt((df['pred_x'] - df['gt_x']) ** 2 + (df['pred_y'] - df['gt_y']) ** 2)\n",
    "    a25 = float((d <= 25.0).mean())\n",
    "    a125 = float((d <= 125.0).mean())\n",
    "    a500 = float((d <= 500.0).mean())\n",
    "    score = 100.0 * float(np.mean([a25, a125, a500]))\n",
    "\n",
    "    return {\n",
    "        'n': float(len(df)),\n",
    "        'mean_err_px': float(d.mean()),\n",
    "        'median_err_px': float(d.median()),\n",
    "        'acc_25': a25,\n",
    "        'acc_125': a125,\n",
    "        'acc_500': a500,\n",
    "        'score': score,\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SuperPoint + LightGlue + MAGSAC matcher\n",
    "class SuperPointLightGlueMagsacMatcher:\n",
    "    def __init__(self, min_conf: float = 0.2, max_num_keypoints: int = 2048, device: Optional[str] = None):\n",
    "        self.min_conf = float(min_conf)\n",
    "        self.max_num_keypoints = int(max_num_keypoints)\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        self.extractor = None\n",
    "        self.matcher = None\n",
    "\n",
    "    def _lazy_init(self):\n",
    "        if self.extractor is not None and self.matcher is not None:\n",
    "            return\n",
    "        self.extractor = SuperPoint(max_num_keypoints=self.max_num_keypoints).eval().to(self.device)\n",
    "        self.matcher = LightGlue(features='superpoint').eval().to(self.device)\n",
    "\n",
    "    def _to_tensor(self, img_rgb: np.ndarray) -> torch.Tensor:\n",
    "        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        t = torch.from_numpy(gray).float()[None, None] / 255.0\n",
    "        return t.to(self.device)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def match(self, img0_rgb: np.ndarray, img1_rgb: np.ndarray):\n",
    "        self._lazy_init()\n",
    "        t0 = self._to_tensor(img0_rgb)\n",
    "        t1 = self._to_tensor(img1_rgb)\n",
    "\n",
    "        f0 = self.extractor.extract(t0)\n",
    "        f1 = self.extractor.extract(t1)\n",
    "        out = self.matcher({'image0': f0, 'image1': f1})\n",
    "        f0, f1, out = [rbd(x) for x in [f0, f1, out]]\n",
    "\n",
    "        k0 = f0['keypoints'].detach().cpu().numpy().astype(np.float32)\n",
    "        k1 = f1['keypoints'].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        m = out['matches'].detach().cpu().numpy().astype(np.int32)\n",
    "        if m.size == 0:\n",
    "            return {\n",
    "                'k0': k0,\n",
    "                'k1': k1,\n",
    "                'matches': np.zeros((0, 2), dtype=np.int32),\n",
    "                'conf': np.zeros((0,), dtype=np.float32),\n",
    "            }\n",
    "\n",
    "        if m.ndim != 2:\n",
    "            m = m.reshape(-1, 2)\n",
    "\n",
    "        if 'scores' in out:\n",
    "            conf = out['scores'].detach().cpu().numpy().astype(np.float32)\n",
    "        else:\n",
    "            conf = np.ones((m.shape[0],), dtype=np.float32)\n",
    "\n",
    "        if conf.shape[0] != m.shape[0]:\n",
    "            conf = np.ones((m.shape[0],), dtype=np.float32)\n",
    "\n",
    "        keep = conf >= self.min_conf\n",
    "        m = m[keep]\n",
    "        conf = conf[keep]\n",
    "\n",
    "        return {'k0': k0, 'k1': k1, 'matches': m, 'conf': conf}\n",
    "\n",
    "    @staticmethod\n",
    "    def magsac_homography(k0: np.ndarray, k1: np.ndarray, matches: np.ndarray, reproj_thr: float = 3.0):\n",
    "        if matches.shape[0] < 8:\n",
    "            return None, np.zeros((matches.shape[0],), dtype=bool)\n",
    "\n",
    "        p0 = k0[matches[:, 0]].astype(np.float32)\n",
    "        p1 = k1[matches[:, 1]].astype(np.float32)\n",
    "\n",
    "        H, mask = cv2.findHomography(\n",
    "            p0,\n",
    "            p1,\n",
    "            method=cv2.USAC_MAGSAC,\n",
    "            ransacReprojThreshold=float(reproj_thr),\n",
    "            maxIters=10000,\n",
    "            confidence=0.999,\n",
    "        )\n",
    "\n",
    "        if H is None or mask is None:\n",
    "            return None, np.zeros((matches.shape[0],), dtype=bool)\n",
    "\n",
    "        return H, mask.ravel().astype(bool)\n",
    "\n",
    "\n",
    "matcher = SuperPointLightGlueMagsacMatcher(\n",
    "    min_conf=BASE_HPARAMS['match_min_conf'],\n",
    "    max_num_keypoints=LIGHTGLUE_MAX_NUM_KEYPOINTS,\n",
    ")\n",
    "print('matcher device:', matcher.device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height/scale model from train GT + per-frame intrinsics\n",
    "@dataclass\n",
    "class HeightScaleModel:\n",
    "    rel_height_ref: float\n",
    "    scale_ref: float\n",
    "    scale_low: float\n",
    "    scale_high: float\n",
    "    n_samples: int\n",
    "\n",
    "\n",
    "def focal_from_row(row) -> float:\n",
    "    fx = float(getattr(row, 'fx', np.nan))\n",
    "    fy = float(getattr(row, 'fy', np.nan))\n",
    "    if np.isfinite(fx) and np.isfinite(fy):\n",
    "        return 0.5 * (fx + fy)\n",
    "    if np.isfinite(fx):\n",
    "        return fx\n",
    "    if np.isfinite(fy):\n",
    "        return fy\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def extract_map_crop(map_img: np.ndarray, center_xy: Tuple[float, float], radius_px: int) -> Tuple[np.ndarray, int, int]:\n",
    "    cx, cy = float(center_xy[0]), float(center_xy[1])\n",
    "    r = int(max(32, radius_px))\n",
    "    x0 = int(np.clip(round(cx) - r, 0, max(0, map_img.shape[1] - 1)))\n",
    "    y0 = int(np.clip(round(cy) - r, 0, max(0, map_img.shape[0] - 1)))\n",
    "    x1 = int(np.clip(round(cx) + r, 0, map_img.shape[1]))\n",
    "    y1 = int(np.clip(round(cy) + r, 0, map_img.shape[0]))\n",
    "    if x1 <= x0:\n",
    "        x1 = min(map_img.shape[1], x0 + 1)\n",
    "    if y1 <= y0:\n",
    "        y1 = min(map_img.shape[0], y0 + 1)\n",
    "    return map_img[y0:y1, x0:x1], x0, y0\n",
    "\n",
    "\n",
    "def template_best_scale_for_gt(\n",
    "    q_proc: np.ndarray,\n",
    "    gt_xy: Tuple[float, float],\n",
    "    map_proc: np.ndarray,\n",
    "    scale_candidates: List[float],\n",
    "    local_radius: int,\n",
    ") -> Tuple[float, float]:\n",
    "    best_scale = np.nan\n",
    "    best_ncc = -1.0\n",
    "\n",
    "    for s in scale_candidates:\n",
    "        tpl = cv2.resize(q_proc, None, fx=float(s), fy=float(s), interpolation=cv2.INTER_AREA)\n",
    "        if tpl.shape[0] < 8 or tpl.shape[1] < 8:\n",
    "            continue\n",
    "\n",
    "        rr = max(int(local_radius), int(max(tpl.shape[:2]) * 1.2))\n",
    "        crop, _, _ = extract_map_crop(map_proc, center_xy=gt_xy, radius_px=rr)\n",
    "        if crop.shape[0] < tpl.shape[0] or crop.shape[1] < tpl.shape[1]:\n",
    "            continue\n",
    "\n",
    "        res = cv2.matchTemplate(crop, tpl, method=cv2.TM_CCOEFF_NORMED)\n",
    "        _, ncc, _, _ = cv2.minMaxLoc(res)\n",
    "        if float(ncc) > best_ncc:\n",
    "            best_ncc = float(ncc)\n",
    "            best_scale = float(s)\n",
    "\n",
    "    return float(best_scale), float(best_ncc)\n",
    "\n",
    "\n",
    "def derive_height_scale_model(fit_subset: pd.DataFrame, map_proc: np.ndarray) -> Tuple[HeightScaleModel, pd.DataFrame]:\n",
    "    ids = fit_subset['id'].astype(int).tolist()\n",
    "    max_frames = int(max(6, HEIGHT_CALIB_FRAMES))\n",
    "    if len(ids) > max_frames:\n",
    "        idx = np.linspace(0, len(ids) - 1, max_frames, dtype=int)\n",
    "        ids = [ids[i] for i in idx]\n",
    "\n",
    "    row_by_id = {int(r.id): r for r in fit_subset.itertuples(index=False)}\n",
    "\n",
    "    rows = []\n",
    "    for qid in ids:\n",
    "        row = row_by_id[int(qid)]\n",
    "        q_proc = get_match_image(int(qid), split='fit')\n",
    "        gt_xy = (float(row.x_pixel), float(row.y_pixel))\n",
    "\n",
    "        s_best, ncc_best = template_best_scale_for_gt(\n",
    "            q_proc=q_proc,\n",
    "            gt_xy=gt_xy,\n",
    "            map_proc=map_proc,\n",
    "            scale_candidates=[float(x) for x in HEIGHT_SCALE_CANDIDATES],\n",
    "            local_radius=int(HEIGHT_LOCAL_RADIUS),\n",
    "        )\n",
    "\n",
    "        if np.isfinite(s_best) and float(ncc_best) >= float(HEIGHT_MIN_NCC):\n",
    "            f = focal_from_row(row)\n",
    "            rel_h = float(s_best * f)\n",
    "            rows.append({\n",
    "                'id': int(qid),\n",
    "                'focal': float(f),\n",
    "                'best_scale': float(s_best),\n",
    "                'best_ncc': float(ncc_best),\n",
    "                'rel_height': float(rel_h),\n",
    "            })\n",
    "\n",
    "    diag = pd.DataFrame(rows)\n",
    "    if len(diag) == 0:\n",
    "        hm = HeightScaleModel(\n",
    "            rel_height_ref=180.0,\n",
    "            scale_ref=0.18,\n",
    "            scale_low=0.10,\n",
    "            scale_high=0.30,\n",
    "            n_samples=0,\n",
    "        )\n",
    "        return hm, diag\n",
    "\n",
    "    med_h = float(diag['rel_height'].median())\n",
    "    mad_h = float(np.median(np.abs(diag['rel_height'].to_numpy() - med_h))) + 1e-6\n",
    "    z = 0.6745 * (diag['rel_height'] - med_h) / mad_h\n",
    "    inlier_mask = np.abs(z) <= 3.0\n",
    "    diag['height_inlier'] = inlier_mask\n",
    "\n",
    "    inl = diag[diag['height_inlier']].copy()\n",
    "    if len(inl) < 5:\n",
    "        inl = diag.copy()\n",
    "\n",
    "    rel_h = float(inl['rel_height'].median())\n",
    "    scale_ref = float(inl['best_scale'].median())\n",
    "    q1 = float(inl['best_scale'].quantile(0.25))\n",
    "    q3 = float(inl['best_scale'].quantile(0.75))\n",
    "    iqr = max(1e-4, q3 - q1)\n",
    "    s_low = max(0.05, q1 - 1.0 * iqr)\n",
    "    s_high = min(0.6, q3 + 1.0 * iqr)\n",
    "\n",
    "    hm = HeightScaleModel(\n",
    "        rel_height_ref=float(rel_h),\n",
    "        scale_ref=float(scale_ref),\n",
    "        scale_low=float(s_low),\n",
    "        scale_high=float(s_high),\n",
    "        n_samples=int(len(inl)),\n",
    "    )\n",
    "    return hm, diag\n",
    "\n",
    "\n",
    "map_proc = preprocess_for_matching(\n",
    "    map_rgb,\n",
    "    enable_gray=ENABLE_GRAY_FILTER,\n",
    "    enable_edge=ENABLE_EDGE_FILTER,\n",
    "    canny_low=EDGE_CANNY_LOW,\n",
    "    canny_high=EDGE_CANNY_HIGH,\n",
    ")\n",
    "\n",
    "height_model, height_diag_df = derive_height_scale_model(fit_df, map_proc=map_proc)\n",
    "print('height_model:', height_model)\n",
    "if len(height_diag_df) > 0:\n",
    "    print('height_samples:', len(height_diag_df), 'inliers:', int(height_diag_df.get('height_inlier', pd.Series(dtype=bool)).sum()))\n",
    "else:\n",
    "    print('height_samples: 0')\n",
    "\n",
    "display(height_diag_df.head(20))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchor-based crop/zoom/padding localization\n",
    "all_train_gt = {int(r.id): (float(r.x_pixel), float(r.y_pixel)) for r in train_df.itertuples(index=False)}\n",
    "fit_train_gt = {int(r.id): (float(r.x_pixel), float(r.y_pixel)) for r in fit_df.itertuples(index=False)}\n",
    "\n",
    "\n",
    "def get_anchor_xy(image_id: int, known_xy: Dict[int, Tuple[float, float]]) -> Tuple[Tuple[float, float], int, str]:\n",
    "    i = int(image_id)\n",
    "    if (i - 1) in known_xy:\n",
    "        return known_xy[i - 1], i - 1, 'prev_id'\n",
    "    if (i + 1) in known_xy:\n",
    "        return known_xy[i + 1], i + 1, 'next_id'\n",
    "    if len(known_xy) > 0:\n",
    "        nearest = min(known_xy.keys(), key=lambda k: abs(int(k) - i))\n",
    "        return known_xy[nearest], int(nearest), f'nearest_id_{nearest}'\n",
    "    return (MAP_W * 0.5, MAP_H * 0.5), -1, 'map_center'\n",
    "\n",
    "\n",
    "def compute_expected_scale(row, hm: HeightScaleModel, hparams: Dict[str, float]) -> float:\n",
    "    f = focal_from_row(row)\n",
    "    s = float(hm.rel_height_ref / max(1e-6, f))\n",
    "    s = float(np.clip(s, hm.scale_low * float(hparams['scale_low_mul']), hm.scale_high * float(hparams['scale_high_mul'])))\n",
    "    return s\n",
    "\n",
    "\n",
    "def resize_rgb(img: np.ndarray, scale: float) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    nw = max(8, int(round(w * float(scale))))\n",
    "    nh = max(8, int(round(h * float(scale))))\n",
    "    return cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def make_centered_canvas(img: np.ndarray, out_w: int, out_h: int) -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "    out_w = int(max(8, out_w))\n",
    "    out_h = int(max(8, out_h))\n",
    "    canvas = np.zeros((out_h, out_w, 3), dtype=img.dtype)\n",
    "\n",
    "    ih, iw = img.shape[:2]\n",
    "    # if too large, shrink to fit the canvas\n",
    "    if ih > out_h or iw > out_w:\n",
    "        sf = min(float(out_w) / max(1, iw), float(out_h) / max(1, ih))\n",
    "        sf = max(1e-3, sf)\n",
    "        img = resize_rgb(img, sf)\n",
    "        ih, iw = img.shape[:2]\n",
    "\n",
    "    x0 = (out_w - iw) // 2\n",
    "    y0 = (out_h - ih) // 2\n",
    "    canvas[y0:y0 + ih, x0:x0 + iw] = img\n",
    "    return canvas, (x0, y0)\n",
    "\n",
    "\n",
    "def extract_crop_by_size(map_img: np.ndarray, center_xy: Tuple[float, float], crop_w: int, crop_h: int) -> Tuple[np.ndarray, int, int]:\n",
    "    cw = int(max(16, crop_w))\n",
    "    ch = int(max(16, crop_h))\n",
    "\n",
    "    cx, cy = float(center_xy[0]), float(center_xy[1])\n",
    "    x0 = int(round(cx - cw / 2.0))\n",
    "    y0 = int(round(cy - ch / 2.0))\n",
    "    x0 = int(np.clip(x0, 0, max(0, map_img.shape[1] - cw)))\n",
    "    y0 = int(np.clip(y0, 0, max(0, map_img.shape[0] - ch)))\n",
    "\n",
    "    x1 = min(map_img.shape[1], x0 + cw)\n",
    "    y1 = min(map_img.shape[0], y0 + ch)\n",
    "    crop = map_img[y0:y1, x0:x1]\n",
    "    return crop, x0, y0\n",
    "\n",
    "\n",
    "def project_query_center(H: np.ndarray, q_shape: Tuple[int, int, int], offset_xy: Tuple[float, float]) -> Tuple[float, float]:\n",
    "    hq, wq = q_shape[:2]\n",
    "    c = np.array([wq / 2.0, hq / 2.0, 1.0], dtype=np.float64)\n",
    "    p = H @ c\n",
    "    if abs(float(p[2])) < 1e-12:\n",
    "        return np.nan, np.nan\n",
    "    uv = p[:2] / p[2]\n",
    "    return float(uv[0] + offset_xy[0]), float(uv[1] + offset_xy[1])\n",
    "\n",
    "\n",
    "def localize_one_frame(\n",
    "    row,\n",
    "    split_name: str,\n",
    "    anchor_xy: Tuple[float, float],\n",
    "    hm: HeightScaleModel,\n",
    "    hparams: Dict[str, float],\n",
    ") -> Dict[str, object]:\n",
    "    qid = int(row.id)\n",
    "    split_for_img = 'val' if split_name == 'val' else 'test'\n",
    "\n",
    "    q_proc = get_match_image(qid, split=split_for_img)\n",
    "\n",
    "    s_expected = compute_expected_scale(row, hm=hm, hparams=hparams)\n",
    "    s_eff = float(s_expected / max(1e-6, float(hparams['virtual_zoom_out'])))\n",
    "\n",
    "    q_scaled = resize_rgb(q_proc, s_eff)\n",
    "    qh, qw = q_scaled.shape[:2]\n",
    "\n",
    "    crop_w = int(round(float(hparams['crop_width_factor']) * float(qw)))\n",
    "    crop_h = int(round(float(hparams['crop_height_factor_n']) * float(qh)))\n",
    "    crop_w = int(np.clip(crop_w, 64, MAP_W))\n",
    "    crop_h = int(np.clip(crop_h, 64, MAP_H))\n",
    "\n",
    "    q_canvas, _ = make_centered_canvas(q_scaled, out_w=crop_w, out_h=crop_h)\n",
    "\n",
    "    map_crop, x0, y0 = extract_crop_by_size(\n",
    "        map_proc,\n",
    "        center_xy=anchor_xy,\n",
    "        crop_w=crop_w,\n",
    "        crop_h=crop_h,\n",
    "    )\n",
    "\n",
    "    # If crop got clipped at borders, resize query canvas to exact crop size.\n",
    "    if q_canvas.shape[:2] != map_crop.shape[:2]:\n",
    "        q_canvas, _ = make_centered_canvas(q_scaled, out_w=map_crop.shape[1], out_h=map_crop.shape[0])\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    m = matcher.match(q_canvas, map_crop)\n",
    "    H, inl = matcher.magsac_homography(\n",
    "        m['k0'],\n",
    "        m['k1'],\n",
    "        m['matches'],\n",
    "        reproj_thr=float(hparams['magsac_reproj_thr']),\n",
    "    )\n",
    "    dt_ms = (perf_counter() - t0) * 1000.0\n",
    "\n",
    "    raw_matches = int(m['matches'].shape[0])\n",
    "    inliers = int(inl.sum()) if inl is not None else 0\n",
    "\n",
    "    if H is None or inliers < int(hparams['min_inliers']):\n",
    "        return {\n",
    "            'pred_xy': (float(anchor_xy[0]), float(anchor_xy[1])),\n",
    "            'raw_matches': raw_matches,\n",
    "            'inliers': inliers,\n",
    "            'used_match': False,\n",
    "            'scale_expected': float(s_expected),\n",
    "            'scale_effective': float(s_eff),\n",
    "            'crop_w': int(map_crop.shape[1]),\n",
    "            'crop_h': int(map_crop.shape[0]),\n",
    "            'runtime_ms': float(dt_ms),\n",
    "        }\n",
    "\n",
    "    px, py = project_query_center(H, q_canvas.shape, offset_xy=(x0, y0))\n",
    "    if not (np.isfinite(px) and np.isfinite(py)):\n",
    "        px, py = float(anchor_xy[0]), float(anchor_xy[1])\n",
    "        used = False\n",
    "    else:\n",
    "        px = float(np.clip(px, 0, MAP_W - 1))\n",
    "        py = float(np.clip(py, 0, MAP_H - 1))\n",
    "        used = True\n",
    "\n",
    "    return {\n",
    "        'pred_xy': (float(px), float(py)),\n",
    "        'raw_matches': raw_matches,\n",
    "        'inliers': inliers,\n",
    "        'used_match': bool(used),\n",
    "        'scale_expected': float(s_expected),\n",
    "        'scale_effective': float(s_eff),\n",
    "        'crop_w': int(map_crop.shape[1]),\n",
    "        'crop_h': int(map_crop.shape[0]),\n",
    "        'runtime_ms': float(dt_ms),\n",
    "    }\n",
    "\n",
    "\n",
    "def localize_split(\n",
    "    query_df: pd.DataFrame,\n",
    "    split_name: str,\n",
    "    known_xy_init: Dict[int, Tuple[float, float]],\n",
    "    hm: HeightScaleModel,\n",
    "    hparams: Dict[str, float],\n",
    "    reverse_prefix_for_test: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    known_xy = dict(known_xy_init)\n",
    "\n",
    "    ids = query_df['id'].astype(int).tolist()\n",
    "    if split_name == 'test' and bool(reverse_prefix_for_test):\n",
    "        order = choose_processing_order(ids, reverse_anchor_id=int(TEST_REVERSE_ANCHOR_ID))\n",
    "    else:\n",
    "        order = sorted(ids)\n",
    "\n",
    "    row_by_id = {int(r.id): r for r in query_df.itertuples(index=False)}\n",
    "    gt_by_id = {}\n",
    "    if 'x_pixel' in query_df.columns and 'y_pixel' in query_df.columns:\n",
    "        for r in query_df.itertuples(index=False):\n",
    "            gt_by_id[int(r.id)] = (float(r.x_pixel), float(r.y_pixel))\n",
    "\n",
    "    rows = []\n",
    "    t_loop = perf_counter()\n",
    "    for j, qid in enumerate(order, 1):\n",
    "        row = row_by_id[int(qid)]\n",
    "        anchor_xy, anchor_id, anchor_src = get_anchor_xy(int(qid), known_xy)\n",
    "\n",
    "        out = localize_one_frame(\n",
    "            row=row,\n",
    "            split_name=split_name,\n",
    "            anchor_xy=anchor_xy,\n",
    "            hm=hm,\n",
    "            hparams=hparams,\n",
    "        )\n",
    "\n",
    "        pred_xy = out['pred_xy']\n",
    "        known_xy[int(qid)] = pred_xy\n",
    "\n",
    "        gt = gt_by_id.get(int(qid), (np.nan, np.nan))\n",
    "        err = np.nan if np.isnan(gt[0]) else float(np.hypot(pred_xy[0] - gt[0], pred_xy[1] - gt[1]))\n",
    "\n",
    "        rows.append({\n",
    "            'id': int(qid),\n",
    "            'pred_x': float(pred_xy[0]),\n",
    "            'pred_y': float(pred_xy[1]),\n",
    "            'gt_x': float(gt[0]),\n",
    "            'gt_y': float(gt[1]),\n",
    "            'err_px': err,\n",
    "            'anchor_id': int(anchor_id),\n",
    "            'anchor_source': anchor_src,\n",
    "            'raw_matches': int(out['raw_matches']),\n",
    "            'inliers': int(out['inliers']),\n",
    "            'used_match': bool(out['used_match']),\n",
    "            'scale_expected': float(out['scale_expected']),\n",
    "            'scale_effective': float(out['scale_effective']),\n",
    "            'crop_w': int(out['crop_w']),\n",
    "            'crop_h': int(out['crop_h']),\n",
    "            'runtime_ms': float(out['runtime_ms']),\n",
    "        })\n",
    "\n",
    "        if j % 10 == 0:\n",
    "            dt = perf_counter() - t_loop\n",
    "            print(f'[{split_name}] done {j}/{len(order)} | avg {dt/max(1,j):.2f}s/frame')\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values('id').reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline validation run\n",
    "matcher.min_conf = float(BASE_HPARAMS['match_min_conf'])\n",
    "\n",
    "val_pred_df = localize_split(\n",
    "    query_df=val_df,\n",
    "    split_name='val',\n",
    "    known_xy_init=fit_train_gt,\n",
    "    hm=height_model,\n",
    "    hparams=dict(BASE_HPARAMS),\n",
    "    reverse_prefix_for_test=False,\n",
    ")\n",
    "\n",
    "val_metrics = eval_metric_from_df(val_pred_df.dropna(subset=['gt_x', 'gt_y']))\n",
    "print(pd.Series(val_metrics))\n",
    "display(val_pred_df.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna optimization\n",
    "if RUN_OPTUNA and not OPTUNA_AVAILABLE:\n",
    "    raise ImportError('RUN_OPTUNA=True but optuna is not available. Install with: pip install optuna')\n",
    "\n",
    "\n",
    "def run_optuna_optimization(\n",
    "    n_trials: int = 15,\n",
    "    val_limit: int = 45,\n",
    "    timeout_s: Optional[int] = None,\n",
    "    seed: int = 123,\n",
    "):\n",
    "    val_sub = val_df.sort_values('id').head(int(min(val_limit, len(val_df))))\n",
    "\n",
    "    def objective(trial: 'optuna.trial.Trial') -> float:\n",
    "        hp = {\n",
    "            'match_min_conf': float(trial.suggest_float('match_min_conf', 0.05, 0.40)),\n",
    "            'magsac_reproj_thr': float(trial.suggest_float('magsac_reproj_thr', 1.5, 6.0)),\n",
    "            'virtual_zoom_out': float(trial.suggest_float('virtual_zoom_out', 1.1, 3.0)),\n",
    "            'crop_width_factor': float(trial.suggest_float('crop_width_factor', 2.6, 3.8)),\n",
    "            'crop_height_factor_n': float(trial.suggest_float('crop_height_factor_n', 4.0, 5.8)),\n",
    "            'min_inliers': int(trial.suggest_int('min_inliers', 8, 30)),\n",
    "            'scale_low_mul': float(trial.suggest_float('scale_low_mul', 0.70, 1.0)),\n",
    "            'scale_high_mul': float(trial.suggest_float('scale_high_mul', 1.0, 1.5)),\n",
    "        }\n",
    "\n",
    "        matcher.min_conf = float(hp['match_min_conf'])\n",
    "\n",
    "        t0 = perf_counter()\n",
    "        pred = localize_split(\n",
    "            query_df=val_sub,\n",
    "            split_name='val',\n",
    "            known_xy_init=fit_train_gt,\n",
    "            hm=height_model,\n",
    "            hparams=hp,\n",
    "            reverse_prefix_for_test=False,\n",
    "        )\n",
    "        met = eval_metric_from_df(pred.dropna(subset=['gt_x', 'gt_y']))\n",
    "        dt = perf_counter() - t0\n",
    "\n",
    "        trial.set_user_attr('mean_err_px', float(met['mean_err_px']))\n",
    "        trial.set_user_attr('runtime_s', float(dt))\n",
    "        return float(met['score'])\n",
    "\n",
    "    sampler = optuna.samplers.TPESampler(seed=int(seed))\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(objective, n_trials=int(n_trials), timeout=timeout_s)\n",
    "\n",
    "    rows = []\n",
    "    for t in study.trials:\n",
    "        row = {'trial': int(t.number), 'score': float(t.value) if t.value is not None else np.nan}\n",
    "        row.update(t.params)\n",
    "        row['mean_err_px'] = t.user_attrs.get('mean_err_px', np.nan)\n",
    "        row['runtime_s'] = t.user_attrs.get('runtime_s', np.nan)\n",
    "        rows.append(row)\n",
    "\n",
    "    trials_df = pd.DataFrame(rows).sort_values('score', ascending=False).reset_index(drop=True)\n",
    "    best_hp = dict(BASE_HPARAMS)\n",
    "    best_hp.update(study.best_trial.params)\n",
    "    return study, trials_df, best_hp\n",
    "\n",
    "\n",
    "if RUN_OPTUNA:\n",
    "    study, trials_df, best_hp = run_optuna_optimization(\n",
    "        n_trials=int(OPTUNA_TRIALS),\n",
    "        val_limit=int(OPTUNA_VAL_LIMIT),\n",
    "        timeout_s=OPTUNA_TIMEOUT_S,\n",
    "        seed=777,\n",
    "    )\n",
    "    print('best score:', study.best_value)\n",
    "    print('best params:', study.best_trial.params)\n",
    "    display(trials_df.head(10))\n",
    "else:\n",
    "    study = None\n",
    "    trials_df = pd.DataFrame()\n",
    "    best_hp = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation + test run\n",
    "final_hp = dict(BASE_HPARAMS)\n",
    "if best_hp is not None:\n",
    "    final_hp.update(best_hp)\n",
    "\n",
    "matcher.min_conf = float(final_hp['match_min_conf'])\n",
    "\n",
    "val_final_df = localize_split(\n",
    "    query_df=val_df,\n",
    "    split_name='val',\n",
    "    known_xy_init=fit_train_gt,\n",
    "    hm=height_model,\n",
    "    hparams=final_hp,\n",
    "    reverse_prefix_for_test=False,\n",
    ")\n",
    "val_final_metrics = eval_metric_from_df(val_final_df.dropna(subset=['gt_x', 'gt_y']))\n",
    "print('Final validation metrics:')\n",
    "print(pd.Series(val_final_metrics))\n",
    "\n",
    "# For test: reverse order for IDs < 13, anchor at id 13\n",
    "known_for_test = dict(all_train_gt)\n",
    "if TEST_REVERSE_ANCHOR_ID in all_train_gt:\n",
    "    known_for_test = {int(TEST_REVERSE_ANCHOR_ID): all_train_gt[int(TEST_REVERSE_ANCHOR_ID)], **known_for_test}\n",
    "\n",
    "test_final_df = localize_split(\n",
    "    query_df=test_cam_df,\n",
    "    split_name='test',\n",
    "    known_xy_init=known_for_test,\n",
    "    hm=height_model,\n",
    "    hparams=final_hp,\n",
    "    reverse_prefix_for_test=True,\n",
    ")\n",
    "print('test predicted:', len(test_final_df))\n",
    "display(test_final_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write submission.csv\n",
    "submission_df = test_final_df[['id', 'pred_x', 'pred_y']].copy()\n",
    "submission_df = submission_df.rename(columns={'pred_x': 'x_pixel', 'pred_y': 'y_pixel'})\n",
    "submission_df = submission_df.sort_values('id').reset_index(drop=True)\n",
    "\n",
    "SUBMISSION_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "submission_df.to_csv(SUBMISSION_OUT, index=False)\n",
    "print('written:', SUBMISSION_OUT)\n",
    "print(submission_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization on map.png\n",
    "fit_xy = fit_df[['x_pixel', 'y_pixel']].to_numpy(dtype=np.float32)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(map_rgb)\n",
    "\n",
    "if len(fit_xy) > 0:\n",
    "    plt.scatter(fit_xy[:, 0], fit_xy[:, 1], s=8, c='deepskyblue', alpha=0.60, label='fit GT anchors')\n",
    "\n",
    "if len(val_final_df) > 0:\n",
    "    v = val_final_df.dropna(subset=['gt_x', 'gt_y']).copy()\n",
    "    for r in v.itertuples(index=False):\n",
    "        plt.plot([r.pred_x, r.gt_x], [r.pred_y, r.gt_y], color='yellow', alpha=0.45, linewidth=1.0)\n",
    "    plt.scatter(v['gt_x'], v['gt_y'], s=20, c='lime', label='val GT')\n",
    "    plt.scatter(v['pred_x'], v['pred_y'], s=20, c='red', label='val Pred')\n",
    "\n",
    "if len(test_final_df) > 0:\n",
    "    plt.scatter(test_final_df['pred_x'], test_final_df['pred_y'], s=14, c='orange', alpha=0.75, label='test Pred')\n",
    "\n",
    "plt.title(\n",
    "    '08 SuperPoint+LightGlue+MAGSAC Gray/Edge Anchor Localization | '\n",
    "    f\"score={val_final_metrics['score']:.2f}\"\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match diagnostics: gray/edge filtered+scaled query vs filtered map crop\n",
    "\n",
    "def resolve_anchor_xy_for_debug(\n",
    "    res_row: pd.Series,\n",
    "    pred_df: pd.DataFrame,\n",
    "    known_xy_init: Dict[int, Tuple[float, float]],\n",
    ") -> Tuple[float, float]:\n",
    "    aid = int(round(float(res_row['anchor_id'])))\n",
    "    src = str(res_row.get('anchor_source', ''))\n",
    "\n",
    "    if src == 'train_gt' and aid in known_xy_init:\n",
    "        ax, ay = known_xy_init[aid]\n",
    "        return float(ax), float(ay)\n",
    "\n",
    "    pred_anchor = pred_df[pred_df['id'].astype(int) == aid]\n",
    "    if len(pred_anchor) > 0:\n",
    "        rr = pred_anchor.iloc[0]\n",
    "        px = float(rr['pred_x'])\n",
    "        py = float(rr['pred_y'])\n",
    "        if np.isfinite(px) and np.isfinite(py):\n",
    "            return px, py\n",
    "\n",
    "    if aid in known_xy_init:\n",
    "        ax, ay = known_xy_init[aid]\n",
    "        return float(ax), float(ay)\n",
    "\n",
    "    px = float(res_row['pred_x'])\n",
    "    py = float(res_row['pred_y'])\n",
    "    if np.isfinite(px) and np.isfinite(py):\n",
    "        return px, py\n",
    "\n",
    "    return float(MAP_W / 2.0), float(MAP_H / 2.0)\n",
    "\n",
    "\n",
    "def build_match_debug_for_id(\n",
    "    qid: int,\n",
    "    pred_df: pd.DataFrame,\n",
    "    cam_df: pd.DataFrame,\n",
    "    hm: HeightScaleModel,\n",
    "    hparams: Dict[str, float],\n",
    "    known_xy_init: Dict[int, Tuple[float, float]],\n",
    "    split_name: str = 'val',\n",
    ") -> Dict[str, object]:\n",
    "    row_pred_df = pred_df[pred_df['id'].astype(int) == int(qid)]\n",
    "    if len(row_pred_df) == 0:\n",
    "        raise ValueError(f'id={qid} not found in pred_df')\n",
    "    row_pred = row_pred_df.iloc[0]\n",
    "\n",
    "    row_cam_df = cam_df[cam_df['id'].astype(int) == int(qid)]\n",
    "    if len(row_cam_df) == 0:\n",
    "        raise ValueError(f'id={qid} not found in cam_df')\n",
    "    row_cam = row_cam_df.iloc[0]\n",
    "\n",
    "    split_for_img = 'val' if split_name == 'val' else 'test'\n",
    "    anchor_xy = resolve_anchor_xy_for_debug(row_pred, pred_df=pred_df, known_xy_init=known_xy_init)\n",
    "\n",
    "    q_proc = get_match_image(int(qid), split=split_for_img)\n",
    "\n",
    "    s_expected = compute_expected_scale(row_cam, hm=hm, hparams=hparams)\n",
    "    s_eff = float(s_expected / max(1e-6, float(hparams['virtual_zoom_out'])))\n",
    "\n",
    "    q_scaled = resize_rgb(q_proc, s_eff)\n",
    "    qh, qw = q_scaled.shape[:2]\n",
    "\n",
    "    crop_w = int(round(float(hparams['crop_width_factor']) * float(qw)))\n",
    "    crop_h = int(round(float(hparams['crop_height_factor_n']) * float(qh)))\n",
    "    crop_w = int(np.clip(crop_w, 64, MAP_W))\n",
    "    crop_h = int(np.clip(crop_h, 64, MAP_H))\n",
    "\n",
    "    q_canvas, q_offset = make_centered_canvas(q_scaled, out_w=crop_w, out_h=crop_h)\n",
    "    map_crop, x0, y0 = extract_crop_by_size(\n",
    "        map_proc,\n",
    "        center_xy=anchor_xy,\n",
    "        crop_w=crop_w,\n",
    "        crop_h=crop_h,\n",
    "    )\n",
    "\n",
    "    if q_canvas.shape[:2] != map_crop.shape[:2]:\n",
    "        q_canvas, q_offset = make_centered_canvas(q_scaled, out_w=map_crop.shape[1], out_h=map_crop.shape[0])\n",
    "\n",
    "    m = matcher.match(q_canvas, map_crop)\n",
    "    H, inl = matcher.magsac_homography(\n",
    "        m['k0'],\n",
    "        m['k1'],\n",
    "        m['matches'],\n",
    "        reproj_thr=float(hparams['magsac_reproj_thr']),\n",
    "    )\n",
    "\n",
    "    raw_matches = int(m['matches'].shape[0])\n",
    "    inliers = int(inl.sum()) if inl is not None else 0\n",
    "\n",
    "    used_match = False\n",
    "    pred_local_xy = (np.nan, np.nan)\n",
    "    if H is not None and inliers >= int(hparams['min_inliers']):\n",
    "        px_local, py_local = project_query_center(H, q_canvas.shape, offset_xy=(0.0, 0.0))\n",
    "        pred_local_xy = (float(px_local), float(py_local))\n",
    "        used_match = bool(np.isfinite(px_local) and np.isfinite(py_local))\n",
    "\n",
    "    anchor_local_xy = (float(anchor_xy[0] - x0), float(anchor_xy[1] - y0))\n",
    "\n",
    "    return {\n",
    "        'id': int(qid),\n",
    "        'anchor_id': int(row_pred['anchor_id']),\n",
    "        'anchor_source': str(row_pred['anchor_source']),\n",
    "        'q_scaled': q_scaled,\n",
    "        'q_canvas': q_canvas,\n",
    "        'q_offset': (int(q_offset[0]), int(q_offset[1])),\n",
    "        'map_crop': map_crop,\n",
    "        'x0': int(x0),\n",
    "        'y0': int(y0),\n",
    "        'scale_expected': float(s_expected),\n",
    "        'scale_effective': float(s_eff),\n",
    "        'match': m,\n",
    "        'H': H,\n",
    "        'inlier_mask': inl,\n",
    "        'raw_matches': raw_matches,\n",
    "        'inliers': inliers,\n",
    "        'used_match': bool(used_match),\n",
    "        'pred_local_xy': pred_local_xy,\n",
    "        'anchor_local_xy': anchor_local_xy,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_side_by_side_rgb(img_left: np.ndarray, img_right: np.ndarray) -> Tuple[np.ndarray, int]:\n",
    "    h = max(img_left.shape[0], img_right.shape[0])\n",
    "    w0 = img_left.shape[1]\n",
    "    w1 = img_right.shape[1]\n",
    "    canvas = np.zeros((h, w0 + w1, 3), dtype=img_left.dtype)\n",
    "    canvas[:img_left.shape[0], :w0] = img_left\n",
    "    canvas[:img_right.shape[0], w0:w0 + w1] = img_right\n",
    "    return canvas, int(w0)\n",
    "\n",
    "\n",
    "def draw_match_debug(debug: Dict[str, object], max_lines: int = 220, seed: int = 7) -> None:\n",
    "    q_canvas = debug['q_canvas']\n",
    "    map_crop = debug['map_crop']\n",
    "    combo, x_shift = make_side_by_side_rgb(q_canvas, map_crop)\n",
    "\n",
    "    m = debug['match']\n",
    "    n_total = int(m['matches'].shape[0])\n",
    "\n",
    "    inl = debug['inlier_mask']\n",
    "    if inl is None:\n",
    "        inl_mask = np.zeros((n_total,), dtype=bool)\n",
    "    else:\n",
    "        inl_mask = inl.astype(bool)\n",
    "        if inl_mask.shape[0] != n_total:\n",
    "            tmp = np.zeros((n_total,), dtype=bool)\n",
    "            n = min(n_total, inl_mask.shape[0])\n",
    "            tmp[:n] = inl_mask[:n]\n",
    "            inl_mask = tmp\n",
    "\n",
    "    draw_idx = np.arange(n_total)\n",
    "    if n_total > int(max_lines):\n",
    "        rng = np.random.default_rng(int(seed))\n",
    "        draw_idx = np.sort(rng.choice(draw_idx, size=int(max_lines), replace=False))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    ax.imshow(combo)\n",
    "    ax.axvline(x=float(x_shift) - 0.5, color='white', linewidth=1.0, alpha=0.9)\n",
    "\n",
    "    for i in draw_idx:\n",
    "        a = int(m['matches'][i, 0])\n",
    "        b = int(m['matches'][i, 1])\n",
    "        p0 = m['k0'][a]\n",
    "        p1 = m['k1'][b]\n",
    "        is_inlier = bool(inl_mask[i])\n",
    "        color = 'lime' if is_inlier else 'orangered'\n",
    "        lw = 1.2 if is_inlier else 0.6\n",
    "        alpha = 0.85 if is_inlier else 0.25\n",
    "        ax.plot([float(p0[0]), float(p1[0] + x_shift)], [float(p0[1]), float(p1[1])], color=color, linewidth=lw, alpha=alpha)\n",
    "\n",
    "    if n_total > 0:\n",
    "        ax.scatter(m['k0'][:, 0], m['k0'][:, 1], s=7, c='deepskyblue', alpha=0.55)\n",
    "        ax.scatter(m['k1'][:, 0] + x_shift, m['k1'][:, 1], s=7, c='orange', alpha=0.55)\n",
    "\n",
    "    qx0, qy0 = debug['q_offset']\n",
    "    qh, qw = debug['q_scaled'].shape[:2]\n",
    "    q_rect = plt.Rectangle(\n",
    "        (float(qx0), float(qy0)),\n",
    "        float(qw),\n",
    "        float(qh),\n",
    "        fill=False,\n",
    "        linewidth=1.2,\n",
    "        edgecolor='cyan',\n",
    "        linestyle='--',\n",
    "        alpha=0.9,\n",
    "    )\n",
    "    ax.add_patch(q_rect)\n",
    "\n",
    "    ax.scatter(\n",
    "        [float(debug['anchor_local_xy'][0] + x_shift)],\n",
    "        [float(debug['anchor_local_xy'][1])],\n",
    "        marker='x',\n",
    "        c='white',\n",
    "        s=70,\n",
    "        linewidths=1.4,\n",
    "    )\n",
    "\n",
    "    px_local, py_local = debug['pred_local_xy']\n",
    "    if np.isfinite(px_local) and np.isfinite(py_local):\n",
    "        ax.scatter([float(px_local + x_shift)], [float(py_local)], marker='*', c='yellow', s=120)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"ID {debug['id']} | left: gray/edge filtered+scaled query (canvas, cyan box=scaled content) | \"\n",
    "        f\"right: gray/edge filtered map crop | matches={debug['raw_matches']} inliers={debug['inliers']}\"\n",
    "    )\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Set DEBUG_VIS_ID to inspect a specific validation frame, e.g. DEBUG_VIS_ID = 28\n",
    "DEBUG_VIS_ID = None\n",
    "\n",
    "diag_pred_df = val_final_df if 'val_final_df' in globals() else val_pred_df\n",
    "diag_hparams = final_hp if 'final_hp' in globals() else dict(BASE_HPARAMS)\n",
    "\n",
    "if len(diag_pred_df) == 0:\n",
    "    print('No validation predictions available for debug visualization.')\n",
    "else:\n",
    "    if DEBUG_VIS_ID is None:\n",
    "        by_err = diag_pred_df.dropna(subset=['err_px'])\n",
    "        if len(by_err) > 0:\n",
    "            DEBUG_VIS_ID = int(by_err.sort_values('err_px', ascending=False).iloc[0]['id'])\n",
    "        else:\n",
    "            DEBUG_VIS_ID = int(diag_pred_df.sort_values('id').iloc[0]['id'])\n",
    "\n",
    "    old_min_conf = float(matcher.min_conf)\n",
    "    matcher.min_conf = float(diag_hparams['match_min_conf'])\n",
    "    try:\n",
    "        debug = build_match_debug_for_id(\n",
    "            qid=int(DEBUG_VIS_ID),\n",
    "            pred_df=diag_pred_df,\n",
    "            cam_df=val_df,\n",
    "            hm=height_model,\n",
    "            hparams=diag_hparams,\n",
    "            known_xy_init=fit_train_gt,\n",
    "            split_name='val',\n",
    "        )\n",
    "    finally:\n",
    "        matcher.min_conf = old_min_conf\n",
    "\n",
    "    draw_match_debug(debug, max_lines=220, seed=7)\n",
    "    print({\n",
    "        'id': int(debug['id']),\n",
    "        'anchor_id': int(debug['anchor_id']),\n",
    "        'anchor_source': debug['anchor_source'],\n",
    "        'raw_matches': int(debug['raw_matches']),\n",
    "        'inliers': int(debug['inliers']),\n",
    "        'used_match': bool(debug['used_match']),\n",
    "        'scale_effective': float(debug['scale_effective']),\n",
    "        'query_scaled_shape_hw': tuple(int(x) for x in debug['q_scaled'].shape[:2]),\n",
    "        'query_canvas_shape_hw': tuple(int(x) for x in debug['q_canvas'].shape[:2]),\n",
    "        'map_crop_shape_hw': tuple(int(x) for x in debug['map_crop'].shape[:2]),\n",
    "    })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics\n",
    "print('Anchor sources (val):')\n",
    "print(val_final_df['anchor_source'].value_counts(dropna=False))\n",
    "\n",
    "print('Matching usage (val):')\n",
    "print(val_final_df['used_match'].value_counts(dropna=False))\n",
    "\n",
    "print('Inliers stats (val):')\n",
    "print(val_final_df['inliers'].describe())\n",
    "\n",
    "display(val_final_df[[\n",
    "    'id', 'err_px', 'anchor_source', 'raw_matches', 'inliers',\n",
    "    'scale_expected', 'scale_effective', 'crop_w', 'crop_h', 'runtime_ms'\n",
    "]].head(40))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
