{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 11 - SuperPoint + LightGlue Pair Localization Tuning\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Ziel\nDieses Notebook optimiert **nur** SuperPoint+LightGlue fuer die Paar-Lokalisierung `anchor -> val` gegen einen konstanten Map-Crop.\n\n- Gray-basierte Filter (inkl. CLAHE, Denoise, Edge-Varianten)\n- Rotation + Skalierung werden ueber Sweep beruecksichtigt\n- Auto-Tuning erweitert Hyperparameter stufenweise, bis `TARGET_INLIERS` erreicht ist oder alle Runden durchlaufen sind\n- Visualisierung wie in deinem Beispiel: 4-Spalten-Matchbild plus Map-Overlay mit GT vs Prediction\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from dataclasses import dataclass\nfrom pathlib import Path\nfrom itertools import product\nfrom copy import deepcopy\nfrom time import perf_counter\nfrom typing import Dict, List, Optional, Tuple\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nfrom IPython.display import display\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dependencies: SuperPoint + LightGlue required\ntry:\n    from lightglue import LightGlue, SuperPoint\n    from lightglue.utils import rbd\nexcept Exception as e:\n    raise ImportError('This notebook requires LightGlue+SuperPoint. Install with: pip install lightglue') from e\n\n# Paths\nCANDIDATE_ROOTS = [Path.cwd(), Path.cwd().parent, Path('.'), Path('..')]\nPROJECT_ROOT = None\n_seen = set()\nfor cand in CANDIDATE_ROOTS:\n    try:\n        root = cand.resolve()\n    except Exception:\n        continue\n    k = str(root)\n    if k in _seen:\n        continue\n    _seen.add(k)\n    if (root / 'data' / 'data').exists():\n        PROJECT_ROOT = root\n        break\nif PROJECT_ROOT is None:\n    raise FileNotFoundError('Could not find project root containing data/data.')\n\nDATA_ROOT = PROJECT_ROOT / 'data' / 'data'\nTRAIN_IMG_DIR = DATA_ROOT / 'train_data' / 'train_images'\nTRAIN_POS_CSV = DATA_ROOT / 'train_data' / 'train_pos.csv'\nTRAIN_CAM_CSV = DATA_ROOT / 'train_data' / 'train_cam.csv'\nMAP_PATH = DATA_ROOT / 'map.png'\n\n# Runtime\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nIMAGE_MAX_SIDE = 1280\nRNG_SEED = 7\n\n# Pair selection\nPAIR_ANCHOR_ID = 13\nPAIR_VAL_ID = 14\nPREVIEW_PAIR_INDEX = 0\n\n# Constant map crop around anchor GT\nCONST_MAP_CROP_BASE_PX = 900\nCONST_MAP_CROP_SCALE = 1.00\nCONST_MAP_CROP_MIN_PX = 240\nCONST_MAP_CROP_MAX_PX = 2200\n\n# Matching goal\nTARGET_INLIERS = 100\nMIN_INLIERS_FOR_POSE = 8\n\n# Tuning control\nMAX_CONFIGS_PER_LEVEL = 100\nAUTO_EXPAND_MAX_ROUNDS = 4\n\n# Gray filter params\nCLAHE_CLIP_LIMIT = 2.5\nCLAHE_GRID = (8, 8)\nEDGE_CANNY_LOW = 50\nEDGE_CANNY_HIGH = 150\nEDGE_DILATE_KERNEL = 2\nEDGE_BLEND_GRAY = 0.75\nEDGE_BLEND_EDGE = 0.25\n\nprint('project_root:', PROJECT_ROOT)\nprint('device:', DEVICE)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load train data and build consecutive pairs\ntrain_pos_df = pd.read_csv(TRAIN_POS_CSV)\ntrain_cam_df = pd.read_csv(TRAIN_CAM_CSV)\ntrain_df = train_cam_df.merge(train_pos_df, on='id', how='inner').copy()\ntrain_df['id'] = train_df['id'].astype(int)\ntrain_df = train_df.sort_values('id').reset_index(drop=True)\n\nfor col in ['id', 'x_pixel', 'y_pixel']:\n    if col not in train_df.columns:\n        raise KeyError(f'Missing required column: {col}')\n\nmap_bgr = cv2.imread(str(MAP_PATH), cv2.IMREAD_COLOR)\nif map_bgr is None:\n    raise FileNotFoundError(f'Map not found: {MAP_PATH}')\nmap_rgb = cv2.cvtColor(map_bgr, cv2.COLOR_BGR2RGB)\nMAP_H, MAP_W = map_rgb.shape[:2]\n\npairs = []\nfor i in range(len(train_df) - 1):\n    r0 = train_df.iloc[i]\n    r1 = train_df.iloc[i + 1]\n    id0 = int(r0['id'])\n    id1 = int(r1['id'])\n    if id1 != id0 + 1:\n        continue\n    pairs.append({\n        'pair_idx': int(len(pairs)),\n        'anchor_id': id0,\n        'val_id': id1,\n        'anchor_x': float(r0['x_pixel']),\n        'anchor_y': float(r0['y_pixel']),\n        'val_gt_x': float(r1['x_pixel']),\n        'val_gt_y': float(r1['y_pixel']),\n    })\n\npair_df = pd.DataFrame(pairs)\nif len(pair_df) == 0:\n    raise RuntimeError('No consecutive pairs found in train data.')\n\nprint('consecutive pairs:', len(pair_df), '| map size:', (MAP_W, MAP_H))\ndisplay(pair_df.head(20))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Utilities: image loading, crop, gray preprocessing\n_IMAGE_CACHE: Dict[Tuple[int, Optional[int]], np.ndarray] = {}\n\n\ndef resolve_train_image_path(image_id: int) -> Path:\n    stems = [f'{int(image_id):04d}', str(int(image_id))]\n    exts = ['.JPG', '.jpg', '.jpeg', '.JPEG', '.png', '.PNG']\n    for st in stems:\n        for ext in exts:\n            p = TRAIN_IMG_DIR / f'{st}{ext}'\n            if p.exists():\n                return p\n    raise FileNotFoundError(f'Image not found for id={image_id} in {TRAIN_IMG_DIR}')\n\n\ndef resize_keep_aspect(img_rgb: np.ndarray, max_side: Optional[int]) -> np.ndarray:\n    if max_side is None:\n        return img_rgb\n    h, w = img_rgb.shape[:2]\n    m = max(h, w)\n    if m <= int(max_side):\n        return img_rgb\n    s = float(max_side) / float(m)\n    nw = max(32, int(round(w * s)))\n    nh = max(32, int(round(h * s)))\n    return cv2.resize(img_rgb, (nw, nh), interpolation=cv2.INTER_AREA)\n\n\ndef load_train_image_cached(image_id: int, max_side: Optional[int]) -> np.ndarray:\n    key = (int(image_id), max_side)\n    if key in _IMAGE_CACHE:\n        return _IMAGE_CACHE[key]\n\n    p = resolve_train_image_path(int(image_id))\n    bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n    if bgr is None:\n        raise RuntimeError(f'Cannot read image: {p}')\n    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n    rgb = resize_keep_aspect(rgb, max_side=max_side)\n    _IMAGE_CACHE[key] = rgb\n    return rgb\n\n\ndef resize_rgb(img: np.ndarray, scale: float) -> np.ndarray:\n    h, w = img.shape[:2]\n    nw = max(12, int(round(w * float(scale))))\n    nh = max(12, int(round(h * float(scale))))\n    return cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n\n\ndef rotate_rgb_keep_size(img: np.ndarray, angle_deg: float) -> np.ndarray:\n    h, w = img.shape[:2]\n    M = cv2.getRotationMatrix2D((w / 2.0, h / 2.0), float(angle_deg), 1.0)\n    return cv2.warpAffine(\n        img,\n        M,\n        (w, h),\n        flags=cv2.INTER_LINEAR,\n        borderMode=cv2.BORDER_REFLECT101,\n    )\n\n\ndef extract_crop_by_size(map_img: np.ndarray, center_xy: Tuple[float, float], crop_w: int, crop_h: int) -> Tuple[np.ndarray, int, int]:\n    cw = int(max(32, crop_w))\n    ch = int(max(32, crop_h))\n\n    cx, cy = float(center_xy[0]), float(center_xy[1])\n    x0 = int(round(cx - cw / 2.0))\n    y0 = int(round(cy - ch / 2.0))\n    x0 = int(np.clip(x0, 0, max(0, map_img.shape[1] - cw)))\n    y0 = int(np.clip(y0, 0, max(0, map_img.shape[0] - ch)))\n\n    x1 = min(map_img.shape[1], x0 + cw)\n    y1 = min(map_img.shape[0], y0 + ch)\n    crop = map_img[y0:y1, x0:x1]\n    return crop, x0, y0\n\n\ndef to_gray(img_rgb: np.ndarray) -> np.ndarray:\n    return cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n\n\ndef _edges(g: np.ndarray) -> np.ndarray:\n    e = cv2.Canny(g, int(EDGE_CANNY_LOW), int(EDGE_CANNY_HIGH))\n    k = int(max(1, EDGE_DILATE_KERNEL))\n    if k > 1:\n        e = cv2.dilate(e, np.ones((k, k), dtype=np.uint8), iterations=1)\n    return e\n\n\ndef preprocess_gray_variant(img_rgb: np.ndarray, variant: str) -> np.ndarray:\n    g = to_gray(img_rgb)\n\n    if variant == 'gray':\n        out = g\n    elif variant == 'gray_clahe':\n        clahe = cv2.createCLAHE(clipLimit=float(CLAHE_CLIP_LIMIT), tileGridSize=tuple(CLAHE_GRID))\n        out = clahe.apply(g)\n    elif variant == 'gray_clahe_blur':\n        clahe = cv2.createCLAHE(clipLimit=float(CLAHE_CLIP_LIMIT), tileGridSize=tuple(CLAHE_GRID))\n        out = cv2.GaussianBlur(clahe.apply(g), (3, 3), 0)\n    elif variant == 'gray_denoise':\n        out = cv2.bilateralFilter(g, d=7, sigmaColor=50, sigmaSpace=50)\n    elif variant == 'gray_edge_binary':\n        out = _edges(g)\n    elif variant == 'gray_edge_blend':\n        e = _edges(g)\n        out = cv2.addWeighted(g, float(EDGE_BLEND_GRAY), e, float(EDGE_BLEND_EDGE), 0.0)\n    elif variant == 'gray_tophat':\n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n        bg = cv2.morphologyEx(g, cv2.MORPH_OPEN, kernel)\n        top = cv2.subtract(g, bg)\n        out = cv2.normalize(top, None, 0, 255, cv2.NORM_MINMAX)\n    else:\n        raise KeyError(f'Unknown gray variant: {variant}')\n\n    return cv2.cvtColor(out.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n\n\ndef prepare_pair_data(pr: pd.Series) -> Dict[str, object]:\n    anchor_xy = (float(pr['anchor_x']), float(pr['anchor_y']))\n    val_xy = (float(pr['val_gt_x']), float(pr['val_gt_y']))\n\n    anchor_rgb = load_train_image_cached(int(pr['anchor_id']), max_side=IMAGE_MAX_SIDE)\n    val_rgb = load_train_image_cached(int(pr['val_id']), max_side=IMAGE_MAX_SIDE)\n\n    tile_size = int(np.clip(\n        round(float(CONST_MAP_CROP_BASE_PX) * float(CONST_MAP_CROP_SCALE)),\n        int(CONST_MAP_CROP_MIN_PX),\n        min(MAP_W, MAP_H, int(CONST_MAP_CROP_MAX_PX)),\n    ))\n    crop_rgb, x0, y0 = extract_crop_by_size(map_rgb, center_xy=anchor_xy, crop_w=tile_size, crop_h=tile_size)\n\n    return {\n        'anchor_rgb': anchor_rgb,\n        'val_rgb': val_rgb,\n        'crop_rgb': crop_rgb,\n        'anchor_local': (float(anchor_xy[0] - x0), float(anchor_xy[1] - y0)),\n        'val_local': (float(val_xy[0] - x0), float(val_xy[1] - y0)),\n        'crop_origin': (int(x0), int(y0)),\n    }\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# SuperPoint + LightGlue matcher\n@dataclass\nclass MatchResult:\n    k0: np.ndarray\n    k1: np.ndarray\n    matches: np.ndarray\n    conf: np.ndarray\n\n\nclass SuperPointLightGlueMatcher:\n    def __init__(self, max_num_keypoints: int, device: Optional[str] = None):\n        self.max_num_keypoints = int(max_num_keypoints)\n        self.device = device or DEVICE\n        self.extractor = None\n        self.matcher = None\n\n    def _lazy_init(self):\n        if self.extractor is not None and self.matcher is not None:\n            return\n        self.extractor = SuperPoint(max_num_keypoints=self.max_num_keypoints).eval().to(self.device)\n        self.matcher = LightGlue(features='superpoint').eval().to(self.device)\n\n    def _to_tensor(self, img_rgb: np.ndarray) -> torch.Tensor:\n        gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n        return (torch.from_numpy(gray).float()[None, None] / 255.0).to(self.device)\n\n    @torch.inference_mode()\n    def match(self, img0_rgb: np.ndarray, img1_rgb: np.ndarray, min_conf: float) -> MatchResult:\n        self._lazy_init()\n\n        t0 = self._to_tensor(img0_rgb)\n        t1 = self._to_tensor(img1_rgb)\n\n        f0 = self.extractor.extract(t0)\n        f1 = self.extractor.extract(t1)\n        out = self.matcher({'image0': f0, 'image1': f1})\n        f0, f1, out = [rbd(x) for x in [f0, f1, out]]\n\n        k0 = f0['keypoints'].detach().cpu().numpy().astype(np.float32)\n        k1 = f1['keypoints'].detach().cpu().numpy().astype(np.float32)\n        m = out['matches'].detach().cpu().numpy().astype(np.int32)\n\n        if m.size == 0:\n            return MatchResult(k0, k1, np.zeros((0, 2), np.int32), np.zeros((0,), np.float32))\n\n        if m.ndim != 2:\n            m = m.reshape(-1, 2)\n\n        if 'scores' in out:\n            conf = out['scores'].detach().cpu().numpy().astype(np.float32)\n        else:\n            conf = np.ones((m.shape[0],), dtype=np.float32)\n\n        if conf.shape[0] != m.shape[0]:\n            conf = np.ones((m.shape[0],), dtype=np.float32)\n\n        keep = conf >= float(min_conf)\n        return MatchResult(k0, k1, m[keep], conf[keep])\n\n\n_MATCHER_CACHE: Dict[int, SuperPointLightGlueMatcher] = {}\n\n\ndef get_matcher(max_kp: int) -> SuperPointLightGlueMatcher:\n    k = int(max_kp)\n    if k not in _MATCHER_CACHE:\n        _MATCHER_CACHE[k] = SuperPointLightGlueMatcher(max_num_keypoints=k, device=DEVICE)\n    return _MATCHER_CACHE[k]\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Matching geometry + scale/rotation sweep\n\ndef magsac_homography(k0: np.ndarray, k1: np.ndarray, matches: np.ndarray, reproj_thr: float) -> Tuple[Optional[np.ndarray], np.ndarray]:\n    if matches.shape[0] < 8:\n        return None, np.zeros((matches.shape[0],), dtype=bool)\n\n    p0 = k0[matches[:, 0]].astype(np.float32)\n    p1 = k1[matches[:, 1]].astype(np.float32)\n\n    H, mask = cv2.findHomography(\n        p0,\n        p1,\n        method=cv2.USAC_MAGSAC,\n        ransacReprojThreshold=float(reproj_thr),\n        maxIters=10000,\n        confidence=0.999,\n    )\n    if H is None or mask is None:\n        return None, np.zeros((matches.shape[0],), dtype=bool)\n    return H, mask.ravel().astype(bool)\n\n\ndef project_point_homography(H: np.ndarray, xy: Tuple[float, float]) -> Tuple[float, float]:\n    p = np.array([float(xy[0]), float(xy[1]), 1.0], dtype=np.float64)\n    q = H @ p\n    if abs(float(q[2])) < 1e-12:\n        return np.nan, np.nan\n    return float(q[0] / q[2]), float(q[1] / q[2])\n\n\ndef estimate_rot_scale_from_h(H: np.ndarray, q_shape: Tuple[int, int, int]) -> Tuple[float, float]:\n    hq, wq = q_shape[:2]\n    c = (wq * 0.5, hq * 0.5)\n    x = (wq * 0.75, hq * 0.5)\n    y = (wq * 0.5, hq * 0.75)\n\n    c2 = project_point_homography(H, c)\n    x2 = project_point_homography(H, x)\n    y2 = project_point_homography(H, y)\n\n    if not all(np.isfinite(v) for v in [c2[0], c2[1], x2[0], x2[1], y2[0], y2[1]]):\n        return np.nan, np.nan\n\n    dx0 = x[0] - c[0]\n    dy0 = x[1] - c[1]\n    dx1 = x2[0] - c2[0]\n    dy1 = x2[1] - c2[1]\n\n    rot_deg = float(np.degrees(np.arctan2(dy1, dx1) - np.arctan2(dy0, dx0)))\n\n    sx = np.hypot(dx1, dy1) / max(1e-8, np.hypot(dx0, dy0))\n    sy = np.hypot(y2[0] - c2[0], y2[1] - c2[1]) / max(1e-8, np.hypot(y[0] - c[0], y[1] - c[1]))\n    sc = float(0.5 * (sx + sy))\n    return rot_deg, sc\n\n\ndef build_reference(crop_rgb: np.ndarray, anchor_local: Tuple[float, float], strategy: str, roi_factor: float) -> Tuple[np.ndarray, int, int]:\n    if strategy == 'direct':\n        return crop_rgb, 0, 0\n    if strategy == 'anchor_roi':\n        h, w = crop_rgb.shape[:2]\n        rw = int(np.clip(round(float(w) * float(roi_factor)), 96, w))\n        rh = int(np.clip(round(float(h) * float(roi_factor)), 96, h))\n        return extract_crop_by_size(crop_rgb, center_xy=anchor_local, crop_w=rw, crop_h=rh)\n    raise ValueError(f'Unknown strategy: {strategy}')\n\n\ndef run_sp_lg_sweep(\n    query_rgb: np.ndarray,\n    crop_rgb: np.ndarray,\n    anchor_local: Tuple[float, float],\n    gt_local: Tuple[float, float],\n    strategy: str,\n    roi_factor: float,\n    max_kp: int,\n    min_conf: float,\n    reproj_thr: float,\n    scales: List[float],\n    rots_deg: List[float],\n) -> Dict[str, object]:\n    ref_rgb, rx, ry = build_reference(crop_rgb, anchor_local=anchor_local, strategy=strategy, roi_factor=roi_factor)\n    matcher = get_matcher(max_kp=max_kp)\n\n    best = None\n\n    for s in scales:\n        s = float(s)\n        if s <= 0.0:\n            continue\n        q_s = resize_rgb(query_rgb, s) if abs(s - 1.0) > 1e-6 else query_rgb\n\n        for rdeg in rots_deg:\n            rdeg = float(rdeg)\n            q_sr = rotate_rgb_keep_size(q_s, rdeg) if abs(rdeg) > 1e-6 else q_s\n\n            try:\n                m = matcher.match(q_sr, ref_rgb, min_conf=min_conf)\n                H, inl = magsac_homography(m.k0, m.k1, m.matches, reproj_thr=reproj_thr)\n                raw = int(m.matches.shape[0])\n                inliers = int(inl.sum()) if inl is not None else 0\n\n                if H is not None and inliers >= int(MIN_INLIERS_FOR_POSE):\n                    q_center = (float(q_sr.shape[1] * 0.5), float(q_sr.shape[0] * 0.5))\n                    px_ref, py_ref = project_point_homography(H, q_center)\n                    if np.isfinite(px_ref) and np.isfinite(py_ref):\n                        pred = (float(px_ref + rx), float(py_ref + ry))\n                        err_px = float(np.hypot(pred[0] - gt_local[0], pred[1] - gt_local[1]))\n                    else:\n                        pred = (np.nan, np.nan)\n                        err_px = np.nan\n                    est_rot_deg, est_scale = estimate_rot_scale_from_h(H, q_sr.shape)\n                else:\n                    pred = (np.nan, np.nan)\n                    err_px = np.nan\n                    est_rot_deg, est_scale = np.nan, np.nan\n\n                conf_mean = float(m.conf.mean()) if m.conf.shape[0] > 0 else 0.0\n                err_rank = -float(err_px) if np.isfinite(err_px) else -1e6\n                score = (inliers, raw, err_rank, conf_mean)\n\n                cand = {\n                    'ok': True,\n                    'query_used': q_sr,\n                    'ref_used': ref_rgb,\n                    'ref_offset': (int(rx), int(ry)),\n                    'scale_used': s,\n                    'rot_used_deg': rdeg,\n                    'match': m,\n                    'H': H,\n                    'inlier_mask': inl,\n                    'raw_matches': raw,\n                    'inliers': inliers,\n                    'pred_local': pred,\n                    'err_px': err_px,\n                    'est_rot_deg': est_rot_deg,\n                    'est_scale': est_scale,\n                    'score': score,\n                }\n            except Exception as e:\n                cand = {\n                    'ok': False,\n                    'error': str(e),\n                    'query_used': q_sr,\n                    'ref_used': ref_rgb,\n                    'ref_offset': (int(rx), int(ry)),\n                    'scale_used': s,\n                    'rot_used_deg': rdeg,\n                    'match': MatchResult(\n                        k0=np.zeros((0, 2), dtype=np.float32),\n                        k1=np.zeros((0, 2), dtype=np.float32),\n                        matches=np.zeros((0, 2), dtype=np.int32),\n                        conf=np.zeros((0,), dtype=np.float32),\n                    ),\n                    'H': None,\n                    'inlier_mask': np.zeros((0,), dtype=bool),\n                    'raw_matches': 0,\n                    'inliers': 0,\n                    'pred_local': (np.nan, np.nan),\n                    'err_px': np.nan,\n                    'est_rot_deg': np.nan,\n                    'est_scale': np.nan,\n                    'score': (-1, -1, -1e9, -1.0),\n                }\n\n            if best is None or cand['score'] > best['score']:\n                best = cand\n\n    if best is None:\n        best = {\n            'ok': False,\n            'query_used': query_rgb,\n            'ref_used': ref_rgb,\n            'ref_offset': (int(rx), int(ry)),\n            'scale_used': 1.0,\n            'rot_used_deg': 0.0,\n            'match': MatchResult(\n                k0=np.zeros((0, 2), dtype=np.float32),\n                k1=np.zeros((0, 2), dtype=np.float32),\n                matches=np.zeros((0, 2), dtype=np.int32),\n                conf=np.zeros((0,), dtype=np.float32),\n            ),\n            'H': None,\n            'inlier_mask': np.zeros((0,), dtype=bool),\n            'raw_matches': 0,\n            'inliers': 0,\n            'pred_local': (np.nan, np.nan),\n            'err_px': np.nan,\n            'est_rot_deg': np.nan,\n            'est_scale': np.nan,\n            'score': (-1, -1, -1e9, -1.0),\n        }\n\n    return best\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Auto-tuning (hyperparameter search + auto-expansion until target)\nBASE_SEARCH_LEVELS = [\n    {\n        'name': 'L1_coarse',\n        'max_kp': [4096],\n        'min_conf': [0.05, 0.03],\n        'reproj_thr': [3.0, 4.0],\n        'filter': ['gray', 'gray_clahe', 'gray_clahe_blur'],\n        'strategy': ['direct'],\n        'roi_factor': [1.0],\n        'crop_scale': [1.0],\n        'scales': [0.25, 0.35, 0.50, 0.70, 1.00],\n        'rots': [-20, -10, 0, 10, 20],\n    },\n    {\n        'name': 'L2_wider',\n        'max_kp': [4096, 8192],\n        'min_conf': [0.03, 0.01],\n        'reproj_thr': [3.0, 4.0, 6.0],\n        'filter': ['gray', 'gray_clahe', 'gray_clahe_blur', 'gray_denoise', 'gray_edge_blend'],\n        'strategy': ['direct', 'anchor_roi'],\n        'roi_factor': [1.0, 0.85, 0.70],\n        'crop_scale': [1.0, 1.2],\n        'scales': [0.18, 0.25, 0.35, 0.50, 0.70, 1.00, 1.30],\n        'rots': [-35, -25, -15, -8, 0, 8, 15, 25, 35],\n    },\n    {\n        'name': 'L3_aggressive',\n        'max_kp': [8192, 12000],\n        'min_conf': [0.01, 0.005],\n        'reproj_thr': [4.0, 6.0, 8.0],\n        'filter': ['gray', 'gray_clahe', 'gray_clahe_blur', 'gray_denoise', 'gray_edge_blend', 'gray_edge_binary', 'gray_tophat'],\n        'strategy': ['direct', 'anchor_roi'],\n        'roi_factor': [1.0, 0.85, 0.70, 0.55],\n        'crop_scale': [1.0, 1.2, 1.5],\n        'scales': [0.12, 0.16, 0.24, 0.35, 0.50, 0.70, 1.00, 1.40, 1.80],\n        'rots': [-60, -45, -35, -25, -15, 0, 15, 25, 35, 45, 60],\n    },\n]\n\n\ndef expand_level(level: Dict[str, object], round_idx: int) -> Dict[str, object]:\n    lvl = deepcopy(level)\n    if round_idx <= 0:\n        return lvl\n\n    # progressively relax and enlarge search\n    kp_extra = int(round(max(lvl['max_kp']) * (1.0 + 0.35 * round_idx)))\n    lvl['max_kp'] = sorted(set([int(x) for x in lvl['max_kp']] + [kp_extra]))\n\n    min_conf_floor = max(0.001, float(min(lvl['min_conf'])) * (0.6 ** round_idx))\n    lvl['min_conf'] = sorted(set([float(x) for x in lvl['min_conf']] + [min_conf_floor]), reverse=True)\n\n    max_rot = max(abs(float(x)) for x in lvl['rots']) + 10.0 * round_idx\n    lvl['rots'] = sorted(set([float(x) for x in lvl['rots']] + [-max_rot, max_rot]))\n\n    smin = min(float(x) for x in lvl['scales'])\n    smax = max(float(x) for x in lvl['scales'])\n    lvl['scales'] = sorted(set([float(x) for x in lvl['scales']] + [max(0.08, smin * 0.8), min(2.6, smax * 1.2)]))\n\n    cmax = max(float(x) for x in lvl['crop_scale'])\n    lvl['crop_scale'] = sorted(set([float(x) for x in lvl['crop_scale']] + [min(2.2, cmax + 0.2 * round_idx)]))\n\n    if round_idx >= 2:\n        lvl['strategy'] = sorted(set([str(x) for x in lvl['strategy']] + ['anchor_roi']))\n        lvl['roi_factor'] = sorted(set([float(x) for x in lvl['roi_factor']] + [0.45]))\n\n    return lvl\n\n\ndef build_configs(level: Dict[str, object]) -> List[Dict[str, object]]:\n    cfgs = []\n    for mkp, mcf, rpt, fil, strat, rfac, csc in product(\n        level['max_kp'],\n        level['min_conf'],\n        level['reproj_thr'],\n        level['filter'],\n        level['strategy'],\n        level['roi_factor'],\n        level['crop_scale'],\n    ):\n        if str(strat) == 'direct' and float(rfac) != 1.0:\n            continue\n        cfgs.append({\n            'level': str(level['name']),\n            'max_kp': int(mkp),\n            'min_conf': float(mcf),\n            'reproj_thr': float(rpt),\n            'filter': str(fil),\n            'strategy': str(strat),\n            'roi_factor': float(rfac),\n            'crop_scale': float(csc),\n            'scales': [float(x) for x in level['scales']],\n            'rots': [float(x) for x in level['rots']],\n        })\n    return cfgs\n\n\ndef sample_configs(cfgs: List[Dict[str, object]], max_n: int, seed: int = 7) -> List[Dict[str, object]]:\n    if len(cfgs) <= int(max_n):\n        return cfgs\n    rng = np.random.default_rng(int(seed))\n    idx = np.sort(rng.choice(np.arange(len(cfgs)), size=int(max_n), replace=False))\n    return [cfgs[int(i)] for i in idx]\n\n\ndef evaluate_config_for_pair(pr: pd.Series, cfg: Dict[str, object]) -> Dict[str, object]:\n    data = prepare_pair_data(pr)\n\n    # optional larger crop around anchor\n    if abs(float(cfg['crop_scale']) - 1.0) > 1e-6:\n        crop_h, crop_w = data['crop_rgb'].shape[:2]\n        new_w = int(np.clip(round(crop_w * float(cfg['crop_scale'])), int(CONST_MAP_CROP_MIN_PX), min(MAP_W, int(CONST_MAP_CROP_MAX_PX))))\n        new_h = int(np.clip(round(crop_h * float(cfg['crop_scale'])), int(CONST_MAP_CROP_MIN_PX), min(MAP_H, int(CONST_MAP_CROP_MAX_PX))))\n\n        anchor_global = (float(pr['anchor_x']), float(pr['anchor_y']))\n        crop2, x2, y2 = extract_crop_by_size(map_rgb, center_xy=anchor_global, crop_w=new_w, crop_h=new_h)\n        data['crop_rgb'] = crop2\n        data['crop_origin'] = (int(x2), int(y2))\n        data['anchor_local'] = (float(anchor_global[0] - x2), float(anchor_global[1] - y2))\n        data['val_local'] = (float(pr['val_gt_x'] - x2), float(pr['val_gt_y'] - y2))\n\n    anchor_f = preprocess_gray_variant(data['anchor_rgb'], cfg['filter'])\n    val_f = preprocess_gray_variant(data['val_rgb'], cfg['filter'])\n    crop_f = preprocess_gray_variant(data['crop_rgb'], cfg['filter'])\n\n    val_res = run_sp_lg_sweep(\n        query_rgb=val_f,\n        crop_rgb=crop_f,\n        anchor_local=data['anchor_local'],\n        gt_local=data['val_local'],\n        strategy=cfg['strategy'],\n        roi_factor=cfg['roi_factor'],\n        max_kp=cfg['max_kp'],\n        min_conf=cfg['min_conf'],\n        reproj_thr=cfg['reproj_thr'],\n        scales=cfg['scales'],\n        rots_deg=cfg['rots'],\n    )\n\n    err_term = float(val_res['err_px']) if np.isfinite(val_res['err_px']) else 1e5\n    score = float(2000.0 * val_res['inliers'] + 2.0 * val_res['raw_matches'] - 0.4 * err_term)\n\n    return {\n        'cfg': cfg,\n        'data': data,\n        'anchor_f': anchor_f,\n        'val_f': val_f,\n        'crop_f': crop_f,\n        'val_res': val_res,\n        'score': score,\n    }\n\n\ndef run_tuning(pr: pd.Series, target_inliers: int = 100) -> Tuple[pd.DataFrame, Dict[str, object]]:\n    rows = []\n    best = None\n    reached = False\n\n    for round_idx in range(int(AUTO_EXPAND_MAX_ROUNDS)):\n        print(f'===== round {round_idx + 1}/{AUTO_EXPAND_MAX_ROUNDS} =====')\n\n        for lvl_i, base_lvl in enumerate(BASE_SEARCH_LEVELS, 1):\n            lvl = expand_level(base_lvl, round_idx=round_idx)\n            cfgs_all = build_configs(lvl)\n            cfgs = sample_configs(cfgs_all, max_n=int(MAX_CONFIGS_PER_LEVEL), seed=int(RNG_SEED + 100 * round_idx + lvl_i))\n            print(f\"[{lvl['name']}] evaluating {len(cfgs)} configs (from {len(cfgs_all)})\")\n\n            t0 = perf_counter()\n            for j, cfg in enumerate(cfgs, 1):\n                try:\n                    out = evaluate_config_for_pair(pr, cfg)\n                except Exception as e:\n                    out = {\n                        'cfg': cfg,\n                        'data': None,\n                        'anchor_f': None,\n                        'val_f': None,\n                        'crop_f': None,\n                        'val_res': {\n                            'raw_matches': 0,\n                            'inliers': 0,\n                            'err_px': np.nan,\n                            'scale_used': np.nan,\n                            'rot_used_deg': np.nan,\n                            'est_rot_deg': np.nan,\n                            'est_scale': np.nan,\n                        },\n                        'score': -1e12,\n                        'error': str(e),\n                    }\n\n                vr = out['val_res']\n                row = {\n                    'round': int(round_idx + 1),\n                    'level': cfg['level'],\n                    'backend': 'superpoint_lightglue',\n                    'filter': cfg['filter'],\n                    'strategy': cfg['strategy'],\n                    'roi_factor': cfg['roi_factor'],\n                    'crop_scale': cfg['crop_scale'],\n                    'max_kp': cfg['max_kp'],\n                    'min_conf': cfg['min_conf'],\n                    'reproj_thr': cfg['reproj_thr'],\n                    'scale_used': float(vr['scale_used']) if np.isfinite(vr['scale_used']) else np.nan,\n                    'rot_used_deg': float(vr['rot_used_deg']) if np.isfinite(vr['rot_used_deg']) else np.nan,\n                    'est_rot_deg': float(vr['est_rot_deg']) if np.isfinite(vr['est_rot_deg']) else np.nan,\n                    'est_scale': float(vr['est_scale']) if np.isfinite(vr['est_scale']) else np.nan,\n                    'raw_matches': int(vr['raw_matches']),\n                    'inliers': int(vr['inliers']),\n                    'err_px': float(vr['err_px']) if np.isfinite(vr['err_px']) else np.nan,\n                    'score': float(out['score']),\n                }\n                rows.append(row)\n\n                if best is None or out['score'] > best['score']:\n                    best = out\n\n                if j % 20 == 0:\n                    bvr = best['val_res']\n                    print(f\"  {j:>3}/{len(cfgs)} | best inl={int(bvr['inliers'])} raw={int(bvr['raw_matches'])} err={bvr['err_px']}\")\n\n            dt = perf_counter() - t0\n            bvr = best['val_res']\n            print(f\"[{lvl['name']}] done in {dt:.1f}s | best inl={int(bvr['inliers'])} raw={int(bvr['raw_matches'])} err={bvr['err_px']}\")\n\n            if int(bvr['inliers']) >= int(target_inliers):\n                print(f\"Target reached: {int(bvr['inliers'])} >= {target_inliers}\")\n                reached = True\n                break\n\n        if reached:\n            break\n\n    if best is None:\n        raise RuntimeError('No configuration could be evaluated.')\n\n    df = pd.DataFrame(rows)\n    if len(df):\n        df = df.sort_values(['inliers', 'raw_matches', 'score'], ascending=False).reset_index(drop=True)\n    return df, best\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run tuning on selected pair\nsel = pair_df[\n    (pair_df['anchor_id'].astype(int) == int(PAIR_ANCHOR_ID)) &\n    (pair_df['val_id'].astype(int) == int(PAIR_VAL_ID))\n]\nif len(sel) == 0:\n    idx = int(np.clip(PREVIEW_PAIR_INDEX, 0, len(pair_df) - 1))\n    pr = pair_df.iloc[idx]\n    print(f'Pair {PAIR_ANCHOR_ID}->{PAIR_VAL_ID} not found, using pair index {idx}.')\nelse:\n    pr = sel.iloc[0]\n\nprint('using pair:', int(pr['anchor_id']), '->', int(pr['val_id']))\n\n# preview constant crop before tuning\npreview = prepare_pair_data(pr)\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\naxes[0].imshow(preview['anchor_rgb'])\naxes[0].set_title(f\"Anchor image | id={int(pr['anchor_id'])}\")\naxes[0].axis('off')\n\naxes[1].imshow(preview['val_rgb'])\naxes[1].set_title(f\"Validation image | id={int(pr['val_id'])}\")\naxes[1].axis('off')\n\naxes[2].imshow(preview['crop_rgb'])\naxes[2].scatter([preview['anchor_local'][0]], [preview['anchor_local'][1]], s=35, c='red', label='anchor GT')\naxes[2].scatter([preview['val_local'][0]], [preview['val_local'][1]], s=35, c='cyan', label='val GT')\naxes[2].set_title(f\"Constant map crop | {preview['crop_rgb'].shape[1]}x{preview['crop_rgb'].shape[0]}\")\naxes[2].legend(loc='upper right')\naxes[2].axis('off')\nplt.tight_layout()\nplt.show()\n\ntune_df, best = run_tuning(pr=pr, target_inliers=int(TARGET_INLIERS))\n\nprint('best config:', best['cfg'])\nprint('best val result:', {\n    'raw_matches': int(best['val_res']['raw_matches']),\n    'inliers': int(best['val_res']['inliers']),\n    'err_px': float(best['val_res']['err_px']) if np.isfinite(best['val_res']['err_px']) else np.nan,\n    'scale_used': float(best['val_res']['scale_used']) if np.isfinite(best['val_res']['scale_used']) else np.nan,\n    'rot_used_deg': float(best['val_res']['rot_used_deg']) if np.isfinite(best['val_res']['rot_used_deg']) else np.nan,\n    'est_rot_deg': float(best['val_res']['est_rot_deg']) if np.isfinite(best['val_res']['est_rot_deg']) else np.nan,\n    'est_scale': float(best['val_res']['est_scale']) if np.isfinite(best['val_res']['est_scale']) else np.nan,\n})\n\ndisplay(tune_df.head(30))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization: 4 columns with matches + map overlay\n\ndef pick_draw_idx(m: MatchResult, inl: np.ndarray, max_draw: int = 160, seed: int = 7):\n    n = int(m.matches.shape[0])\n    if n == 0:\n        return np.zeros((0,), dtype=np.int32)\n\n    if inl is not None and inl.shape[0] == n and np.any(inl):\n        idx = np.where(inl.astype(bool))[0]\n    else:\n        idx = np.arange(n, dtype=np.int32)\n\n    if idx.size <= max_draw:\n        return idx\n\n    if m.conf is not None and m.conf.shape[0] == n:\n        order = np.argsort(-m.conf[idx])[:max_draw]\n        return idx[order]\n\n    rng = np.random.default_rng(int(seed))\n    return np.sort(rng.choice(idx, size=max_draw, replace=False))\n\n\ndef draw_heading(ax, x: float, y: float, deg: float, color: str, length: float = 55.0):\n    if not np.isfinite(deg):\n        return\n    t = np.deg2rad(float(deg))\n    dx = float(length * np.cos(t))\n    dy = float(length * np.sin(t))\n    ax.arrow(x, y, dx, dy, color=color, width=0.8, head_width=10, head_length=12, length_includes_head=True)\n\n\ndef draw_best_4col(best: Dict[str, object], pr: pd.Series, max_draw: int = 160, seed: int = 7):\n    cfg = best['cfg']\n    data = best['data']\n\n    # Anchor run with same tuned config for side-by-side comparison\n    anchor_res = run_sp_lg_sweep(\n        query_rgb=best['anchor_f'],\n        crop_rgb=best['crop_f'],\n        anchor_local=data['anchor_local'],\n        gt_local=data['anchor_local'],\n        strategy=cfg['strategy'],\n        roi_factor=cfg['roi_factor'],\n        max_kp=cfg['max_kp'],\n        min_conf=cfg['min_conf'],\n        reproj_thr=cfg['reproj_thr'],\n        scales=cfg['scales'],\n        rots_deg=cfg['rots'],\n    )\n    val_res = best['val_res']\n\n    a = anchor_res['query_used']\n    v = val_res['query_used']\n    c = best['crop_f']\n\n    # [anchor | crop] [val | crop]\n    h = max(a.shape[0], c.shape[0], v.shape[0], c.shape[0])\n    w1, w2, w3, w4 = a.shape[1], c.shape[1], v.shape[1], c.shape[1]\n    W = w1 + w2 + w3 + w4\n    canvas = np.zeros((h, W, 3), dtype=np.uint8)\n\n    def put(im, x):\n        y = (h - im.shape[0]) // 2\n        canvas[y:y + im.shape[0], x:x + im.shape[1]] = im\n        return (x, y, im.shape[1], im.shape[0])\n\n    p1 = put(a, 0)\n    p2 = put(c, w1)\n    p3 = put(v, w1 + w2)\n    p4 = put(c, w1 + w2 + w3)\n\n    fig, ax = plt.subplots(1, 1, figsize=(30, 8))\n    ax.imshow(canvas)\n    ax.axis('off')\n\n    for xs in [p2[0] - 0.5, p3[0] - 0.5, p4[0] - 0.5]:\n        ax.axvline(xs, color='white', linewidth=1.0, alpha=0.55)\n\n    # anchor -> crop lines (cyan)\n    am = anchor_res['match']\n    aidx = pick_draw_idx(am, anchor_res['inlier_mask'], max_draw=max_draw, seed=seed)\n    x1, y1, _, _ = p1\n    x2, y2, _, _ = p2\n    aoffx, aoffy = anchor_res['ref_offset']\n    for i in aidx:\n        ii = int(i)\n        qi = int(am.matches[ii, 0]); ri = int(am.matches[ii, 1])\n        q = am.k0[qi]; r = am.k1[ri]\n        ok_inl = bool(anchor_res['inlier_mask'][ii]) if anchor_res['inlier_mask'] is not None and ii < len(anchor_res['inlier_mask']) else False\n        ax.plot(\n            [float(q[0] + x1), float(r[0] + aoffx + x2)],\n            [float(q[1] + y1), float(r[1] + aoffy + y2)],\n            color='cyan', linewidth=1.3 if ok_inl else 0.6, alpha=0.9 if ok_inl else 0.2,\n        )\n\n    # val -> crop lines (orange)\n    vm = val_res['match']\n    vidx = pick_draw_idx(vm, val_res['inlier_mask'], max_draw=max_draw, seed=seed)\n    x3, y3, _, _ = p3\n    x4, y4, _, _ = p4\n    voffx, voffy = val_res['ref_offset']\n    for i in vidx:\n        ii = int(i)\n        qi = int(vm.matches[ii, 0]); ri = int(vm.matches[ii, 1])\n        q = vm.k0[qi]; r = vm.k1[ri]\n        ok_inl = bool(val_res['inlier_mask'][ii]) if val_res['inlier_mask'] is not None and ii < len(val_res['inlier_mask']) else False\n        ax.plot(\n            [float(q[0] + x3), float(r[0] + voffx + x4)],\n            [float(q[1] + y3), float(r[1] + voffy + y4)],\n            color='orange', linewidth=1.3 if ok_inl else 0.6, alpha=0.9 if ok_inl else 0.2,\n        )\n\n    al = data['anchor_local']\n    vl = data['val_local']\n\n    # GT points in both crop columns\n    ax.scatter([al[0] + x2], [al[1] + y2], s=32, c='red')\n    ax.scatter([vl[0] + x2], [vl[1] + y2], s=30, c='cyan')\n    ax.scatter([al[0] + x4], [al[1] + y4], s=32, c='red')\n    ax.scatter([vl[0] + x4], [vl[1] + y4], s=30, c='cyan')\n\n    # predicted val center in right crop\n    pred = val_res['pred_local']\n    if np.isfinite(pred[0]) and np.isfinite(pred[1]):\n        px = float(pred[0] + x4)\n        py = float(pred[1] + y4)\n        ax.scatter([px], [py], s=100, c='yellow', marker='*')\n        draw_heading(ax, px, py, float(val_res['est_rot_deg']), color='yellow', length=50)\n\n    ax.set_title(\n        f\"{cfg['filter']} | superpoint_lightglue | {cfg['strategy']} | \"\n        f\"A raw={anchor_res['raw_matches']} inl={anchor_res['inliers']} | \"\n        f\"V raw={val_res['raw_matches']} inl={val_res['inliers']} err={val_res['err_px']:.1f} \"\n        f\"est_rot={val_res['est_rot_deg']:.1f}deg est_scale={val_res['est_scale']:.3f}\"\n    )\n    plt.tight_layout()\n    plt.show()\n\n\ndef draw_map_overlay(best: Dict[str, object], pr: pd.Series):\n    data = best['data']\n    x0, y0 = data['crop_origin']\n    vpred = best['val_res']['pred_local']\n\n    if np.isfinite(vpred[0]) and np.isfinite(vpred[1]):\n        pred_x = float(np.clip(vpred[0] + x0, 0, MAP_W - 1))\n        pred_y = float(np.clip(vpred[1] + y0, 0, MAP_H - 1))\n    else:\n        pred_x, pred_y = np.nan, np.nan\n\n    gt_x, gt_y = float(pr['val_gt_x']), float(pr['val_gt_y'])\n    anc_x, anc_y = float(pr['anchor_x']), float(pr['anchor_y'])\n\n    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\n    axes[0].imshow(map_rgb)\n    axes[0].scatter([anc_x], [anc_y], s=45, c='red', label='anchor GT')\n    axes[0].scatter([gt_x], [gt_y], s=45, c='cyan', label='val GT')\n    if np.isfinite(pred_x) and np.isfinite(pred_y):\n        axes[0].scatter([pred_x], [pred_y], s=80, c='yellow', marker='*', label='val pred')\n        axes[0].plot([gt_x, pred_x], [gt_y, pred_y], color='orange', linewidth=1.3, alpha=0.8)\n    axes[0].set_title('Global map overlay')\n    axes[0].legend(loc='upper right')\n    axes[0].axis('off')\n\n    crop_vis = best['crop_f']\n    axes[1].imshow(crop_vis)\n    al = data['anchor_local']\n    vl = data['val_local']\n    axes[1].scatter([al[0]], [al[1]], s=45, c='red', label='anchor GT')\n    axes[1].scatter([vl[0]], [vl[1]], s=45, c='cyan', label='val GT')\n    if np.isfinite(vpred[0]) and np.isfinite(vpred[1]):\n        axes[1].scatter([vpred[0]], [vpred[1]], s=80, c='yellow', marker='*', label='val pred')\n        axes[1].plot([vl[0], vpred[0]], [vl[1], vpred[1]], color='orange', linewidth=1.3, alpha=0.8)\n    axes[1].set_title('Local crop overlay')\n    axes[1].legend(loc='upper right')\n    axes[1].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n\ndraw_best_4col(best, pr, max_draw=180, seed=RNG_SEED)\ndraw_map_overlay(best, pr)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Diagnostics: which hyperparameters worked best?\nif len(tune_df) == 0:\n    print('No tuning rows available.')\nelse:\n    cols = [\n        'round', 'level', 'filter', 'strategy', 'crop_scale',\n        'max_kp', 'min_conf', 'reproj_thr',\n        'scale_used', 'rot_used_deg', 'est_rot_deg', 'est_scale',\n        'raw_matches', 'inliers', 'err_px', 'score'\n    ]\n    display(tune_df[cols].head(25))\n\n    by_filter = (\n        tune_df\n        .groupby('filter', as_index=False)\n        .agg(\n            best_inliers=('inliers', 'max'),\n            mean_inliers=('inliers', 'mean'),\n            best_err_px=('err_px', 'min'),\n            runs=('inliers', 'size'),\n        )\n        .sort_values(['best_inliers', 'mean_inliers'], ascending=False)\n        .reset_index(drop=True)\n    )\n    display(by_filter)\n\n    topn = min(20, len(tune_df))\n    plot_df = tune_df.head(topn).iloc[::-1]\n    fig, ax = plt.subplots(1, 1, figsize=(10, max(4, 0.35 * topn)))\n    labels = [f\"{r['filter']} | kp={int(r['max_kp'])} conf={r['min_conf']:.3f}\" for _, r in plot_df.iterrows()]\n    ax.barh(np.arange(topn), plot_df['inliers'].to_numpy(), color='tab:blue', alpha=0.85)\n    ax.set_yticks(np.arange(topn))\n    ax.set_yticklabels(labels)\n    ax.set_xlabel('Inliers')\n    ax.set_title('Top configurations by inliers')\n    ax.grid(axis='x', alpha=0.25)\n    plt.tight_layout()\n    plt.show()\n\nbest_inl = int(best['val_res']['inliers'])\nif best_inl >= int(TARGET_INLIERS):\n    print(f'Target achieved: {best_inl} inliers >= {TARGET_INLIERS}')\nelse:\n    print(f'Target not reached: {best_inl} inliers < {TARGET_INLIERS}')\n    print('Increase AUTO_EXPAND_MAX_ROUNDS or MAX_CONFIGS_PER_LEVEL, then rerun tuning cell.')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}