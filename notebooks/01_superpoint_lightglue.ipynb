{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = Path(\"../data/data\")\n",
    "MAP_PATH = DATA_PATH / \"map.png\"\n",
    "\n",
    "TRAIN_IMG_DIR = DATA_PATH / \"train_data\" / \"train_images\"\n",
    "TEST_IMG_DIR  = DATA_PATH / \"test_data\" / \"test_images\"\n",
    "\n",
    "TRAIN_POS_CSV = DATA_PATH / \"train_data\" / \"train_pos.csv\"\n",
    "TRAIN_CAM_CSV = DATA_PATH / \"train_data\" / \"train_cam.csv\"\n",
    "TEST_CAM_CSV  = DATA_PATH / \"test_data\" / \"test_cam.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_bgr = cv2.imread(str(MAP_PATH), cv2.IMREAD_COLOR)\n",
    "assert map_bgr is not None\n",
    "map_rgb = cv2.cvtColor(map_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.imshow(map_rgb)\n",
    "plt.title(f\"map.png shape={map_rgb.shape}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_csv(TRAIN_POS_CSV)\n",
    "pos_df[\"id\"] = pos_df[\"id\"].astype(int)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.imshow(map_rgb)\n",
    "plt.scatter(pos_df[\"x_pixel\"], pos_df[\"y_pixel\"], s=8)\n",
    "plt.title(\"Train GT positions on map.png\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(pos_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec613e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def overlay_train_images_on_map(\n",
    "    map_rgb,\n",
    "    pos_df,\n",
    "    train_img_dir,\n",
    "    start_idx=0,\n",
    "    end_idx=20,\n",
    "    scale=0.25,\n",
    "    alpha=0.5,\n",
    "    draw_center_dot=True\n",
    "):\n",
    "    \"\"\"\n",
    "    map_rgb: RGB image of map\n",
    "    pos_df: dataframe with columns ['id','x_pixel','y_pixel']\n",
    "    train_img_dir: path to train_images folder\n",
    "    start_idx, end_idx: index range in pos_df (row indices, not image IDs)\n",
    "    scale: scale factor for drone image\n",
    "    alpha: transparency of overlay\n",
    "    draw_center_dot: whether to draw GT point\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(map_rgb)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    H_map, W_map = map_rgb.shape[:2]\n",
    "\n",
    "    for idx in range(start_idx, min(end_idx, len(pos_df))):\n",
    "        row = pos_df.iloc[idx]\n",
    "        img_id = int(row[\"id\"])\n",
    "        x = float(row[\"x_pixel\"])\n",
    "        y = float(row[\"y_pixel\"])\n",
    "\n",
    "        # find image file\n",
    "        img_path = None\n",
    "        for ext in [\".JPG\", \".jpg\", \".png\", \".jpeg\"]:\n",
    "            p = train_img_dir / f\"{img_id:04d}{ext}\"\n",
    "            if p.exists():\n",
    "                img_path = p\n",
    "                break\n",
    "            p = train_img_dir / f\"{img_id}{ext}\"\n",
    "            if p.exists():\n",
    "                img_path = p\n",
    "                break\n",
    "\n",
    "        if img_path is None:\n",
    "            print(f\"Image not found for id {img_id}\")\n",
    "            continue\n",
    "\n",
    "        img_bgr = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # resize\n",
    "        h, w = img_rgb.shape[:2]\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        img_small = cv2.resize(img_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # compute overlay extent\n",
    "        x_min = x - new_w / 2\n",
    "        x_max = x + new_w / 2\n",
    "        y_min = y - new_h / 2\n",
    "        y_max = y + new_h / 2\n",
    "\n",
    "        # draw image\n",
    "        plt.imshow(\n",
    "            img_small,\n",
    "            extent=[x_min, x_max, y_max, y_min],  # origin='upper'\n",
    "            alpha=alpha\n",
    "        )\n",
    "\n",
    "        # draw GT center\n",
    "        if draw_center_dot:\n",
    "            plt.scatter([x], [y], s=40)\n",
    "\n",
    "        # draw ID text\n",
    "        plt.text(\n",
    "            x, y,\n",
    "            str(img_id),\n",
    "            color=\"red\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\"\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Train images overlayed | idx range [{start_idx}, {end_idx})\")\n",
    "    plt.show()\n",
    "\n",
    "overlay_train_images_on_map(\n",
    "    map_rgb,\n",
    "    pos_df,\n",
    "    TRAIN_IMG_DIR,\n",
    "    start_idx=19,\n",
    "    end_idx=20,\n",
    "    scale=0.05,\n",
    "    alpha=0.8,\n",
    "    draw_center_dot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_image(img_id: int):\n",
    "    # handle 13.jpg / 0013.JPG / 13.png etc. if needed; simplest first:\n",
    "    for ext in [\".JPG\", \".jpg\", \".png\", \".jpeg\", \".JPEG\", \".PNG\"]:\n",
    "        p = TRAIN_IMG_DIR / f\"{img_id:04d}{ext}\"\n",
    "        if p.exists():\n",
    "            img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "            if img is not None:\n",
    "                return p, cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        p = TRAIN_IMG_DIR / f\"{img_id}{ext}\"\n",
    "        if p.exists():\n",
    "            img = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "            if img is not None:\n",
    "                return p, cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return None, None\n",
    "\n",
    "sample_ids = pos_df[\"id\"][20:26]#+.sample(6, random_state=0).tolist()\n",
    "print(sample_ids)\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i, img_id in enumerate(sample_ids, 1):\n",
    "    p, img = read_train_image(img_id)\n",
    "    ax = plt.subplot(2, 3, i)\n",
    "    ax.imshow(img)\n",
    "    row = pos_df[pos_df[\"id\"] == img_id].iloc[0]\n",
    "    ax.set_title(f\"id={img_id} | gt=({row.x_pixel:.0f},{row.y_pixel:.0f})\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/cvg/LightGlue.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff781bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"LightGlue\")\n",
    "\n",
    "import torch\n",
    "from lightglue import LightGlue, SuperPoint\n",
    "from lightglue.utils import rbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_inlier_matches(\n",
    "    img0_rgb,\n",
    "    img1_rgb,\n",
    "    kpts0,\n",
    "    kpts1,\n",
    "    matches01,\n",
    "    inlier_mask,\n",
    "    max_draw=50,\n",
    "    line_thickness=4,\n",
    "    point_radius=6,\n",
    "    line_color=(255, 0, 0),\n",
    "    darken_bg=True\n",
    "):\n",
    "    idx = np.where(inlier_mask)[0]\n",
    "    if len(idx) == 0:\n",
    "        print(\"No inliers to draw.\")\n",
    "        return\n",
    "\n",
    "    # Random subset for clarity\n",
    "    if len(idx) > max_draw:\n",
    "        idx = np.random.choice(idx, size=max_draw, replace=False)\n",
    "\n",
    "    pts0 = kpts0[matches01[idx, 0]]\n",
    "    pts1 = kpts1[matches01[idx, 1]]\n",
    "\n",
    "    h0, w0 = img0_rgb.shape[:2]\n",
    "    h1, w1 = img1_rgb.shape[:2]\n",
    "\n",
    "    canvas = np.zeros((max(h0, h1), w0 + w1, 3), dtype=np.uint8)\n",
    "    canvas[:h0, :w0] = img0_rgb\n",
    "    canvas[:h1, w0:] = img1_rgb\n",
    "\n",
    "    if darken_bg:\n",
    "        canvas = (canvas * 0.6).astype(np.uint8)\n",
    "\n",
    "    for p0, p1 in zip(pts0, pts1):\n",
    "        x0, y0 = int(p0[0]), int(p0[1])\n",
    "        x1, y1 = int(p1[0]) + w0, int(p1[1])\n",
    "\n",
    "        cv2.line(canvas, (x0, y0), (x1, y1), line_color, thickness=line_thickness)\n",
    "        cv2.circle(canvas, (x0, y0), point_radius, (0, 255, 0), -1)\n",
    "        cv2.circle(canvas, (x1, y1), point_radius, (0, 255, 0), -1)\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(canvas)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e20f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "extractor = SuperPoint(max_num_keypoints=2048*2).eval().to(device)\n",
    "matcher = LightGlue(features=\"superpoint\").eval().to(device)\n",
    "\n",
    "def to_tensor_image(img_rgb):\n",
    "    # LightGlue expects torch image in [0,1], shape [1,1,H,W] if grayscale\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    t = torch.from_numpy(gray).float()[None, None] / 255.0\n",
    "    return t.to(device)\n",
    "\n",
    "def match_two_images(img0_rgb, img1_rgb):\n",
    "    image0 = to_tensor_image(img0_rgb)\n",
    "    image1 = to_tensor_image(img1_rgb)\n",
    "\n",
    "    feats0 = extractor.extract(image0)\n",
    "    feats1 = extractor.extract(image1)\n",
    "\n",
    "    matches01 = matcher({\"image0\": feats0, \"image1\": feats1})\n",
    "    feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "\n",
    "    kpts0 = feats0[\"keypoints\"].cpu().numpy()\n",
    "    kpts1 = feats1[\"keypoints\"].cpu().numpy()\n",
    "    matches = matches01[\"matches\"].cpu().numpy()  # (M,2) indices into kpts0/kpts1\n",
    "\n",
    "    return kpts0, kpts1, matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magsac_inliers_homography(kpts0, kpts1, matches, reproj_thr=3.0):\n",
    "    pts0 = kpts0[matches[:, 0]].astype(np.float32)\n",
    "    pts1 = kpts1[matches[:, 1]].astype(np.float32)\n",
    "\n",
    "    if len(pts0) < 8:\n",
    "        return None, None, np.zeros((len(pts0),), dtype=bool)\n",
    "\n",
    "    H, mask = cv2.findHomography(\n",
    "        pts0, pts1,\n",
    "        method=cv2.USAC_MAGSAC,\n",
    "        ransacReprojThreshold=reproj_thr,\n",
    "        maxIters=10000,\n",
    "        confidence=0.999\n",
    "    )\n",
    "    if mask is None:\n",
    "        return H, None, np.zeros((len(pts0),), dtype=bool)\n",
    "    inlier_mask = mask.ravel().astype(bool)\n",
    "    return H, mask, inlier_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick two random train ids\n",
    "ids = pos_df[\"id\"][0:2].tolist()#.sample(2, random_state=1).tolist()\n",
    "p0, img0 = read_train_image(ids[0])\n",
    "p1, img1 = read_train_image(ids[1])\n",
    "\n",
    "k0, k1, matches = match_two_images(img0, img1)\n",
    "H, mask, inliers = magsac_inliers_homography(k0, k1, matches)\n",
    "\n",
    "print(\"train-train\")\n",
    "print(\"ids:\", ids, \"matches:\", len(matches), \"inliers:\", int(inliers.sum()))\n",
    "draw_inlier_matches(\n",
    "    img0,\n",
    "    img1,\n",
    "    k0,\n",
    "    k1,\n",
    "    matches,\n",
    "    inliers,\n",
    "    max_draw=40,        # very important\n",
    "    line_thickness=5,\n",
    "    point_radius=7,\n",
    "    line_color=(0, 255, 255)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_tiles(map_rgb, tile_size=768, stride=512):\n",
    "    H, W = map_rgb.shape[:2]\n",
    "    for y0 in range(0, H - tile_size + 1, stride):\n",
    "        for x0 in range(0, W - tile_size + 1, stride):\n",
    "            tile = map_rgb[y0:y0+tile_size, x0:x0+tile_size]\n",
    "            yield (x0, y0, tile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46615e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = int(pos_df[\"id\"].sample(1, random_state=2).iloc[0])\n",
    "p_q, img_q = read_train_image(train_id)\n",
    "gt = pos_df[pos_df[\"id\"] == train_id].iloc[0]\n",
    "print(\"train_id\", train_id, \"gt\", (gt.x_pixel, gt.y_pixel))\n",
    "\n",
    "best = None\n",
    "\n",
    "# debug: nur Tiles in der Nähe der GT (um zu prüfen, ob es prinzipiell klappt)\n",
    "tile_size = 768\n",
    "stride = 512\n",
    "radius = 1000  # pixels around GT to search (debug only)\n",
    "\n",
    "for (x0, y0, tile_rgb) in iter_tiles(map_rgb, tile_size=tile_size, stride=stride):\n",
    "    cx_tile = x0 + tile_size/2\n",
    "    cy_tile = y0 + tile_size/2\n",
    "    if abs(cx_tile - gt.x_pixel) > radius or abs(cy_tile - gt.y_pixel) > radius:\n",
    "        continue\n",
    "\n",
    "    kq, kt, m = match_two_images(img_q, tile_rgb)\n",
    "    Hqt, _, inl = magsac_inliers_homography(kq, kt, m, reproj_thr=3.0)\n",
    "    score = int(inl.sum())\n",
    "\n",
    "    if best is None or score > best[\"score\"]:\n",
    "        best = {\"x0\": x0, \"y0\": y0, \"tile\": tile_rgb, \"kq\": kq, \"kt\": kt, \"m\": m, \"inl\": inl, \"H\": Hqt, \"score\": score}\n",
    "\n",
    "print(\"best inliers:\", best[\"score\"], \"tile origin:\", (best[\"x0\"], best[\"y0\"]))\n",
    "draw_inlier_matches(img_q, best[\"tile\"], best[\"kq\"], best[\"kt\"], best[\"m\"], best[\"inl\"], max_draw=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def apply_homography(H: np.ndarray, xy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    xy: shape (2,) float [x,y] in source image coordinates\n",
    "    returns: shape (2,) float in destination coordinates\n",
    "    \"\"\"\n",
    "    p = np.array([xy[0], xy[1], 1.0], dtype=np.float64)\n",
    "    q = H @ p\n",
    "    if abs(q[2]) < 1e-12:\n",
    "        return np.array([np.nan, np.nan], dtype=np.float64)\n",
    "    return (q[:2] / q[2]).astype(np.float64)\n",
    "\n",
    "def euclidean_px(a_xy, b_xy) -> float:\n",
    "    dx = float(a_xy[0]) - float(b_xy[0])\n",
    "    dy = float(a_xy[1]) - float(b_xy[1])\n",
    "    return float(np.sqrt(dx*dx + dy*dy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "@dataclass\n",
    "class Tile:\n",
    "    tile_id: int\n",
    "    x0: int\n",
    "    y0: int\n",
    "    rgb: np.ndarray  # tile image\n",
    "\n",
    "def build_tiles(map_rgb: np.ndarray, tile_size: int = 768, stride: int = 512) -> List[Tile]:\n",
    "    H, W = map_rgb.shape[:2]\n",
    "    tiles: List[Tile] = []\n",
    "    tid = 0\n",
    "    for y0 in range(0, H - tile_size + 1, stride):\n",
    "        for x0 in range(0, W - tile_size + 1, stride):\n",
    "            tile_rgb = map_rgb[y0:y0+tile_size, x0:x0+tile_size].copy()\n",
    "            tiles.append(Tile(tile_id=tid, x0=x0, y0=y0, rgb=tile_rgb))\n",
    "            tid += 1\n",
    "    return tiles\n",
    "\n",
    "# Example\n",
    "tile_size = 768\n",
    "stride = 512\n",
    "tiles = build_tiles(map_rgb, tile_size=tile_size, stride=stride)\n",
    "print(\"tiles:\", len(tiles), \"tile_size:\", tile_size, \"stride:\", stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, Any\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def to_tensor_image(img_rgb: np.ndarray, device: str) -> torch.Tensor:\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    t = torch.from_numpy(gray).float()[None, None] / 255.0  # [1,1,H,W]\n",
    "    return t.to(device)\n",
    "\n",
    "def extract_features_rgb(extractor, img_rgb: np.ndarray, device: str):\n",
    "    \"\"\"\n",
    "    Returns features in LightGlue expected shape:\n",
    "      keypoints:   [1, N, 2]\n",
    "      descriptors: [1, N, D]\n",
    "      scores:      [1, N]\n",
    "      image_size:  [1, 2]\n",
    "    Keep them as torch tensors (CPU or GPU doesn't matter; we'll move on demand).\n",
    "    \"\"\"\n",
    "    image_t = to_tensor_image(img_rgb, device)\n",
    "    feats = extractor.extract(image_t)  # already batched\n",
    "    # move to CPU for caching (optional, saves GPU memory)\n",
    "    feats_cpu = {k: v.detach().cpu() for k, v in feats.items()}\n",
    "    return feats_cpu\n",
    "\n",
    "\n",
    "# Build tile feature cache\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tile_feats = {}\n",
    "for t in tiles:\n",
    "    tile_feats[t.tile_id] = extract_features_rgb(extractor, t.rgb, device)\n",
    "print(\"cached tile feats:\", len(tile_feats))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue.utils import rbd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def match_query_to_tile(\n",
    "    matcher,\n",
    "    query_feats,\n",
    "    tile_feats,\n",
    "    device: str,\n",
    "    reproj_thr: float = 3.0,\n",
    "):\n",
    "    # move tensors to device\n",
    "    q = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in query_feats.items()}\n",
    "    t = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in tile_feats.items()}\n",
    "\n",
    "    out = matcher({\"image0\": q, \"image1\": t})\n",
    "    out = rbd(out)\n",
    "\n",
    "    matches = out[\"matches\"].cpu().numpy()  # (M,2)\n",
    "\n",
    "    # keypoints: [1, N, 2] -> remove batch for numpy indexing\n",
    "    kq = query_feats[\"keypoints\"][0].numpy()\n",
    "    kt = tile_feats[\"keypoints\"][0].numpy()\n",
    "\n",
    "    if len(matches) < 8:\n",
    "        return {\"matches\": matches, \"inliers\": np.zeros((len(matches),), bool), \"H\": None, \"score\": 0}\n",
    "\n",
    "    pts0 = kq[matches[:, 0]].astype(np.float32)\n",
    "    pts1 = kt[matches[:, 1]].astype(np.float32)\n",
    "\n",
    "    H, mask = cv2.findHomography(\n",
    "        pts0, pts1,\n",
    "        method=cv2.USAC_MAGSAC,\n",
    "        ransacReprojThreshold=reproj_thr,\n",
    "        maxIters=10000,\n",
    "        confidence=0.999\n",
    "    )\n",
    "\n",
    "    if mask is None or H is None:\n",
    "        inl = np.zeros((len(matches),), dtype=bool)\n",
    "        return {\"matches\": matches, \"inliers\": inl, \"H\": None, \"score\": 0, \"kq\": kq, \"kt\": kt}\n",
    "\n",
    "    inl = mask.ravel().astype(bool)\n",
    "    score = int(inl.sum())\n",
    "    return {\"matches\": matches, \"inliers\": inl, \"H\": H, \"score\": score, \"kq\": kq, \"kt\": kt}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ceedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xy_from_best_tile(\n",
    "    query_rgb: np.ndarray,\n",
    "    best_tile: Tile,\n",
    "    H_query_to_tile: np.ndarray,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Project query image center into tile coords using H, then add tile offset to get map coords.\n",
    "    \"\"\"\n",
    "    hq, wq = query_rgb.shape[:2]\n",
    "    center_q = np.array([wq / 2.0, hq / 2.0], dtype=np.float64)\n",
    "\n",
    "    center_in_tile = apply_homography(H_query_to_tile, center_q)  # (x,y) in tile\n",
    "    x_map = float(center_in_tile[0] + best_tile.x0)\n",
    "    y_map = float(center_in_tile[1] + best_tile.y0)\n",
    "    return x_map, y_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_query_against_map_tiles(\n",
    "    query_rgb,\n",
    "    tiles,\n",
    "    tile_feats,\n",
    "    device: str,\n",
    "    top_k: int = 5,\n",
    "    reproj_thr: float = 3.0,\n",
    "    tile_subsample: int = 1,\n",
    "):\n",
    "    q_feats = extract_features_rgb(extractor, query_rgb, device)\n",
    "\n",
    "    scored = []\n",
    "    for idx, t in enumerate(tiles):\n",
    "        if tile_subsample > 1 and (idx % tile_subsample != 0):\n",
    "            continue\n",
    "\n",
    "        res = match_query_to_tile(matcher, q_feats, tile_feats[t.tile_id], device=device, reproj_thr=reproj_thr)\n",
    "        scored.append((res[\"score\"], t, res))\n",
    "\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return scored[:top_k], q_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20884d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(210, 300, 10):\n",
    "    # pick one train sample\n",
    "    train_id = int(pos_df[\"id\"][id])#.sample(1, random_state=3).iloc[0])\n",
    "    p_q, img_q = read_train_image(train_id)\n",
    "    gt_row = pos_df[pos_df[\"id\"] == train_id].iloc[0]\n",
    "    gt_xy = (float(gt_row.x_pixel), float(gt_row.y_pixel))\n",
    "    print(\"train_id:\", train_id, \"GT:\", gt_xy, \"file:\", p_q.name if p_q else None)\n",
    "\n",
    "    best_list, q_feats = localize_query_against_map_tiles(\n",
    "        img_q, tiles, tile_feats,\n",
    "        device=device,\n",
    "        top_k=4, reproj_thr=3.0,\n",
    "        tile_subsample=1\n",
    "    )\n",
    "\n",
    "    for rank, (score, tile, res) in enumerate(best_list, 1):\n",
    "        print(f\"rank={rank} score(inliers)={score} tile_id={tile.tile_id} origin=({tile.x0},{tile.y0}) H={'yes' if res['H'] is not None else 'no'}\")\n",
    "\n",
    "    # take best\n",
    "    best_score, best_tile, best_res = best_list[0]\n",
    "    if best_res[\"H\"] is None:\n",
    "        print(\"No homography found.\")\n",
    "    else:\n",
    "        pred_xy = predict_xy_from_best_tile(img_q, best_tile, best_res[\"H\"])\n",
    "        err = euclidean_px(pred_xy, gt_xy)\n",
    "        print(\"pred:\", pred_xy, \"err_px:\", err)\n",
    "\n",
    "        # visualize inlier matches (query vs best tile)\n",
    "        draw_inlier_matches(img_q, best_tile.rgb, best_res[\"kq\"], best_res[\"kt\"], best_res[\"matches\"], best_res[\"inliers\"], max_draw=250)\n",
    "\n",
    "        # visualize overlay on global map: point GT vs Pred\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(14,8))\n",
    "        plt.imshow(map_rgb)\n",
    "        plt.scatter([gt_xy[0]], [gt_xy[1]], s=80, label=\"GT\")\n",
    "        plt.scatter([pred_xy[0]], [pred_xy[1]], s=80, label=\"Pred\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"id={train_id} | inliers={best_score} | err={err:.1f}px\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10337762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tile_centers = np.zeros((len(tiles), 2), dtype=np.float32)  # [cx, cy]\n",
    "for i, t in enumerate(tiles):\n",
    "    tile_centers[i, 0] = t.x0 + tile_size * 0.5\n",
    "    tile_centers[i, 1] = t.y0 + tile_size * 0.5\n",
    "\n",
    "tile_ids = np.array([t.tile_id for t in tiles], dtype=np.int32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
